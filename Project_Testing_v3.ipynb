{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethanmarshallanalytics/Object-Detection-YOLOv8/blob/main/Project_Testing_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zA4qBMPrEk6",
        "outputId": "34a398d3-e520-418d-fb01-b96a4796978c"
      },
      "id": "_zA4qBMPrEk6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/project_folder\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGOG_vkUGeiy",
        "outputId": "783c2d5c-dbba-4d31-876d-5abcf5915912"
      },
      "id": "bGOG_vkUGeiy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project_folder\n",
            " annotated    'old versions'\t\t'Project Testing v3.ipynb'   train\t      yolov8n.pt\n",
            " config.yaml  'Project Data v5.ipynb'\t runs\t\t\t     valid\n",
            " kits19       'Project Slides.gslides'\t test\t\t\t     visualizations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install squarify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js7L1jXeHHEG",
        "outputId": "e90bfb66-1af0-4f85-c795-63d284cf20c1"
      },
      "id": "Js7L1jXeHHEG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.47-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m750.4/750.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.9.0.80)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Collecting py-cpuinfo (from ultralytics)\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import squarify\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "%matplotlib inline\n",
        "#os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ],
      "metadata": {
        "id": "3gI0HtaUHB8X"
      },
      "id": "3gI0HtaUHB8X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rY_XeCQq6ns",
        "outputId": "09656ef4-f063-4076-8a9f-1722ebd71dde"
      },
      "id": "8rY_XeCQq6ns",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 13 20:17:45 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0              24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxrCWFtiq5go",
        "outputId": "4a730115-06a5-4312-fffc-5d3c1cbad0e6"
      },
      "id": "PxrCWFtiq5go",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b306bcf0-6ea8-48cd-a271-81622eb52593",
      "metadata": {
        "id": "b306bcf0-6ea8-48cd-a271-81622eb52593"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8b6e70-da91-4ff8-9ed7-fa120ca87561",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd8b6e70-da91-4ff8-9ed7-fa120ca87561",
        "outputId": "233dd2fa-0a3d-458e-c71f-b1361651d248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.47 ðŸš€ Python-3.10.12 torch-2.2.0+cpu CPU (Intel Xeon 2.00GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/drive/MyDrive/project_folder/config.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 19.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011433 parameters, 3011417 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1HYs_H2Rdh45csuTtATRlA7BMqJiWKVI8/project_folder/train/labels... 1387 images, 64 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1387/1387 [01:43<00:00, 13.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1HYs_H2Rdh45csuTtATRlA7BMqJiWKVI8/project_folder/train/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1HYs_H2Rdh45csuTtATRlA7BMqJiWKVI8/project_folder/valid/labels... 175 images, 9 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 175/175 [01:56<00:00,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1HYs_H2Rdh45csuTtATRlA7BMqJiWKVI8/project_folder/valid/labels.cache\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50         0G      3.615       4.62      3.898         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:37<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50         0G        2.8      3.587      2.852         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:36<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:06<00:00,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.013      0.227     0.0108    0.00628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50         0G      2.155      2.568      2.317         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:36<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.391      0.193      0.254      0.153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50         0G      1.698      1.953      1.928         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.398      0.324      0.371      0.245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50         0G      1.414      1.554      1.685         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:36<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.482      0.374      0.426      0.321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50         0G      1.333      1.404      1.599         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.486      0.483      0.439      0.316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50         0G      1.194      1.284      1.498         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.862      0.135      0.174      0.121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50         0G      1.123      1.168      1.409         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:37<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.481      0.464      0.458      0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50         0G      1.106      1.109        1.4         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:36<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.483        0.5      0.438      0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50         0G      1.043      1.051      1.351         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.597        0.5      0.481      0.369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50         0G      1.018      1.015      1.326         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.725      0.509      0.559      0.416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50         0G     0.9742     0.9437      1.278         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.582      0.549      0.479       0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50         0G     0.9594     0.9309      1.284         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:37<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.712      0.544      0.586      0.461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50         0G     0.9468     0.9003      1.264         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.732      0.513        0.6      0.478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50         0G     0.9085     0.8271      1.231         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.408      0.384      0.317      0.245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50         0G     0.8915      0.801      1.219         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.595      0.574      0.535       0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50         0G     0.8739     0.7819      1.209         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355       0.62      0.556      0.546       0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50         0G     0.8534     0.7518      1.184         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.622      0.534      0.517      0.403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50         0G     0.8463     0.7335      1.198         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.707      0.519      0.547      0.429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50         0G     0.8404     0.7085      1.179         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:36<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.679      0.563      0.586      0.464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50         0G     0.8343      0.701      1.177         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.773      0.549      0.604      0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50         0G     0.8168     0.6986      1.163         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.685      0.552      0.535       0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50         0G      0.785     0.6481      1.142         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.809      0.583      0.635      0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50         0G     0.7919     0.6601      1.154         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.693      0.573       0.56      0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50         0G     0.7869     0.6415      1.139         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.686      0.545      0.589      0.463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50         0G     0.7488     0.6044      1.108         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.744       0.57      0.614      0.476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50         0G     0.7365     0.5857      1.105         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.569      0.302      0.325      0.247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50         0G     0.7523     0.6031      1.117         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.472      0.218      0.149      0.106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50         0G     0.7277     0.5783      1.102         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.774      0.572      0.613      0.485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50         0G     0.7162     0.5858      1.111         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:37<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:07<00:00,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.762      0.569      0.583      0.455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50         0G     0.7119     0.5672      1.093         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.702      0.547      0.565      0.449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50         0G     0.7033     0.5514      1.085         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.653      0.544      0.591      0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50         0G     0.7083     0.5464      1.094         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355       0.56      0.498      0.466      0.373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50         0G     0.6842     0.5265       1.08         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.746      0.564      0.596       0.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50         0G     0.6747     0.5266      1.075         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.783      0.566      0.603      0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50         0G     0.6751      0.523      1.073         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:34<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.658      0.569      0.557      0.435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50         0G      0.666      0.511      1.063         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:06<00:00,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.781      0.488      0.606      0.478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50         0G     0.6508     0.4961       1.05         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:35<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.731       0.52      0.572      0.465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50         0G     0.6501     0.4957      1.054         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:36<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.638      0.552      0.579      0.477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50         0G     0.6474     0.4952      1.046         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:36<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.752      0.559      0.594      0.459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50         0G     0.5681     0.4374      1.014         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.627      0.569      0.561      0.437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50         0G     0.5409     0.4171      1.004         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:33<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.628      0.542      0.546      0.441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50         0G     0.5353     0.4069     0.9986         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:31<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.758      0.544      0.567      0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50         0G     0.5194     0.3942     0.9868         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:32<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.672      0.573      0.575       0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50         0G      0.512     0.3833     0.9817         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:32<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.759      0.561      0.591      0.465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50         0G     0.5017     0.3791     0.9733         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:30<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.785      0.545      0.599      0.492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50         0G     0.4908     0.3727     0.9694         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:31<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.742       0.54      0.578      0.474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50         0G     0.4866     0.3614     0.9654         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:31<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.793      0.547      0.592      0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50         0G     0.4781     0.3594     0.9613         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:31<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.742      0.581      0.596      0.487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50         0G     0.4773     0.3583     0.9604         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [01:32<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355       0.77      0.574      0.606      0.491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 1.389 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.47 ðŸš€ Python-3.10.12 torch-2.2.0+cpu CPU (Intel Xeon 2.00GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        175        355      0.784      0.544        0.6      0.492\n",
            "                kidney        175        275      0.926        0.8      0.868      0.756\n",
            "                 tumor        175         80      0.643      0.287      0.331      0.228\n",
            "Speed: 1.1ms preprocess, 20.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = model.train(data = \"/content/drive/MyDrive/project_folder/config.yaml\", seed=42, epochs=50, lr0=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Directory containing test images\n",
        "TEST_IMAGES_DIR = r'/content/drive/MyDrive/project_folder/test/images'\n",
        "# Directory to save annotated images\n",
        "ANNOTATED_IMAGES_DIR = os.path.join(r'/content/drive/MyDrive/project_folder', 'annotated')\n",
        "\n",
        "# Create annotated images directory if it doesn't exist\n",
        "os.makedirs(ANNOTATED_IMAGES_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "sngvjdZt8lg5"
      },
      "id": "sngvjdZt8lg5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "28416c0b-f83d-4d28-ae51-c19e8b413bce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28416c0b-f83d-4d28-ae51-c19e8b413bce",
        "outputId": "c8a61a5b-d1b4-4a2b-fd23-7e7574ab3bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Speed: 2.6ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.5ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.5ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.5ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 3.2ms preprocess, 45.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.2ms\n",
            "Speed: 3.1ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.6ms\n",
            "Speed: 2.5ms preprocess, 50.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.5ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.9ms preprocess, 52.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.5ms\n",
            "Speed: 2.7ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.5ms\n",
            "Speed: 2.6ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 56.8ms\n",
            "Speed: 2.7ms preprocess, 56.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 44.6ms\n",
            "Speed: 2.5ms preprocess, 44.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.3ms\n",
            "Speed: 2.6ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.7ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.6ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.6ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 2.6ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.8ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.6ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.6ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 51.0ms\n",
            "Speed: 2.6ms preprocess, 51.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.6ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.5ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.1ms\n",
            "Speed: 2.6ms preprocess, 52.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.5ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.6ms preprocess, 50.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 2.8ms preprocess, 44.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.6ms\n",
            "Speed: 2.7ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.1ms\n",
            "Speed: 2.7ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.8ms\n",
            "Speed: 2.7ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 48.7ms\n",
            "Speed: 2.7ms preprocess, 48.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.8ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.9ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.6ms preprocess, 44.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.7ms\n",
            "Speed: 2.5ms preprocess, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.5ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 49.9ms\n",
            "Speed: 2.6ms preprocess, 49.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.6ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.7ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.8ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.8ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.5ms preprocess, 50.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.6ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.6ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.6ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.6ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.8ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.7ms\n",
            "Speed: 2.7ms preprocess, 50.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 2.6ms preprocess, 50.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.7ms\n",
            "Speed: 2.5ms preprocess, 49.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 50.3ms\n",
            "Speed: 2.7ms preprocess, 50.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.2ms\n",
            "Speed: 2.6ms preprocess, 50.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.6ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.5ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 50.0ms\n",
            "Speed: 2.4ms preprocess, 50.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.7ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.5ms\n",
            "Speed: 2.6ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.6ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.6ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.8ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.7ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.3ms\n",
            "Speed: 2.6ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.7ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.6ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.7ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.8ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.4ms\n",
            "Speed: 2.9ms preprocess, 50.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.7ms\n",
            "Speed: 2.5ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 2 tumors, 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.3ms\n",
            "Speed: 2.8ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.5ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.5ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.9ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.5ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.6ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.6ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.5ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.8ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.6ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.5ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.1ms\n",
            "Speed: 2.6ms preprocess, 54.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.7ms\n",
            "Speed: 2.6ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.7ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.6ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.7ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.6ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.5ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.6ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.5ms\n",
            "Speed: 2.5ms preprocess, 50.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 2.5ms preprocess, 50.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.3ms\n",
            "Speed: 2.5ms preprocess, 50.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.5ms\n",
            "Speed: 2.6ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.8ms\n",
            "Speed: 2.5ms preprocess, 49.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.3ms\n",
            "Speed: 2.5ms preprocess, 50.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 2.6ms preprocess, 50.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.9ms\n",
            "Speed: 2.5ms preprocess, 49.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.1ms\n",
            "Speed: 2.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.8ms\n",
            "Speed: 2.5ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.8ms\n",
            "Speed: 2.5ms preprocess, 43.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.4ms\n",
            "Speed: 2.5ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.8ms\n",
            "Speed: 2.7ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.2ms\n",
            "Speed: 2.5ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.5ms\n",
            "Speed: 2.4ms preprocess, 52.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.6ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.2ms\n",
            "Speed: 2.8ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.7ms\n",
            "Speed: 2.5ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.7ms\n",
            "Speed: 2.6ms preprocess, 43.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.9ms\n",
            "Speed: 2.5ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.0ms\n",
            "Speed: 2.6ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.9ms\n",
            "Speed: 2.6ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.7ms\n",
            "Speed: 2.6ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.9ms\n",
            "Speed: 2.8ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.2ms\n",
            "Speed: 2.6ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.8ms\n",
            "Speed: 2.6ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.1ms\n",
            "Speed: 2.6ms preprocess, 50.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.8ms\n",
            "Speed: 2.8ms preprocess, 50.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.1ms\n",
            "Speed: 2.5ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 42.9ms\n",
            "Speed: 2.7ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 42.4ms\n",
            "Speed: 2.5ms preprocess, 42.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.5ms\n",
            "Speed: 2.6ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.7ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.5ms\n",
            "Speed: 2.6ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.3ms\n",
            "Speed: 2.5ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.7ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.8ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.7ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.7ms\n",
            "Speed: 2.8ms preprocess, 42.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.7ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.6ms\n",
            "Speed: 2.7ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.5ms\n",
            "Speed: 2.6ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.7ms preprocess, 43.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.7ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.9ms\n",
            "Speed: 2.9ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.6ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.7ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.1ms\n",
            "Speed: 2.5ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.7ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.6ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.8ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.6ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.8ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.5ms preprocess, 50.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.6ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.7ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.9ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 58.7ms\n",
            "Speed: 2.7ms preprocess, 58.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.8ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.7ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.7ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.3ms\n",
            "Speed: 2.9ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.6ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.3ms\n",
            "Speed: 2.7ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.6ms\n",
            "Speed: 2.6ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.8ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.6ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.7ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.6ms preprocess, 51.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.5ms\n",
            "Speed: 2.8ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.0ms\n",
            "Speed: 2.6ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.7ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 50.4ms\n",
            "Speed: 2.5ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.7ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 5.5ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.6ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.6ms\n",
            "Speed: 2.5ms preprocess, 48.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 3.0ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.7ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.8ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.6ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.4ms\n",
            "Speed: 2.6ms preprocess, 42.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.7ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.5ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.9ms\n",
            "Speed: 2.9ms preprocess, 42.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.6ms\n",
            "Speed: 2.6ms preprocess, 51.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.8ms\n",
            "Speed: 2.6ms preprocess, 50.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 48.6ms\n",
            "Speed: 2.6ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.4ms\n",
            "Speed: 2.5ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.9ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.6ms\n",
            "Speed: 2.5ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.5ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.8ms\n",
            "Speed: 2.5ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 50.6ms\n",
            "Speed: 2.5ms preprocess, 50.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 51.3ms\n",
            "Speed: 2.9ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.5ms\n",
            "Speed: 2.6ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.5ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 2.6ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.6ms\n",
            "Speed: 3.3ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.8ms preprocess, 50.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.5ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.6ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 50.6ms\n",
            "Speed: 2.5ms preprocess, 50.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.2ms\n",
            "Speed: 2.8ms preprocess, 48.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.3ms\n",
            "Speed: 5.7ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.7ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.5ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.3ms\n",
            "Speed: 2.8ms preprocess, 47.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.5ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.5ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.6ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.2ms\n",
            "Speed: 2.5ms preprocess, 50.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.0ms\n",
            "Speed: 2.5ms preprocess, 51.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.5ms\n",
            "Speed: 2.7ms preprocess, 51.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.2ms\n",
            "Speed: 2.6ms preprocess, 52.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.7ms\n",
            "Speed: 2.5ms preprocess, 51.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.1ms\n",
            "Speed: 2.7ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.4ms\n",
            "Speed: 2.6ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.4ms\n",
            "Speed: 2.7ms preprocess, 51.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.7ms\n",
            "Speed: 2.5ms preprocess, 51.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 57.4ms\n",
            "Speed: 2.9ms preprocess, 57.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.6ms preprocess, 50.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.3ms\n",
            "Speed: 2.6ms preprocess, 56.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.5ms\n",
            "Speed: 2.7ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.9ms\n",
            "Speed: 2.6ms preprocess, 50.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.7ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.9ms\n",
            "Speed: 2.6ms preprocess, 50.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.5ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.7ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.5ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.7ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 2.6ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 51.6ms\n",
            "Speed: 2.6ms preprocess, 51.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 51.3ms\n",
            "Speed: 2.8ms preprocess, 51.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.8ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.6ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.6ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.4ms\n",
            "Speed: 2.8ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 3.0ms preprocess, 50.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 59.0ms\n",
            "Speed: 3.2ms preprocess, 59.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.7ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.3ms\n",
            "Speed: 2.8ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.1ms\n",
            "Speed: 2.6ms preprocess, 52.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 53.0ms\n",
            "Speed: 2.6ms preprocess, 53.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.6ms\n",
            "Speed: 2.7ms preprocess, 45.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.2ms\n",
            "Speed: 2.6ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.2ms\n",
            "Speed: 2.8ms preprocess, 45.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.4ms\n",
            "Speed: 2.7ms preprocess, 51.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.7ms\n",
            "Speed: 2.7ms preprocess, 52.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.7ms\n",
            "Speed: 2.7ms preprocess, 52.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.5ms\n",
            "Speed: 2.7ms preprocess, 52.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.4ms\n",
            "Speed: 2.9ms preprocess, 52.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 2.6ms preprocess, 51.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.6ms preprocess, 52.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.7ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.9ms\n",
            "Speed: 3.0ms preprocess, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.9ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.8ms\n",
            "Speed: 3.1ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 3.4ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 3.3ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.8ms\n",
            "Speed: 3.0ms preprocess, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.6ms\n",
            "Speed: 2.9ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.7ms\n",
            "Speed: 2.9ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.3ms\n",
            "Speed: 3.2ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.2ms\n",
            "Speed: 3.4ms preprocess, 47.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.4ms\n",
            "Speed: 3.2ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 3.2ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.3ms\n",
            "Speed: 3.2ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.7ms\n",
            "Speed: 3.0ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.2ms\n",
            "Speed: 2.9ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 2.9ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 2.9ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.3ms\n",
            "Speed: 2.8ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 3.1ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.7ms\n",
            "Speed: 2.9ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.8ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.8ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 2.6ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.4ms\n",
            "Speed: 3.3ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.6ms\n",
            "Speed: 2.5ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.5ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.5ms\n",
            "Speed: 2.4ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.5ms\n",
            "Speed: 2.6ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.6ms\n",
            "Speed: 2.5ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.3ms\n",
            "Speed: 2.5ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 2.5ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.6ms\n",
            "Speed: 2.5ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.8ms\n",
            "Speed: 2.5ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.8ms\n",
            "Speed: 2.5ms preprocess, 44.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.9ms\n",
            "Speed: 2.6ms preprocess, 51.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.3ms\n",
            "Speed: 2.8ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.8ms\n",
            "Speed: 2.5ms preprocess, 43.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.6ms\n",
            "Speed: 2.5ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 2 tumors, 42.7ms\n",
            "Speed: 2.6ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.7ms\n",
            "Speed: 2.5ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.2ms\n",
            "Speed: 2.6ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 42.7ms\n",
            "Speed: 2.5ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.4ms\n",
            "Speed: 2.6ms preprocess, 42.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.5ms\n",
            "Speed: 2.7ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 44.0ms\n",
            "Speed: 2.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 43.9ms\n",
            "Speed: 2.4ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.5ms\n",
            "Speed: 2.5ms preprocess, 54.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.8ms\n",
            "Speed: 2.8ms preprocess, 52.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.9ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.7ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.8ms preprocess, 52.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.9ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 3.0ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.8ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.8ms\n",
            "Speed: 3.0ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.7ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.9ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.4ms\n",
            "Speed: 2.7ms preprocess, 45.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.8ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.5ms\n",
            "Speed: 2.8ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.8ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.7ms\n",
            "Speed: 2.7ms preprocess, 45.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.9ms\n",
            "Speed: 2.7ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 2.8ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 2.9ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.7ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 3.0ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.0ms\n",
            "Speed: 2.7ms preprocess, 45.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.0ms\n",
            "Speed: 3.0ms preprocess, 46.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.8ms\n",
            "Speed: 3.0ms preprocess, 44.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.7ms\n",
            "Speed: 3.1ms preprocess, 45.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.0ms\n",
            "Speed: 2.9ms preprocess, 46.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.6ms\n",
            "Speed: 4.4ms preprocess, 46.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 3.4ms preprocess, 50.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.5ms\n",
            "Speed: 2.8ms preprocess, 45.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 48.3ms\n",
            "Speed: 3.6ms preprocess, 48.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.9ms\n",
            "Speed: 2.8ms preprocess, 45.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.4ms\n",
            "Speed: 2.7ms preprocess, 44.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.3ms\n",
            "Speed: 2.7ms preprocess, 45.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.6ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.3ms\n",
            "Speed: 2.8ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.4ms\n",
            "Speed: 2.9ms preprocess, 45.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.5ms\n",
            "Speed: 2.8ms preprocess, 45.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.9ms\n",
            "Speed: 2.8ms preprocess, 45.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.6ms\n",
            "Speed: 3.1ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.7ms\n",
            "Speed: 2.7ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.9ms\n",
            "Speed: 2.7ms preprocess, 45.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.6ms\n",
            "Speed: 2.8ms preprocess, 45.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 3.1ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.9ms\n",
            "Speed: 3.1ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.9ms\n",
            "Speed: 2.9ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.9ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.8ms preprocess, 45.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.8ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.7ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.7ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 3.0ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.8ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.6ms preprocess, 46.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.6ms\n",
            "Speed: 2.7ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.9ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.9ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 3.0ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 3.1ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.8ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.9ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.9ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.7ms\n",
            "Speed: 2.7ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.7ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 2.9ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.7ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 2.8ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.9ms\n",
            "Speed: 3.0ms preprocess, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 3.0ms preprocess, 45.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.9ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.2ms\n",
            "Speed: 2.9ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.2ms\n",
            "Speed: 2.8ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 2.9ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 2.9ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.1ms\n",
            "Speed: 3.0ms preprocess, 52.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.6ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.7ms\n",
            "Speed: 2.7ms preprocess, 52.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.1ms\n",
            "Speed: 2.7ms preprocess, 52.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.0ms\n",
            "Speed: 2.7ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.8ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 2.7ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 2.9ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.3ms\n",
            "Speed: 2.8ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.2ms\n",
            "Speed: 2.7ms preprocess, 46.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.6ms\n",
            "Speed: 2.9ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.3ms\n",
            "Speed: 2.6ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 2.8ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 2.7ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.1ms\n",
            "Speed: 3.1ms preprocess, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.1ms\n",
            "Speed: 3.1ms preprocess, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.2ms\n",
            "Speed: 3.4ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.9ms\n",
            "Speed: 3.2ms preprocess, 55.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.2ms\n",
            "Speed: 3.0ms preprocess, 54.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.0ms\n",
            "Speed: 3.0ms preprocess, 55.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.9ms\n",
            "Speed: 3.2ms preprocess, 53.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.0ms\n",
            "Speed: 3.0ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.8ms\n",
            "Speed: 2.9ms preprocess, 54.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.0ms\n",
            "Speed: 2.9ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.5ms\n",
            "Speed: 2.8ms preprocess, 56.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.2ms\n",
            "Speed: 2.9ms preprocess, 55.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.4ms\n",
            "Speed: 2.9ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.5ms\n",
            "Speed: 2.9ms preprocess, 55.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.6ms\n",
            "Speed: 3.0ms preprocess, 54.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.0ms\n",
            "Speed: 3.1ms preprocess, 54.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.3ms\n",
            "Speed: 3.0ms preprocess, 56.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.7ms\n",
            "Speed: 3.2ms preprocess, 54.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.7ms\n",
            "Speed: 3.0ms preprocess, 54.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.7ms\n",
            "Speed: 3.0ms preprocess, 54.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.8ms\n",
            "Speed: 3.0ms preprocess, 53.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.5ms\n",
            "Speed: 3.0ms preprocess, 53.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.8ms\n",
            "Speed: 3.1ms preprocess, 54.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.0ms\n",
            "Speed: 3.0ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.6ms\n",
            "Speed: 2.9ms preprocess, 53.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.4ms\n",
            "Speed: 2.9ms preprocess, 54.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.7ms\n",
            "Speed: 2.8ms preprocess, 53.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.7ms\n",
            "Speed: 3.0ms preprocess, 55.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.8ms\n",
            "Speed: 3.0ms preprocess, 56.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.4ms\n",
            "Speed: 3.0ms preprocess, 55.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.7ms\n",
            "Speed: 2.9ms preprocess, 55.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 55.1ms\n",
            "Speed: 3.2ms preprocess, 55.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.4ms\n",
            "Speed: 2.9ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 55.2ms\n",
            "Speed: 2.9ms preprocess, 55.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.1ms\n",
            "Speed: 2.9ms preprocess, 55.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 54.6ms\n",
            "Speed: 2.9ms preprocess, 54.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.2ms\n",
            "Speed: 2.8ms preprocess, 55.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 53.8ms\n",
            "Speed: 3.0ms preprocess, 53.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.2ms\n",
            "Speed: 3.0ms preprocess, 54.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 54.0ms\n",
            "Speed: 2.9ms preprocess, 54.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.1ms\n",
            "Speed: 3.0ms preprocess, 54.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 55.7ms\n",
            "Speed: 3.0ms preprocess, 55.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 55.3ms\n",
            "Speed: 3.2ms preprocess, 55.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 59.2ms\n",
            "Speed: 3.2ms preprocess, 59.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 53.8ms\n",
            "Speed: 3.2ms preprocess, 53.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 53.8ms\n",
            "Speed: 2.8ms preprocess, 53.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 54.8ms\n",
            "Speed: 3.0ms preprocess, 54.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 54.1ms\n",
            "Speed: 2.9ms preprocess, 54.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 55.0ms\n",
            "Speed: 3.0ms preprocess, 55.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.8ms\n",
            "Speed: 3.2ms preprocess, 54.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 55.9ms\n",
            "Speed: 3.0ms preprocess, 55.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 55.1ms\n",
            "Speed: 3.1ms preprocess, 55.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.8ms\n",
            "Speed: 2.9ms preprocess, 54.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 54.7ms\n",
            "Speed: 2.9ms preprocess, 54.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 54.1ms\n",
            "Speed: 3.0ms preprocess, 54.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.3ms\n",
            "Speed: 2.9ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 55.0ms\n",
            "Speed: 2.8ms preprocess, 55.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.1ms\n",
            "Speed: 3.4ms preprocess, 56.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 58.0ms\n",
            "Speed: 3.2ms preprocess, 58.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.6ms\n",
            "Speed: 2.9ms preprocess, 54.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.5ms\n",
            "Speed: 3.0ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.3ms\n",
            "Speed: 2.9ms preprocess, 54.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.4ms\n",
            "Speed: 2.9ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.1ms\n",
            "Speed: 2.9ms preprocess, 54.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 59.1ms\n",
            "Speed: 2.9ms preprocess, 59.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 58.1ms\n",
            "Speed: 3.0ms preprocess, 58.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.8ms\n",
            "Speed: 3.0ms preprocess, 54.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.5ms\n",
            "Speed: 3.1ms preprocess, 54.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.9ms\n",
            "Speed: 3.1ms preprocess, 54.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.6ms\n",
            "Speed: 2.9ms preprocess, 54.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.7ms\n",
            "Speed: 2.9ms preprocess, 54.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.1ms\n",
            "Speed: 2.9ms preprocess, 55.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.9ms\n",
            "Speed: 3.0ms preprocess, 53.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.8ms\n",
            "Speed: 3.0ms preprocess, 54.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.3ms\n",
            "Speed: 2.9ms preprocess, 54.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.6ms\n",
            "Speed: 2.9ms preprocess, 54.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.9ms\n",
            "Speed: 3.1ms preprocess, 54.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.4ms\n",
            "Speed: 3.1ms preprocess, 55.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.4ms\n",
            "Speed: 3.0ms preprocess, 54.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.0ms\n",
            "Speed: 3.1ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.0ms\n",
            "Speed: 2.8ms preprocess, 56.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.9ms\n",
            "Speed: 2.9ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.8ms\n",
            "Speed: 2.8ms preprocess, 56.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.1ms\n",
            "Speed: 3.0ms preprocess, 55.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.9ms\n",
            "Speed: 2.8ms preprocess, 54.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.1ms\n",
            "Speed: 3.1ms preprocess, 54.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.5ms\n",
            "Speed: 3.2ms preprocess, 56.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.8ms\n",
            "Speed: 3.0ms preprocess, 53.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 55.1ms\n",
            "Speed: 2.9ms preprocess, 55.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.5ms\n",
            "Speed: 2.8ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.6ms\n",
            "Speed: 2.9ms preprocess, 56.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.2ms\n",
            "Speed: 3.0ms preprocess, 53.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.9ms\n",
            "Speed: 2.9ms preprocess, 53.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.1ms\n",
            "Speed: 3.0ms preprocess, 54.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.0ms\n",
            "Speed: 2.8ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.0ms\n",
            "Speed: 3.1ms preprocess, 55.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.2ms\n",
            "Speed: 3.0ms preprocess, 56.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.8ms\n",
            "Speed: 2.9ms preprocess, 54.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.4ms\n",
            "Speed: 2.9ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.9ms\n",
            "Speed: 3.3ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.8ms\n",
            "Speed: 3.0ms preprocess, 47.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 3.2ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.3ms\n",
            "Speed: 3.0ms preprocess, 49.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.9ms\n",
            "Speed: 3.1ms preprocess, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.0ms\n",
            "Speed: 2.7ms preprocess, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 2.7ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.9ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.8ms\n",
            "Speed: 2.8ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 2.8ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.9ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.7ms preprocess, 44.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.8ms preprocess, 44.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 3.0ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.9ms\n",
            "Speed: 2.8ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 46.3ms\n",
            "Speed: 2.7ms preprocess, 46.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 52.4ms\n",
            "Speed: 2.8ms preprocess, 52.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 48.7ms\n",
            "Speed: 2.6ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.5ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.3ms\n",
            "Speed: 2.4ms preprocess, 51.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.5ms preprocess, 50.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.5ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.6ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.4ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.5ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.8ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 44.1ms\n",
            "Speed: 2.6ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.6ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.9ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.8ms\n",
            "Speed: 2.8ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.9ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.2ms\n",
            "Speed: 2.8ms preprocess, 55.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.7ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.9ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.8ms preprocess, 50.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.7ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.8ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.7ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.9ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.9ms preprocess, 50.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.9ms\n",
            "Speed: 2.9ms preprocess, 50.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 50.5ms\n",
            "Speed: 2.9ms preprocess, 50.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.3ms\n",
            "Speed: 2.9ms preprocess, 50.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.7ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.1ms\n",
            "Speed: 2.8ms preprocess, 50.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 50.1ms\n",
            "Speed: 2.8ms preprocess, 50.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 49.8ms\n",
            "Speed: 2.7ms preprocess, 49.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 51.0ms\n",
            "Speed: 2.9ms preprocess, 51.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.8ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.3ms\n",
            "Speed: 2.7ms preprocess, 51.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.8ms preprocess, 51.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.8ms preprocess, 50.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.9ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 3.0ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.6ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.8ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.6ms\n",
            "Speed: 2.8ms preprocess, 46.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.9ms\n",
            "Speed: 2.9ms preprocess, 55.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.9ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.3ms\n",
            "Speed: 2.7ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.8ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.6ms preprocess, 50.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 3.0ms preprocess, 50.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.1ms\n",
            "Speed: 2.8ms preprocess, 52.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.8ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.1ms\n",
            "Speed: 2.9ms preprocess, 52.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.2ms\n",
            "Speed: 2.7ms preprocess, 53.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.3ms\n",
            "Speed: 2.9ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.2ms\n",
            "Speed: 2.8ms preprocess, 51.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.0ms\n",
            "Speed: 2.7ms preprocess, 52.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.4ms\n",
            "Speed: 2.7ms preprocess, 52.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.2ms\n",
            "Speed: 2.7ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.2ms\n",
            "Speed: 3.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.0ms\n",
            "Speed: 2.9ms preprocess, 46.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.7ms\n",
            "Speed: 2.7ms preprocess, 46.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.9ms\n",
            "Speed: 2.7ms preprocess, 45.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.9ms\n",
            "Speed: 2.5ms preprocess, 44.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.8ms\n",
            "Speed: 2.9ms preprocess, 50.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.2ms\n",
            "Speed: 2.7ms preprocess, 50.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.5ms\n",
            "Speed: 2.6ms preprocess, 54.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.3ms\n",
            "Speed: 2.6ms preprocess, 44.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.9ms\n",
            "Speed: 2.5ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.4ms\n",
            "Speed: 2.7ms preprocess, 43.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.7ms\n",
            "Speed: 2.6ms preprocess, 45.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.3ms\n",
            "Speed: 2.7ms preprocess, 46.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.4ms\n",
            "Speed: 2.6ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.5ms\n",
            "Speed: 2.6ms preprocess, 44.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.9ms\n",
            "Speed: 2.5ms preprocess, 43.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.6ms\n",
            "Speed: 2.9ms preprocess, 50.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.5ms\n",
            "Speed: 2.7ms preprocess, 50.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.2ms\n",
            "Speed: 3.0ms preprocess, 52.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.2ms\n",
            "Speed: 3.1ms preprocess, 51.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.5ms\n",
            "Speed: 2.8ms preprocess, 50.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.6ms\n",
            "Speed: 2.7ms preprocess, 50.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.7ms\n",
            "Speed: 2.7ms preprocess, 50.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.3ms\n",
            "Speed: 2.7ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.9ms\n",
            "Speed: 2.8ms preprocess, 51.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.1ms\n",
            "Speed: 2.9ms preprocess, 46.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 47.1ms\n",
            "Speed: 3.0ms preprocess, 47.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.6ms\n",
            "Speed: 2.8ms preprocess, 52.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.9ms\n",
            "Speed: 2.8ms preprocess, 53.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.8ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.8ms\n",
            "Speed: 2.8ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 48.4ms\n",
            "Speed: 2.6ms preprocess, 48.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.5ms\n",
            "Speed: 2.4ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.1ms\n",
            "Speed: 2.5ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 42.5ms\n",
            "Speed: 2.6ms preprocess, 42.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.8ms\n",
            "Speed: 2.6ms preprocess, 50.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.0ms\n",
            "Speed: 2.6ms preprocess, 51.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.9ms\n",
            "Speed: 2.7ms preprocess, 51.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 47.0ms\n",
            "Speed: 2.7ms preprocess, 47.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.0ms\n",
            "Speed: 2.7ms preprocess, 46.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.4ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 2.8ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 43.0ms\n",
            "Speed: 2.6ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.6ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.5ms\n",
            "Speed: 2.8ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 43.3ms\n",
            "Speed: 2.8ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 43.0ms\n",
            "Speed: 2.9ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.5ms\n",
            "Speed: 2.8ms preprocess, 51.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.9ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.8ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.8ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.9ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 3.1ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.8ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 3.1ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 3.1ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.6ms\n",
            "Speed: 2.8ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.7ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 2.7ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.8ms preprocess, 51.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.0ms\n",
            "Speed: 2.8ms preprocess, 52.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.6ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.7ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.6ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.6ms preprocess, 50.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.9ms\n",
            "Speed: 2.7ms preprocess, 44.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 2.5ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.6ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.0ms\n",
            "Speed: 2.9ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.5ms\n",
            "Speed: 3.0ms preprocess, 46.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.7ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.9ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.0ms\n",
            "Speed: 2.8ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.0ms\n",
            "Speed: 2.9ms preprocess, 56.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.4ms\n",
            "Speed: 2.7ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.9ms\n",
            "Speed: 3.0ms preprocess, 52.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 3.0ms preprocess, 50.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.9ms\n",
            "Speed: 2.9ms preprocess, 50.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.5ms\n",
            "Speed: 3.1ms preprocess, 53.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.8ms\n",
            "Speed: 2.7ms preprocess, 52.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.5ms\n",
            "Speed: 2.9ms preprocess, 54.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.2ms\n",
            "Speed: 2.7ms preprocess, 53.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.5ms\n",
            "Speed: 2.8ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.5ms\n",
            "Speed: 3.0ms preprocess, 53.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 2.9ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 59.0ms\n",
            "Speed: 3.0ms preprocess, 59.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 48.2ms\n",
            "Speed: 3.0ms preprocess, 48.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 53.6ms\n",
            "Speed: 3.0ms preprocess, 53.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 2.8ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.5ms\n",
            "Speed: 2.7ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.8ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.8ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.8ms\n",
            "Speed: 2.8ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.7ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 3.0ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 3.0ms preprocess, 52.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 2.7ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 3.0ms preprocess, 51.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 2.8ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.9ms preprocess, 51.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 3.0ms preprocess, 52.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.8ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.8ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.9ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.7ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 3.0ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.8ms preprocess, 51.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.3ms\n",
            "Speed: 2.7ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.6ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.7ms preprocess, 43.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.7ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 43.2ms\n",
            "Speed: 3.2ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.1ms\n",
            "Speed: 3.1ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 52.1ms\n",
            "Speed: 2.9ms preprocess, 52.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.1ms\n",
            "Speed: 2.8ms preprocess, 52.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.1ms\n",
            "Speed: 2.8ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.6ms\n",
            "Speed: 2.7ms preprocess, 51.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.1ms\n",
            "Speed: 2.8ms preprocess, 52.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.9ms\n",
            "Speed: 2.7ms preprocess, 51.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.9ms\n",
            "Speed: 2.8ms preprocess, 51.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.8ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.0ms\n",
            "Speed: 2.8ms preprocess, 52.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.0ms\n",
            "Speed: 2.7ms preprocess, 43.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.8ms\n",
            "Speed: 2.6ms preprocess, 50.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.8ms\n",
            "Speed: 2.5ms preprocess, 50.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 2.5ms preprocess, 50.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.4ms\n",
            "Speed: 2.7ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.2ms\n",
            "Speed: 2.6ms preprocess, 51.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.4ms\n",
            "Speed: 2.5ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.4ms\n",
            "Speed: 2.5ms preprocess, 51.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.7ms\n",
            "Speed: 2.7ms preprocess, 50.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.6ms\n",
            "Speed: 2.5ms preprocess, 50.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.5ms\n",
            "Speed: 2.6ms preprocess, 52.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.7ms\n",
            "Speed: 2.7ms preprocess, 50.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.7ms\n",
            "Speed: 2.4ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.0ms\n",
            "Speed: 2.6ms preprocess, 44.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 43.2ms\n",
            "Speed: 2.8ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.1ms\n",
            "Speed: 2.7ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 56.9ms\n",
            "Speed: 2.7ms preprocess, 56.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.7ms\n",
            "Speed: 2.6ms preprocess, 51.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.5ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.5ms\n",
            "Speed: 2.7ms preprocess, 50.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.6ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.5ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.1ms\n",
            "Speed: 2.8ms preprocess, 47.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.8ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.6ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.7ms preprocess, 44.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.5ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.7ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 2.8ms preprocess, 45.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.9ms\n",
            "Speed: 2.5ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.8ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.7ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.6ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.7ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.5ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.5ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.5ms\n",
            "Speed: 2.6ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 2.6ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.8ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 2.5ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.2ms\n",
            "Speed: 2.6ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.6ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.5ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.5ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.5ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.8ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.6ms\n",
            "Speed: 2.5ms preprocess, 47.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.7ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.7ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.6ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.5ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.6ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.5ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.8ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.7ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.6ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.5ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.7ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.5ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.4ms preprocess, 43.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 2.5ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.5ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 4.3ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.5ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.3ms\n",
            "Speed: 2.7ms preprocess, 47.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.6ms\n",
            "Speed: 2.6ms preprocess, 42.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.6ms\n",
            "Speed: 2.5ms preprocess, 43.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.8ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.9ms\n",
            "Speed: 2.7ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 2.6ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 3.0ms preprocess, 51.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.8ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.9ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.8ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.8ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.3ms\n",
            "Speed: 2.7ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.1ms\n",
            "Speed: 2.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.5ms\n",
            "Speed: 2.6ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.6ms\n",
            "Speed: 2.7ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.5ms\n",
            "Speed: 2.5ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.0ms\n",
            "Speed: 2.9ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.1ms\n",
            "Speed: 2.5ms preprocess, 50.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.1ms\n",
            "Speed: 2.8ms preprocess, 50.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.5ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.7ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.7ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.6ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.9ms\n",
            "Speed: 2.6ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.0ms\n",
            "Speed: 2.9ms preprocess, 56.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.7ms\n",
            "Speed: 2.9ms preprocess, 52.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.8ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.6ms\n",
            "Speed: 2.7ms preprocess, 52.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.8ms\n",
            "Speed: 2.7ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.9ms\n",
            "Speed: 2.8ms preprocess, 51.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.3ms\n",
            "Speed: 2.8ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.6ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.5ms\n",
            "Speed: 2.9ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.6ms\n",
            "Speed: 2.6ms preprocess, 42.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.5ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.6ms\n",
            "Speed: 2.6ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.7ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.8ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.6ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.7ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.6ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.6ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.0ms\n",
            "Speed: 2.9ms preprocess, 53.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.0ms\n",
            "Speed: 2.7ms preprocess, 52.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.4ms\n",
            "Speed: 2.7ms preprocess, 51.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.0ms\n",
            "Speed: 2.7ms preprocess, 53.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.1ms\n",
            "Speed: 2.8ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 44.9ms\n",
            "Speed: 2.7ms preprocess, 44.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.2ms\n",
            "Speed: 4.2ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.4ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.5ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.8ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.6ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.8ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.7ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.6ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 2.8ms preprocess, 44.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.6ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.5ms\n",
            "Speed: 2.9ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 2.7ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.3ms\n",
            "Speed: 2.6ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.9ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.7ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.4ms\n",
            "Speed: 2.5ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.7ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.8ms\n",
            "Speed: 2.7ms preprocess, 51.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 50.6ms\n",
            "Speed: 2.8ms preprocess, 50.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.1ms\n",
            "Speed: 2.7ms preprocess, 50.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 2.6ms preprocess, 50.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 55.3ms\n",
            "Speed: 2.6ms preprocess, 55.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.0ms\n",
            "Speed: 2.6ms preprocess, 50.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.8ms\n",
            "Speed: 2.6ms preprocess, 50.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.5ms\n",
            "Speed: 2.7ms preprocess, 50.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 51.4ms\n",
            "Speed: 2.6ms preprocess, 51.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 50.5ms\n",
            "Speed: 2.5ms preprocess, 50.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 49.8ms\n",
            "Speed: 2.6ms preprocess, 49.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.4ms\n",
            "Speed: 2.7ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.5ms\n",
            "Speed: 2.6ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.6ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.6ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.7ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.5ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.6ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.7ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.5ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 44.0ms\n",
            "Speed: 2.5ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 2.6ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.9ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.6ms\n",
            "Speed: 2.5ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.6ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.8ms preprocess, 51.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.1ms\n",
            "Speed: 2.9ms preprocess, 53.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.4ms\n",
            "Speed: 2.8ms preprocess, 48.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.7ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.5ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.9ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 2.8ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 3.1ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.9ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.8ms preprocess, 50.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.6ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.9ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.7ms preprocess, 51.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.3ms\n",
            "Speed: 2.8ms preprocess, 51.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.8ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.9ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.8ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.8ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.9ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 2.8ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.9ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.8ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.8ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.7ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.7ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 2.9ms preprocess, 45.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.8ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.8ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.7ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.6ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.8ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.8ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 3.0ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.4ms\n",
            "Speed: 2.8ms preprocess, 50.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.7ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 50.7ms\n",
            "Speed: 2.9ms preprocess, 50.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.6ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.8ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.7ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.9ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.9ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.5ms\n",
            "Speed: 2.9ms preprocess, 50.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 2.7ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 2.8ms preprocess, 51.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 3.0ms preprocess, 50.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 52.1ms\n",
            "Speed: 2.7ms preprocess, 52.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.0ms\n",
            "Speed: 2.8ms preprocess, 50.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 2.7ms preprocess, 50.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.0ms\n",
            "Speed: 2.7ms preprocess, 52.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.0ms\n",
            "Speed: 2.7ms preprocess, 51.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.6ms\n",
            "Speed: 3.0ms preprocess, 53.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.0ms\n",
            "Speed: 2.7ms preprocess, 51.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.5ms\n",
            "Speed: 2.9ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.5ms\n",
            "Speed: 2.7ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.6ms\n",
            "Speed: 2.8ms preprocess, 51.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.8ms\n",
            "Speed: 3.0ms preprocess, 51.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.9ms preprocess, 52.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.2ms\n",
            "Speed: 2.7ms preprocess, 50.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.9ms\n",
            "Speed: 2.8ms preprocess, 50.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.5ms\n",
            "Speed: 2.9ms preprocess, 50.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 48.7ms\n",
            "Speed: 2.7ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.5ms\n",
            "Speed: 2.7ms preprocess, 43.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.5ms\n",
            "Speed: 2.9ms preprocess, 46.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.1ms\n",
            "Speed: 2.8ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.5ms\n",
            "Speed: 2.8ms preprocess, 43.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.2ms\n",
            "Speed: 3.1ms preprocess, 44.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.8ms preprocess, 44.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.8ms\n",
            "Speed: 3.1ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.6ms\n",
            "Speed: 3.1ms preprocess, 45.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.9ms\n",
            "Speed: 2.8ms preprocess, 44.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.3ms\n",
            "Speed: 2.8ms preprocess, 45.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.3ms\n",
            "Speed: 3.1ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.7ms\n",
            "Speed: 2.7ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.3ms\n",
            "Speed: 2.8ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.2ms\n",
            "Speed: 2.8ms preprocess, 45.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.8ms\n",
            "Speed: 2.7ms preprocess, 43.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.5ms\n",
            "Speed: 3.0ms preprocess, 44.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.5ms\n",
            "Speed: 2.7ms preprocess, 44.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.7ms\n",
            "Speed: 2.7ms preprocess, 46.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.2ms\n",
            "Speed: 2.7ms preprocess, 44.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.1ms\n",
            "Speed: 2.7ms preprocess, 44.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.7ms\n",
            "Speed: 2.8ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.9ms\n",
            "Speed: 2.7ms preprocess, 51.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.3ms\n",
            "Speed: 2.6ms preprocess, 53.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.1ms\n",
            "Speed: 3.1ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.3ms\n",
            "Speed: 2.7ms preprocess, 50.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 3.0ms preprocess, 51.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.7ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.3ms\n",
            "Speed: 2.9ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.8ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.9ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.7ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.9ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.4ms\n",
            "Speed: 2.7ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 2.7ms preprocess, 46.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.7ms preprocess, 43.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 3.0ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 3.0ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 2.8ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.5ms\n",
            "Speed: 2.7ms preprocess, 46.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 56.3ms\n",
            "Speed: 2.7ms preprocess, 56.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.7ms preprocess, 49.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 2.8ms preprocess, 45.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.4ms\n",
            "Speed: 3.4ms preprocess, 46.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 2.7ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.8ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.7ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 2.7ms preprocess, 44.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.9ms\n",
            "Speed: 3.0ms preprocess, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 3.0ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 3.1ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 3.0ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 3.2ms preprocess, 45.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 3.0ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 3.0ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.3ms\n",
            "Speed: 2.9ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.9ms preprocess, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 3.2ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.6ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 45.8ms\n",
            "Speed: 2.7ms preprocess, 45.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.7ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.9ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.7ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.8ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.6ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.9ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.3ms\n",
            "Speed: 2.9ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.4ms\n",
            "Speed: 3.7ms preprocess, 51.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 47.2ms\n",
            "Speed: 2.7ms preprocess, 47.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 53.0ms\n",
            "Speed: 9.4ms preprocess, 53.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 3.0ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.0ms\n",
            "Speed: 3.1ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.8ms\n",
            "Speed: 3.0ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.1ms\n",
            "Speed: 2.9ms preprocess, 53.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.6ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.6ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.8ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.5ms\n",
            "Speed: 2.7ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.5ms\n",
            "Speed: 2.8ms preprocess, 51.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 2.6ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.5ms\n",
            "Speed: 2.7ms preprocess, 50.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.3ms\n",
            "Speed: 2.8ms preprocess, 51.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.1ms\n",
            "Speed: 2.8ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.3ms\n",
            "Speed: 2.6ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 2.6ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.8ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.5ms\n",
            "Speed: 2.7ms preprocess, 49.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.6ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.6ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.8ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.7ms\n",
            "Speed: 2.7ms preprocess, 47.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.9ms\n",
            "Speed: 2.6ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.8ms preprocess, 50.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.7ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.6ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.7ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.5ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.7ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.8ms\n",
            "Speed: 2.5ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.8ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.5ms\n",
            "Speed: 2.7ms preprocess, 45.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.7ms\n",
            "Speed: 2.8ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 47.3ms\n",
            "Speed: 2.5ms preprocess, 47.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.9ms\n",
            "Speed: 2.8ms preprocess, 45.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.6ms\n",
            "Speed: 2.6ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.0ms\n",
            "Speed: 2.7ms preprocess, 43.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 47.2ms\n",
            "Speed: 2.6ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.5ms\n",
            "Speed: 2.5ms preprocess, 43.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.7ms\n",
            "Speed: 2.5ms preprocess, 43.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.6ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.5ms\n",
            "Speed: 2.7ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.2ms\n",
            "Speed: 2.7ms preprocess, 43.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.4ms\n",
            "Speed: 2.8ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.8ms\n",
            "Speed: 2.6ms preprocess, 43.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.2ms\n",
            "Speed: 2.7ms preprocess, 44.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.7ms\n",
            "Speed: 2.7ms preprocess, 45.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 49.5ms\n",
            "Speed: 3.6ms preprocess, 49.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.6ms\n",
            "Speed: 2.7ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.6ms\n",
            "Speed: 2.8ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.5ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.8ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.6ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.7ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.7ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.8ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 3.0ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.6ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.7ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.6ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.6ms\n",
            "Speed: 2.8ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.6ms\n",
            "Speed: 2.9ms preprocess, 48.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.9ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.6ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.8ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.5ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.9ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.7ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.6ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.9ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.7ms\n",
            "Speed: 2.5ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.6ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.9ms\n",
            "Speed: 2.6ms preprocess, 42.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 3.6ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.6ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.7ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.8ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.9ms\n",
            "Speed: 2.6ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.6ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.8ms\n",
            "Speed: 2.5ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.8ms\n",
            "Speed: 2.7ms preprocess, 55.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 50.6ms\n",
            "Speed: 2.8ms preprocess, 50.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.6ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.6ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.7ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.7ms\n",
            "Speed: 2.6ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.5ms\n",
            "Speed: 2.6ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.6ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.7ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.6ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.5ms\n",
            "Speed: 2.6ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.9ms\n",
            "Speed: 2.6ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.8ms\n",
            "Speed: 2.7ms preprocess, 48.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.7ms\n",
            "Speed: 2.8ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.7ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.7ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.8ms\n",
            "Speed: 2.8ms preprocess, 51.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.7ms\n",
            "Speed: 2.6ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.6ms\n",
            "Speed: 2.6ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 48.1ms\n",
            "Speed: 2.8ms preprocess, 48.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.4ms\n",
            "Speed: 2.9ms preprocess, 54.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 53.2ms\n",
            "Speed: 2.7ms preprocess, 53.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 54.0ms\n",
            "Speed: 2.7ms preprocess, 54.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.7ms\n",
            "Speed: 2.7ms preprocess, 53.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 2.8ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 2.7ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.0ms\n",
            "Speed: 2.8ms preprocess, 55.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.0ms\n",
            "Speed: 2.7ms preprocess, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.8ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 3.8ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.8ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.7ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 42.6ms\n",
            "Speed: 2.8ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.6ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.6ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.2ms\n",
            "Speed: 2.6ms preprocess, 42.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.3ms\n",
            "Speed: 2.8ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 2.5ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.4ms\n",
            "Speed: 2.6ms preprocess, 42.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.8ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.5ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 58.1ms\n",
            "Speed: 2.7ms preprocess, 58.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 2.7ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.6ms preprocess, 45.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.7ms preprocess, 51.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.7ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 2.7ms preprocess, 51.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.7ms preprocess, 50.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.7ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.5ms\n",
            "Speed: 2.7ms preprocess, 50.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.4ms\n",
            "Speed: 2.7ms preprocess, 50.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.6ms\n",
            "Speed: 2.7ms preprocess, 50.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 51.3ms\n",
            "Speed: 2.6ms preprocess, 51.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 2 tumors, 51.0ms\n",
            "Speed: 2.5ms preprocess, 51.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 2.7ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 46.7ms\n",
            "Speed: 2.6ms preprocess, 46.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.6ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.6ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.8ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 44.0ms\n",
            "Speed: 2.7ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.0ms\n",
            "Speed: 2.6ms preprocess, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.6ms\n",
            "Speed: 2.6ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.3ms\n",
            "Speed: 2.7ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.7ms\n",
            "Speed: 3.3ms preprocess, 52.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.4ms\n",
            "Speed: 3.7ms preprocess, 53.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.6ms preprocess, 51.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.0ms\n",
            "Speed: 3.3ms preprocess, 53.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.4ms\n",
            "Speed: 3.5ms preprocess, 54.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.7ms\n",
            "Speed: 3.4ms preprocess, 54.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.6ms\n",
            "Speed: 3.2ms preprocess, 53.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.6ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.6ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.4ms\n",
            "Speed: 2.5ms preprocess, 49.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.7ms\n",
            "Speed: 2.5ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.6ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.6ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.9ms\n",
            "Speed: 2.6ms preprocess, 47.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.6ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.8ms\n",
            "Speed: 2.5ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.3ms\n",
            "Speed: 2.7ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.6ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.8ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.1ms\n",
            "Speed: 2.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.1ms\n",
            "Speed: 2.7ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 48.6ms\n",
            "Speed: 2.6ms preprocess, 48.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 47.3ms\n",
            "Speed: 2.6ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 46.7ms\n",
            "Speed: 2.5ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.0ms\n",
            "Speed: 2.6ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.1ms\n",
            "Speed: 2.5ms preprocess, 44.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.4ms\n",
            "Speed: 2.5ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 44.4ms\n",
            "Speed: 2.6ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 49.3ms\n",
            "Speed: 2.6ms preprocess, 49.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.9ms\n",
            "Speed: 2.8ms preprocess, 50.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.3ms\n",
            "Speed: 2.8ms preprocess, 50.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 49.2ms\n",
            "Speed: 2.6ms preprocess, 49.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 42.9ms\n",
            "Speed: 2.7ms preprocess, 42.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.5ms\n",
            "Speed: 2.8ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.8ms\n",
            "Speed: 2.7ms preprocess, 43.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.6ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.6ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 44.6ms\n",
            "Speed: 2.9ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 45.2ms\n",
            "Speed: 2.7ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 45.4ms\n",
            "Speed: 2.7ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 44.5ms\n",
            "Speed: 2.9ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.9ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.4ms\n",
            "Speed: 2.8ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.8ms\n",
            "Speed: 2.7ms preprocess, 54.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.1ms\n",
            "Speed: 2.5ms preprocess, 52.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 44.2ms\n",
            "Speed: 2.7ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 2.7ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.6ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.8ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.6ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.8ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.7ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 2.5ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.9ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 43.9ms\n",
            "Speed: 3.6ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 42.6ms\n",
            "Speed: 2.7ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 2.7ms preprocess, 51.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 53.7ms\n",
            "Speed: 2.8ms preprocess, 53.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.4ms\n",
            "Speed: 2.8ms preprocess, 46.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.7ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.2ms\n",
            "Speed: 2.6ms preprocess, 47.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.3ms\n",
            "Speed: 3.3ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.6ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.7ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.8ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.8ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.6ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.8ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.5ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.8ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.6ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.8ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.7ms preprocess, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.9ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.8ms\n",
            "Speed: 2.6ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.6ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 2.6ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.2ms\n",
            "Speed: 2.7ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.7ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.5ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.6ms\n",
            "Speed: 2.7ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.8ms\n",
            "Speed: 2.5ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.8ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.7ms preprocess, 45.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.7ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.9ms\n",
            "Speed: 2.6ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.8ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.8ms\n",
            "Speed: 2.6ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.6ms\n",
            "Speed: 2.8ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 42.7ms\n",
            "Speed: 2.7ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 56.1ms\n",
            "Speed: 2.7ms preprocess, 56.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.7ms\n",
            "Speed: 2.7ms preprocess, 50.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.0ms\n",
            "Speed: 2.7ms preprocess, 51.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.5ms\n",
            "Speed: 2.6ms preprocess, 50.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.6ms\n",
            "Speed: 2.7ms preprocess, 49.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.3ms\n",
            "Speed: 3.4ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.6ms\n",
            "Speed: 2.8ms preprocess, 42.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.5ms\n",
            "Speed: 2.5ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.3ms\n",
            "Speed: 2.6ms preprocess, 43.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 43.1ms\n",
            "Speed: 2.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.7ms\n",
            "Speed: 2.8ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 48.2ms\n",
            "Speed: 2.6ms preprocess, 48.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.6ms\n",
            "Speed: 2.6ms preprocess, 49.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.9ms\n",
            "Speed: 2.4ms preprocess, 49.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.1ms\n",
            "Speed: 2.9ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.4ms\n",
            "Speed: 2.7ms preprocess, 50.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.5ms\n",
            "Speed: 2.6ms preprocess, 49.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.7ms\n",
            "Speed: 2.6ms preprocess, 49.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.9ms\n",
            "Speed: 2.6ms preprocess, 42.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.9ms\n",
            "Speed: 2.5ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 42.3ms\n",
            "Speed: 2.7ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.2ms\n",
            "Speed: 2.6ms preprocess, 44.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.0ms\n",
            "Speed: 2.5ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.5ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.6ms\n",
            "Speed: 2.7ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 44.1ms\n",
            "Speed: 2.9ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.2ms\n",
            "Speed: 2.5ms preprocess, 45.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.5ms preprocess, 43.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.5ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 3.0ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.5ms\n",
            "Speed: 2.9ms preprocess, 53.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.3ms\n",
            "Speed: 2.9ms preprocess, 52.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.3ms\n",
            "Speed: 3.0ms preprocess, 51.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.1ms\n",
            "Speed: 2.8ms preprocess, 54.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 57.5ms\n",
            "Speed: 2.9ms preprocess, 57.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.5ms\n",
            "Speed: 2.8ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.9ms\n",
            "Speed: 3.0ms preprocess, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.8ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.7ms preprocess, 45.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.8ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 2.7ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.2ms\n",
            "Speed: 3.0ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.6ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.0ms\n",
            "Speed: 2.7ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.5ms\n",
            "Speed: 2.5ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.0ms\n",
            "Speed: 2.5ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.4ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.5ms\n",
            "Speed: 2.8ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.5ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.1ms\n",
            "Speed: 2.5ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 2.5ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 44.9ms\n",
            "Speed: 2.5ms preprocess, 44.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 2.9ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 3.1ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.4ms\n",
            "Speed: 2.7ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.8ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.5ms\n",
            "Speed: 2.9ms preprocess, 51.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.8ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 3.0ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.8ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.8ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 2.8ms preprocess, 50.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.9ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.9ms\n",
            "Speed: 3.0ms preprocess, 45.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.1ms\n",
            "Speed: 2.8ms preprocess, 52.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 54.1ms\n",
            "Speed: 2.8ms preprocess, 54.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.1ms\n",
            "Speed: 2.8ms preprocess, 52.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.5ms\n",
            "Speed: 3.0ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.4ms\n",
            "Speed: 2.7ms preprocess, 51.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.7ms\n",
            "Speed: 2.9ms preprocess, 51.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.5ms\n",
            "Speed: 2.9ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.7ms\n",
            "Speed: 2.8ms preprocess, 51.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.5ms\n",
            "Speed: 2.8ms preprocess, 51.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.2ms\n",
            "Speed: 2.8ms preprocess, 51.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.9ms\n",
            "Speed: 2.7ms preprocess, 50.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.8ms preprocess, 51.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.5ms\n",
            "Speed: 2.7ms preprocess, 52.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.8ms\n",
            "Speed: 2.9ms preprocess, 52.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.9ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 2.7ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.2ms\n",
            "Speed: 2.9ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.3ms\n",
            "Speed: 3.0ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.7ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.6ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.7ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.8ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.6ms preprocess, 50.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.7ms\n",
            "Speed: 2.5ms preprocess, 50.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 49.3ms\n",
            "Speed: 2.6ms preprocess, 49.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.2ms\n",
            "Speed: 2.6ms preprocess, 49.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.5ms\n",
            "Speed: 2.6ms preprocess, 49.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.5ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.7ms\n",
            "Speed: 2.6ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.7ms\n",
            "Speed: 2.7ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.3ms\n",
            "Speed: 2.6ms preprocess, 48.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.0ms\n",
            "Speed: 2.6ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.8ms\n",
            "Speed: 2.8ms preprocess, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.9ms\n",
            "Speed: 2.6ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.7ms\n",
            "Speed: 2.6ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 65.6ms\n",
            "Speed: 2.5ms preprocess, 65.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.5ms\n",
            "Speed: 2.5ms preprocess, 53.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.9ms\n",
            "Speed: 2.5ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.9ms\n",
            "Speed: 2.5ms preprocess, 48.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.6ms\n",
            "Speed: 3.0ms preprocess, 51.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.3ms\n",
            "Speed: 2.9ms preprocess, 51.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 45.5ms\n",
            "Speed: 2.9ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 1 tumor, 50.3ms\n",
            "Speed: 2.7ms preprocess, 50.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 1 tumor, 50.2ms\n",
            "Speed: 2.6ms preprocess, 50.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.8ms\n",
            "Speed: 2.7ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.9ms\n",
            "Speed: 2.9ms preprocess, 52.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.2ms\n",
            "Speed: 2.7ms preprocess, 53.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 2.9ms preprocess, 51.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.4ms\n",
            "Speed: 2.8ms preprocess, 52.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 44.6ms\n",
            "Speed: 2.8ms preprocess, 44.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 3.0ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.8ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.8ms\n",
            "Speed: 3.1ms preprocess, 51.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 3.1ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 2.9ms preprocess, 51.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.6ms\n",
            "Speed: 2.8ms preprocess, 51.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.0ms\n",
            "Speed: 3.1ms preprocess, 52.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.3ms\n",
            "Speed: 2.8ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.7ms\n",
            "Speed: 2.9ms preprocess, 51.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 51.8ms\n",
            "Speed: 2.8ms preprocess, 51.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.6ms\n",
            "Speed: 2.8ms preprocess, 51.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 59.9ms\n",
            "Speed: 2.8ms preprocess, 59.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.7ms\n",
            "Speed: 2.7ms preprocess, 52.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 44.5ms\n",
            "Speed: 2.7ms preprocess, 44.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 45.6ms\n",
            "Speed: 3.0ms preprocess, 45.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.9ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 46.8ms\n",
            "Speed: 3.0ms preprocess, 46.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.1ms\n",
            "Speed: 3.0ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.9ms\n",
            "Speed: 2.9ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.1ms\n",
            "Speed: 2.7ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.8ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.8ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.4ms\n",
            "Speed: 2.8ms preprocess, 43.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 48.9ms\n",
            "Speed: 3.2ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.8ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.8ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.7ms\n",
            "Speed: 2.7ms preprocess, 43.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 47.0ms\n",
            "Speed: 2.9ms preprocess, 47.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.0ms\n",
            "Speed: 3.0ms preprocess, 44.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.3ms\n",
            "Speed: 2.7ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 46.1ms\n",
            "Speed: 2.7ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.2ms\n",
            "Speed: 2.7ms preprocess, 44.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.8ms\n",
            "Speed: 2.6ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.7ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 2.8ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 52.6ms\n",
            "Speed: 2.8ms preprocess, 52.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.4ms\n",
            "Speed: 2.8ms preprocess, 52.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.1ms\n",
            "Speed: 2.9ms preprocess, 52.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 53.9ms\n",
            "Speed: 2.7ms preprocess, 53.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 52.1ms\n",
            "Speed: 3.0ms preprocess, 52.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 53.2ms\n",
            "Speed: 2.7ms preprocess, 53.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 52.5ms\n",
            "Speed: 2.9ms preprocess, 52.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 51.9ms\n",
            "Speed: 2.8ms preprocess, 51.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 54.1ms\n",
            "Speed: 2.9ms preprocess, 54.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 52.5ms\n",
            "Speed: 2.8ms preprocess, 52.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 53.1ms\n",
            "Speed: 2.8ms preprocess, 53.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.3ms\n",
            "Speed: 2.9ms preprocess, 53.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.8ms\n",
            "Speed: 2.9ms preprocess, 52.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.7ms\n",
            "Speed: 2.9ms preprocess, 52.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.9ms\n",
            "Speed: 2.7ms preprocess, 53.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.6ms\n",
            "Speed: 3.2ms preprocess, 53.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.2ms\n",
            "Speed: 2.8ms preprocess, 53.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.6ms\n",
            "Speed: 2.9ms preprocess, 53.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.5ms\n",
            "Speed: 2.7ms preprocess, 54.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.4ms\n",
            "Speed: 2.8ms preprocess, 52.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.6ms\n",
            "Speed: 2.8ms preprocess, 52.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.0ms\n",
            "Speed: 2.9ms preprocess, 52.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.9ms\n",
            "Speed: 2.8ms preprocess, 51.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 51.9ms\n",
            "Speed: 2.7ms preprocess, 51.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.8ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.3ms\n",
            "Speed: 2.8ms preprocess, 53.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.4ms\n",
            "Speed: 2.7ms preprocess, 53.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.3ms\n",
            "Speed: 2.9ms preprocess, 53.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.5ms\n",
            "Speed: 2.9ms preprocess, 53.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.7ms\n",
            "Speed: 3.0ms preprocess, 54.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.9ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.1ms\n",
            "Speed: 2.8ms preprocess, 52.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.6ms\n",
            "Speed: 2.9ms preprocess, 52.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 52.5ms\n",
            "Speed: 2.8ms preprocess, 52.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 kidneys, 52.7ms\n",
            "Speed: 2.9ms preprocess, 52.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.5ms\n",
            "Speed: 2.7ms preprocess, 54.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.0ms\n",
            "Speed: 2.9ms preprocess, 53.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.3ms\n",
            "Speed: 2.8ms preprocess, 53.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.8ms\n",
            "Speed: 2.8ms preprocess, 52.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.2ms\n",
            "Speed: 2.9ms preprocess, 52.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.5ms\n",
            "Speed: 2.6ms preprocess, 52.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 53.0ms\n",
            "Speed: 3.0ms preprocess, 53.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.2ms\n",
            "Speed: 2.9ms preprocess, 52.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.0ms\n",
            "Speed: 2.8ms preprocess, 52.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.3ms\n",
            "Speed: 2.7ms preprocess, 52.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.8ms\n",
            "Speed: 2.9ms preprocess, 52.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 52.2ms\n",
            "Speed: 2.8ms preprocess, 52.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 54.5ms\n",
            "Speed: 2.9ms preprocess, 54.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.6ms\n",
            "Speed: 2.9ms preprocess, 49.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 49.6ms\n",
            "Speed: 2.7ms preprocess, 49.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.7ms preprocess, 49.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.9ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.7ms preprocess, 50.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 2.8ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.7ms\n",
            "Speed: 3.3ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.5ms\n",
            "Speed: 2.8ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.2ms\n",
            "Speed: 2.8ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.6ms\n",
            "Speed: 2.7ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.4ms\n",
            "Speed: 2.9ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.9ms\n",
            "Speed: 2.7ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.8ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.3ms\n",
            "Speed: 2.8ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.3ms\n",
            "Speed: 2.6ms preprocess, 50.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.7ms\n",
            "Speed: 2.9ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.7ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.5ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.6ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.3ms\n",
            "Speed: 2.6ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.3ms\n",
            "Speed: 2.7ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 44.6ms\n",
            "Speed: 2.5ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.0ms\n",
            "Speed: 2.5ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.1ms\n",
            "Speed: 2.7ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.7ms\n",
            "Speed: 2.5ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 41.7ms\n",
            "Speed: 2.4ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 42.0ms\n",
            "Speed: 2.6ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 43.1ms\n",
            "Speed: 2.6ms preprocess, 43.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.1ms\n",
            "Speed: 2.8ms preprocess, 55.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.1ms\n",
            "Speed: 2.8ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 53.5ms\n",
            "Speed: 3.0ms preprocess, 53.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 2.9ms preprocess, 51.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.8ms preprocess, 50.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.7ms\n",
            "Speed: 2.9ms preprocess, 51.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.8ms\n",
            "Speed: 2.8ms preprocess, 49.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.7ms\n",
            "Speed: 2.9ms preprocess, 49.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.9ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 52.1ms\n",
            "Speed: 2.9ms preprocess, 52.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.7ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.9ms\n",
            "Speed: 2.8ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.8ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.8ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.7ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.9ms preprocess, 50.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.7ms\n",
            "Speed: 2.8ms preprocess, 45.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.8ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 tumors, 45.1ms\n",
            "Speed: 2.9ms preprocess, 45.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 45.0ms\n",
            "Speed: 2.8ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.8ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.3ms\n",
            "Speed: 2.8ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.2ms\n",
            "Speed: 2.8ms preprocess, 50.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 tumor, 49.8ms\n",
            "Speed: 2.9ms preprocess, 49.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.8ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.6ms preprocess, 50.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.6ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.7ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.4ms\n",
            "Speed: 2.6ms preprocess, 49.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.5ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.5ms\n",
            "Speed: 2.5ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.7ms\n",
            "Speed: 2.7ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.3ms\n",
            "Speed: 2.6ms preprocess, 49.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.6ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.9ms\n",
            "Speed: 2.6ms preprocess, 49.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.7ms\n",
            "Speed: 2.5ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.7ms\n",
            "Speed: 2.8ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.6ms\n",
            "Speed: 2.6ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.6ms\n",
            "Speed: 2.7ms preprocess, 50.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.5ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.2ms\n",
            "Speed: 2.7ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.6ms preprocess, 51.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 2.6ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.4ms\n",
            "Speed: 2.6ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.0ms\n",
            "Speed: 2.6ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 49.6ms\n",
            "Speed: 2.8ms preprocess, 49.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 49.5ms\n",
            "Speed: 2.7ms preprocess, 49.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 49.6ms\n",
            "Speed: 2.5ms preprocess, 49.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 kidneys, 50.0ms\n",
            "Speed: 3.1ms preprocess, 50.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 1 tumor, 50.1ms\n",
            "Speed: 2.8ms preprocess, 50.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 kidney, 50.4ms\n",
            "Speed: 2.9ms preprocess, 50.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 55.7ms\n",
            "Speed: 2.7ms preprocess, 55.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 54.0ms\n",
            "Speed: 3.2ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.4ms\n",
            "Speed: 2.9ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.8ms\n",
            "Speed: 3.2ms preprocess, 50.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.0ms\n",
            "Speed: 3.0ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.9ms\n",
            "Speed: 3.0ms preprocess, 50.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 51.1ms\n",
            "Speed: 2.7ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 (no detections), 50.7ms\n",
            "Speed: 2.8ms preprocess, 50.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Annotation completed.\n"
          ]
        }
      ],
      "source": [
        "# Model path\n",
        "model_path = os.path.join('.', 'runs', 'detect', 'train2', 'weights', 'last.pt')\n",
        "\n",
        "# Load model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Threshold for detection\n",
        "threshold = 0.5\n",
        "\n",
        "# Process each image in the test directory\n",
        "for image_name in os.listdir(TEST_IMAGES_DIR):\n",
        "    image_path = os.path.join(TEST_IMAGES_DIR, image_name)\n",
        "\n",
        "    # Read image\n",
        "    frame = cv2.imread(image_path)\n",
        "\n",
        "    # Perform object detection\n",
        "    results = model(frame)[0]\n",
        "\n",
        "    # Process results\n",
        "    for i in range(len(results.boxes.xyxy)):\n",
        "        box = results.boxes.xyxy[i]\n",
        "        conf = results.boxes.conf[i]\n",
        "        class_id = int(results.boxes.cls[i].cpu())  # Convert to CPU tensor and then to int\n",
        "\n",
        "        if conf > threshold:\n",
        "            x1, y1, x2, y2 = box[:4]  # Extracting bounding box coordinates\n",
        "\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
        "            # Add class label\n",
        "            cv2.putText(frame, results.names[class_id].upper(), (int(x1), int(y1 - 10)),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
        "\n",
        "    # Save annotated image\n",
        "    annotated_image_path = os.path.join(ANNOTATED_IMAGES_DIR, image_name)\n",
        "    cv2.imwrite(annotated_image_path, frame)\n",
        "\n",
        "# Print message after processing all images\n",
        "print(\"Annotation completed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## IOU curve\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load annotations from ground truth files\n",
        "def load_annotations(annotation_folder):\n",
        "    annotations = {}\n",
        "    for filename in os.listdir(annotation_folder):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            image_id = os.path.splitext(filename)[0]\n",
        "            with open(os.path.join(annotation_folder, filename), \"r\") as file:\n",
        "                lines = file.readlines()\n",
        "                annotations[image_id] = [(float(line.split()[1]), float(line.split()[2]),\n",
        "                                          float(line.split()[3]), float(line.split()[4])) for line in lines]\n",
        "    return annotations\n",
        "\n",
        "ground_truth_annotations = load_annotations(\"/content/drive/MyDrive/project_folder/test/labels\")\n",
        "\n",
        "# Extract predictions from images\n",
        "def extract_predictions_from_images(image_folder):\n",
        "    predictions = {}\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            image_id = os.path.splitext(filename)[0]\n",
        "            # Your code to extract bounding boxes from images and store them in predictions\n",
        "            # You may need need YOLO output parser\n",
        "            predictions[image_id] = [(x1, y1, x2, y2) for each_prediction in predictions]  # Example format\n",
        "    return predictions\n",
        "\n",
        "yolo_predictions = extract_predictions_from_images(\"/content/drive/MyDrive/project_folder/annotated\")\n",
        "\n",
        "# Define IoU function\n",
        "def calculate_iou(box1, box2):\n",
        "    intersection_x1 = max(box1[0], box2[0])\n",
        "    intersection_y1 = max(box1[1], box2[1])\n",
        "    intersection_x2 = min(box1[2], box2[2])\n",
        "    intersection_y2 = min(box1[3], box2[3])\n",
        "    intersection_area = max(0, intersection_x2 - intersection_x1 + 1) * max(0, intersection_y2 - intersection_y1 + 1)\n",
        "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
        "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "# Compute Precision and Recall\n",
        "def compute_precision_recall(ground_truth, predictions, threshold):\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "    for image_id, prediction_boxes in predictions.items():\n",
        "        ground_truth_boxes = ground_truth.get(image_id, [])\n",
        "        for prediction_box in prediction_boxes:\n",
        "            # Find the best matching ground truth annotation\n",
        "            best_iou = 0\n",
        "            for gt_box in ground_truth_boxes:\n",
        "                iou = calculate_iou(prediction_box, gt_box)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "            # If IoU is above a certain threshold, count as true positive\n",
        "            if best_iou >= threshold:\n",
        "                true_positives += 1\n",
        "            else:\n",
        "                false_positives += 1\n",
        "        false_negatives += max(0, len(ground_truth_boxes) - len(prediction_boxes))\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) != 0 else 0\n",
        "    return precision, recall\n",
        "\n",
        "# Thresholds for confidence scores\n",
        "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# Compute precision and recall for each threshold\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    precision, recall = compute_precision_recall(ground_truth_annotations, yolo_predictions, threshold)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "# Plot PR curve\n",
        "plt.plot(recalls, precisions)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "D-H2dVmcy0Fi",
        "outputId": "c49f2abf-ecf8-44dd-9947-3e7ca7a95fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "id": "D-H2dVmcy0Fi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load annotations from ground truth files\n",
        "def load_annotations(annotation_folder):\n",
        "    annotations = {}\n",
        "    for filename in os.listdir(annotation_folder):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            image_id = os.path.splitext(filename)[0]\n",
        "            with open(os.path.join(annotation_folder, filename), \"r\") as file:\n",
        "                lines = file.readlines()\n",
        "                annotations[image_id] = [(float(line.split()[1]), float(line.split()[2]),\n",
        "                                          float(line.split()[3]), float(line.split()[4])) for line in lines]\n",
        "    return annotations\n",
        "\n",
        "ground_truth_annotations = load_annotations(\"/content/drive/MyDrive/project_folder/test/labels\")\n",
        "print(\"Ground Truth Annotations:\", ground_truth_annotations)\n",
        "\n",
        "# Extract predictions from images\n",
        "def extract_predictions_from_images(image_folder):\n",
        "    predictions = {}\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            image_id = os.path.splitext(filename)[0]\n",
        "            # Your code to extract bounding boxes from images and store them in predictions\n",
        "            # You may need to use image processing techniques or a YOLO output parser\n",
        "            predictions[image_id] = [(x1, y1, x2, y2) for each_prediction in predictions]  # Example format\n",
        "    return predictions\n",
        "\n",
        "yolo_predictions = extract_predictions_from_images(\"/content/drive/MyDrive/project_folder/annotated\")\n",
        "print(\"YOLO Predictions:\", yolo_predictions)\n",
        "\n",
        "# Define IoU function\n",
        "def calculate_iou(box1, box2):\n",
        "    intersection_x1 = max(box1[0], box2[0])\n",
        "    intersection_y1 = max(box1[1], box2[1])\n",
        "    intersection_x2 = min(box1[2], box2[2])\n",
        "    intersection_y2 = min(box1[3], box2[3])\n",
        "    intersection_area = max(0, intersection_x2 - intersection_x1 + 1) * max(0, intersection_y2 - intersection_y1 + 1)\n",
        "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
        "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "# Compute Precision and Recall\n",
        "def compute_precision_recall(ground_truth, predictions, threshold):\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    false_negatives = 0\n",
        "    for image_id, prediction_boxes in predictions.items():\n",
        "        ground_truth_boxes = ground_truth.get(image_id, [])\n",
        "        for prediction_box in prediction_boxes:\n",
        "            # Find the best matching ground truth annotation\n",
        "            best_iou = 0\n",
        "            for gt_box in ground_truth_boxes:\n",
        "                iou = calculate_iou(prediction_box, gt_box)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "            # If IoU is above a certain threshold, count as true positive\n",
        "            if best_iou >= threshold:\n",
        "                true_positives += 1\n",
        "            else:\n",
        "                false_positives += 1\n",
        "        false_negatives += max(0, len(ground_truth_boxes) - len(prediction_boxes))\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) != 0 else 0\n",
        "    return precision, recall\n",
        "\n",
        "# Thresholds for confidence scores\n",
        "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "# Compute precision and recall for each threshold\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    precision, recall = compute_precision_recall(ground_truth_annotations, yolo_predictions, threshold)\n",
        "    print(\"Threshold:\", threshold)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "# Plot PR curve\n",
        "plt.plot(recalls, precisions)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eDdqRSZZBVJF",
        "outputId": "65eadbc5-eb69-45a7-ccc4-f710e45894fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        }
      },
      "id": "eDdqRSZZBVJF",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth Annotations: {'case_00033_380': [], 'case_00033_385': [], 'case_00033_390': [], 'case_00033_395': [], 'case_00033_400': [], 'case_00033_405': [], 'case_00033_410': [], 'case_00033_415': [], 'case_00033_420': [], 'case_00030_0': [], 'case_00030_5': [(0.7216796875, 0.466796875, 0.083984375, 0.09375)], 'case_00030_10': [(0.60546875, 0.5205078125, 0.09765625, 0.154296875), (0.71875, 0.4794921875, 0.25390625, 0.275390625)], 'case_00030_20': [(0.2998046875, 0.591796875, 0.134765625, 0.17578125), (0.6962890625, 0.5126953125, 0.388671875, 0.384765625)], 'case_00030_15': [(0.57421875, 0.5576171875, 0.05859375, 0.052734375), (0.3251953125, 0.626953125, 0.119140625, 0.1171875), (0.6962890625, 0.50390625, 0.380859375, 0.375)], 'case_00030_25': [(0.6015625, 0.3291015625, 0.11328125, 0.056640625), (0.279296875, 0.57421875, 0.12109375, 0.15625), (0.6953125, 0.501953125, 0.375, 0.37890625)], 'case_00030_30': [(0.609375, 0.3466796875, 0.09765625, 0.083984375), (0.5595703125, 0.3916015625, 0.001953125, 0.001953125), (0.27734375, 0.5546875, 0.0625, 0.08203125), (0.6787109375, 0.4814453125, 0.255859375, 0.275390625)], 'case_00030_35': [(0.7275390625, 0.412109375, 0.029296875, 0.03125), (0.7529296875, 0.455078125, 0.017578125, 0.01171875), (0.7109375, 0.4921875, 0.0546875, 0.0390625), (0.689453125, 0.529296875, 0.05859375, 0.046875), (0.7373046875, 0.5556640625, 0.029296875, 0.025390625)], 'case_00111_0': [], 'case_00111_5': [], 'case_00111_20': [], 'case_00111_15': [], 'case_00111_10': [], 'case_00111_30': [], 'case_00111_25': [], 'case_00111_35': [], 'case_00111_40': [(0.36328125, 0.6396484375, 0.12109375, 0.107421875)], 'case_00111_45': [(0.3525390625, 0.6240234375, 0.162109375, 0.130859375), (0.65625, 0.62109375, 0.06640625, 0.05859375)], 'case_00111_50': [(0.3427734375, 0.609375, 0.173828125, 0.14453125), (0.662109375, 0.603515625, 0.13671875, 0.125), (0.7255859375, 0.5625, 0.009765625, 0.015625)], 'case_00111_55': [(0.3271484375, 0.587890625, 0.162109375, 0.16796875), (0.6728515625, 0.59765625, 0.169921875, 0.14453125), (0.7265625, 0.556640625, 0.09765625, 0.09765625)], 'case_00111_60': [(0.32421875, 0.5712890625, 0.15234375, 0.166015625), (0.681640625, 0.572265625, 0.17578125, 0.16796875), (0.724609375, 0.5419921875, 0.09765625, 0.103515625)], 'case_00111_65': [(0.6953125, 0.5625, 0.171875, 0.17578125), (0.3271484375, 0.560546875, 0.142578125, 0.16015625)], 'case_00111_70': [(0.703125, 0.5498046875, 0.16796875, 0.177734375), (0.32421875, 0.546875, 0.125, 0.13671875)], 'case_00111_75': [(0.697265625, 0.5390625, 0.17578125, 0.16015625), (0.3212890625, 0.5458984375, 0.083984375, 0.111328125)], 'case_00111_80': [(0.6953125, 0.529296875, 0.1640625, 0.13671875)], 'case_00111_85': [(0.6904296875, 0.5185546875, 0.126953125, 0.099609375)], 'case_00111_90': [(0.6943359375, 0.5166015625, 0.044921875, 0.033203125)], 'case_00111_95': [], 'case_00111_105': [], 'case_00111_100': [], 'case_00111_110': [], 'case_00111_115': [], 'case_00111_120': [], 'case_00111_125': [], 'case_00111_130': [], 'case_00111_135': [], 'case_00111_140': [], 'case_00111_145': [], 'case_00111_150': [], 'case_00111_155': [], 'case_00111_160': [], 'case_00111_165': [], 'case_00111_170': [], 'case_00111_175': [], 'case_00111_180': [], 'case_00111_185': [], 'case_00031_10': [], 'case_00031_5': [], 'case_00031_0': [], 'case_00031_15': [], 'case_00031_25': [(0.3330078125, 0.591796875, 0.158203125, 0.140625), (0.6962890625, 0.6552734375, 0.201171875, 0.169921875)], 'case_00031_20': [(0.68359375, 0.66015625, 0.1640625, 0.12109375)], 'case_00031_30': [(0.3095703125, 0.58203125, 0.205078125, 0.17578125), (0.7060546875, 0.6533203125, 0.212890625, 0.177734375)], 'case_00031_35': [(0.2744140625, 0.5673828125, 0.181640625, 0.193359375), (0.7333984375, 0.6494140625, 0.185546875, 0.173828125)], 'case_00031_40': [(0.2734375, 0.5537109375, 0.1953125, 0.189453125), (0.732421875, 0.6376953125, 0.1953125, 0.169921875), (0.671875, 0.6435546875, 0.05859375, 0.060546875)], 'case_00031_45': [(0.267578125, 0.5400390625, 0.1796875, 0.154296875), (0.7236328125, 0.6298828125, 0.150390625, 0.138671875), (0.6767578125, 0.6416015625, 0.068359375, 0.056640625)], 'case_00031_55': [], 'case_00031_50': [(0.2607421875, 0.533203125, 0.103515625, 0.09375), (0.7099609375, 0.623046875, 0.041015625, 0.0390625)], 'case_00031_60': [], 'case_00031_65': [], 'case_00031_70': [], 'case_00031_75': [], 'case_00031_80': [], 'case_00031_85': [], 'case_00031_90': [], 'case_00031_95': [], 'case_00031_100': [], 'case_00031_105': [], 'case_00031_110': [], 'case_00031_115': [], 'case_00104_0': [], 'case_00104_15': [], 'case_00104_10': [], 'case_00104_5': [], 'case_00104_25': [], 'case_00104_20': [], 'case_00104_30': [(0.6728515625, 0.6767578125, 0.052734375, 0.017578125), (0.6708984375, 0.72265625, 0.087890625, 0.0859375)], 'case_00104_35': [(0.3095703125, 0.625, 0.123046875, 0.1953125), (0.685546875, 0.69140625, 0.15234375, 0.1484375)], 'case_00104_45': [(0.33203125, 0.53515625, 0.08984375, 0.140625), (0.693359375, 0.62890625, 0.11328125, 0.10546875), (0.2744140625, 0.544921875, 0.123046875, 0.1171875)], 'case_00104_40': [(0.3115234375, 0.5791015625, 0.154296875, 0.216796875), (0.701171875, 0.6572265625, 0.15234375, 0.138671875)], 'case_00104_50': [(0.2568359375, 0.5244140625, 0.041015625, 0.060546875)], 'case_00104_55': [], 'case_00104_60': [], 'case_00104_65': [], 'case_00104_70': [], 'case_00104_75': [], 'case_00104_85': [], 'case_00104_80': [], 'case_00104_90': [], 'case_00104_95': [], 'case_00104_100': [], 'case_00104_105': [], 'case_00104_110': [], 'case_00101_0': [], 'case_00101_5': [], 'case_00101_10': [], 'case_00101_15': [], 'case_00101_20': [], 'case_00101_25': [], 'case_00101_30': [], 'case_00101_35': [], 'case_00101_40': [], 'case_00101_45': [(0.400390625, 0.6943359375, 0.0234375, 0.029296875)], 'case_00101_50': [(0.599609375, 0.7275390625, 0.01953125, 0.029296875), (0.400390625, 0.69921875, 0.04296875, 0.046875)], 'case_00101_55': [(0.3916015625, 0.6748046875, 0.001953125, 0.001953125), (0.3837890625, 0.6796875, 0.009765625, 0.0078125), (0.375, 0.701171875, 0.01171875, 0.03515625), (0.6044921875, 0.728515625, 0.048828125, 0.06640625), (0.3818359375, 0.7197265625, 0.001953125, 0.001953125), (0.3994140625, 0.7001953125, 0.044921875, 0.052734375)], 'case_00101_60': [(0.3779296875, 0.6982421875, 0.029296875, 0.056640625), (0.6103515625, 0.7275390625, 0.068359375, 0.087890625), (0.3984375, 0.69921875, 0.046875, 0.0546875)], 'case_00101_65': [(0.3720703125, 0.703125, 0.037109375, 0.06640625), (0.61328125, 0.7265625, 0.08203125, 0.1015625), (0.3974609375, 0.6982421875, 0.048828125, 0.064453125)], 'case_00101_70': [(0.37890625, 0.703125, 0.0703125, 0.08984375), (0.6181640625, 0.724609375, 0.091796875, 0.11328125), (0.400390625, 0.703125, 0.04296875, 0.046875)], 'case_00101_75': [(0.3779296875, 0.7041015625, 0.087890625, 0.103515625), (0.6220703125, 0.7236328125, 0.103515625, 0.119140625), (0.4033203125, 0.703125, 0.037109375, 0.0390625)], 'case_00101_80': [(0.373046875, 0.7021484375, 0.09765625, 0.115234375), (0.626953125, 0.7197265625, 0.11328125, 0.126953125), (0.4013671875, 0.7021484375, 0.041015625, 0.044921875)], 'case_00101_85': [(0.3681640625, 0.7021484375, 0.107421875, 0.123046875), (0.6318359375, 0.7177734375, 0.119140625, 0.130859375), (0.404296875, 0.701171875, 0.03125, 0.0390625)], 'case_00101_90': [(0.3642578125, 0.7001953125, 0.115234375, 0.130859375), (0.63671875, 0.7158203125, 0.12890625, 0.134765625)], 'case_00101_95': [(0.361328125, 0.69921875, 0.125, 0.13671875), (0.640625, 0.71484375, 0.13671875, 0.13671875)], 'case_00101_100': [(0.3583984375, 0.697265625, 0.134765625, 0.140625), (0.64453125, 0.7138671875, 0.14453125, 0.138671875)], 'case_00101_105': [(0.35546875, 0.6982421875, 0.140625, 0.142578125), (0.6484375, 0.7138671875, 0.1484375, 0.138671875)], 'case_00101_110': [(0.3515625, 0.6982421875, 0.1484375, 0.146484375), (0.6533203125, 0.7119140625, 0.150390625, 0.142578125)], 'case_00101_115': [(0.34765625, 0.6982421875, 0.15234375, 0.146484375), (0.65625, 0.7099609375, 0.15625, 0.142578125)], 'case_00101_120': [(0.3427734375, 0.697265625, 0.158203125, 0.14453125), (0.66015625, 0.7080078125, 0.15625, 0.146484375)], 'case_00101_125': [(0.3408203125, 0.6962890625, 0.158203125, 0.142578125), (0.6630859375, 0.7041015625, 0.158203125, 0.150390625)], 'case_00101_130': [(0.3369140625, 0.69140625, 0.162109375, 0.15234375), (0.669921875, 0.7021484375, 0.1640625, 0.154296875)], 'case_00101_135': [(0.3330078125, 0.6875, 0.158203125, 0.15625), (0.671875, 0.7001953125, 0.15625, 0.154296875)], 'case_00101_140': [(0.330078125, 0.68359375, 0.15234375, 0.1640625), (0.6748046875, 0.6962890625, 0.158203125, 0.158203125)], 'case_00101_145': [(0.328125, 0.6796875, 0.1484375, 0.16796875), (0.677734375, 0.6943359375, 0.15625, 0.162109375)], 'case_00101_150': [(0.3251953125, 0.677734375, 0.146484375, 0.16796875), (0.6806640625, 0.69140625, 0.150390625, 0.1640625)], 'case_00101_155': [(0.322265625, 0.673828125, 0.140625, 0.16796875), (0.6845703125, 0.6884765625, 0.146484375, 0.166015625)], 'case_00101_160': [(0.3203125, 0.671875, 0.13671875, 0.16796875), (0.6875, 0.6875, 0.14453125, 0.1640625)], 'case_00101_165': [(0.3203125, 0.6708984375, 0.1328125, 0.169921875), (0.689453125, 0.6845703125, 0.140625, 0.166015625)], 'case_00101_170': [(0.3203125, 0.66796875, 0.1328125, 0.16796875), (0.6904296875, 0.6826171875, 0.142578125, 0.166015625)], 'case_00101_175': [(0.3212890625, 0.6669921875, 0.130859375, 0.166015625), (0.6884765625, 0.681640625, 0.138671875, 0.1640625)], 'case_00101_180': [(0.3212890625, 0.6650390625, 0.130859375, 0.166015625), (0.6875, 0.6787109375, 0.13671875, 0.162109375)], 'case_00101_185': [(0.3203125, 0.6640625, 0.12890625, 0.1640625), (0.6865234375, 0.6767578125, 0.134765625, 0.158203125)], 'case_00101_190': [(0.3203125, 0.6630859375, 0.125, 0.162109375), (0.685546875, 0.677734375, 0.12890625, 0.15625)], 'case_00101_195': [(0.3193359375, 0.662109375, 0.123046875, 0.16015625), (0.6845703125, 0.6748046875, 0.123046875, 0.154296875)], 'case_00101_200': [(0.3193359375, 0.66015625, 0.119140625, 0.15625), (0.685546875, 0.673828125, 0.1171875, 0.1484375)], 'case_00101_205': [(0.3203125, 0.6591796875, 0.1171875, 0.154296875), (0.6845703125, 0.6728515625, 0.111328125, 0.142578125)], 'case_00101_210': [(0.3203125, 0.6572265625, 0.11328125, 0.150390625), (0.68359375, 0.671875, 0.1015625, 0.13671875)], 'case_00101_215': [(0.3203125, 0.654296875, 0.109375, 0.14453125), (0.68359375, 0.669921875, 0.09375, 0.12890625)], 'case_00101_220': [(0.3193359375, 0.65234375, 0.103515625, 0.13671875), (0.68359375, 0.669921875, 0.0859375, 0.12109375)], 'case_00101_225': [(0.3193359375, 0.6513671875, 0.095703125, 0.126953125), (0.6826171875, 0.66796875, 0.076171875, 0.11328125)], 'case_00101_230': [(0.3173828125, 0.6513671875, 0.087890625, 0.115234375), (0.681640625, 0.6669921875, 0.06640625, 0.099609375)], 'case_00101_235': [(0.31640625, 0.6513671875, 0.08203125, 0.107421875), (0.6796875, 0.6640625, 0.05078125, 0.0859375)], 'case_00101_240': [(0.31640625, 0.650390625, 0.06640625, 0.09375), (0.6787109375, 0.650390625, 0.033203125, 0.04296875)], 'case_00101_245': [(0.31640625, 0.6494140625, 0.05859375, 0.076171875)], 'case_00101_255': [(0.3154296875, 0.646484375, 0.033203125, 0.0390625)], 'case_00101_250': [(0.31640625, 0.6474609375, 0.046875, 0.060546875)], 'case_00101_260': [], 'case_00101_265': [], 'case_00101_270': [], 'case_00101_275': [], 'case_00101_280': [], 'case_00101_285': [], 'case_00101_290': [], 'case_00101_295': [], 'case_00101_300': [], 'case_00101_305': [], 'case_00101_310': [], 'case_00101_315': [], 'case_00101_320': [], 'case_00101_325': [], 'case_00101_330': [], 'case_00101_335': [], 'case_00101_340': [], 'case_00101_345': [], 'case_00101_350': [], 'case_00101_355': [], 'case_00101_360': [], 'case_00101_365': [], 'case_00101_370': [], 'case_00101_375': [], 'case_00101_380': [], 'case_00101_385': [], 'case_00101_390': [], 'case_00101_395': [], 'case_00101_400': [], 'case_00101_405': [], 'case_00101_410': [], 'case_00101_415': [], 'case_00101_420': [], 'case_00101_425': [], 'case_00101_430': [], 'case_00101_435': [], 'case_00101_440': [], 'case_00101_445': [], 'case_00101_450': [], 'case_00101_455': [], 'case_00101_460': [], 'case_00101_465': [], 'case_00101_470': [], 'case_00101_475': [], 'case_00101_480': [], 'case_00101_485': [], 'case_00101_490': [], 'case_00101_495': [], 'case_00101_500': [], 'case_00101_505': [], 'case_00101_510': [], 'case_00208_0': [], 'case_00208_5': [], 'case_00208_10': [], 'case_00208_15': [], 'case_00208_20': [(0.2890625, 0.650390625, 0.0390625, 0.0390625)], 'case_00208_25': [(0.2822265625, 0.625, 0.138671875, 0.140625), (0.6435546875, 0.6572265625, 0.138671875, 0.115234375)], 'case_00208_30': [(0.26953125, 0.6142578125, 0.12890625, 0.150390625), (0.6513671875, 0.630859375, 0.126953125, 0.1484375), (0.609375, 0.685546875, 0.04296875, 0.04296875)], 'case_00208_35': [(0.2861328125, 0.599609375, 0.115234375, 0.1171875), (0.634765625, 0.615234375, 0.12109375, 0.125)], 'case_00208_40': [(0.626953125, 0.6005859375, 0.0546875, 0.072265625)], 'case_00208_45': [(0.607421875, 0.5947265625, 0.046875, 0.048828125)], 'case_00208_50': [], 'case_00208_55': [], 'case_00208_60': [], 'case_00208_65': [], 'case_00208_70': [], 'case_00208_75': [], 'case_00208_80': [], 'case_00208_85': [], 'case_00080_5': [], 'case_00080_0': [], 'case_00080_10': [], 'case_00080_20': [(0.609375, 0.7373046875, 0.08203125, 0.107421875), (0.3505859375, 0.736328125, 0.052734375, 0.05859375)], 'case_00080_15': [], 'case_00080_30': [(0.3134765625, 0.6904296875, 0.166015625, 0.154296875), (0.6591796875, 0.71875, 0.173828125, 0.18359375), (0.671875, 0.767578125, 0.0390625, 0.03515625)], 'case_00080_25': [(0.6396484375, 0.728515625, 0.146484375, 0.1640625), (0.3291015625, 0.716796875, 0.154296875, 0.13671875), (0.677734375, 0.7802734375, 0.109375, 0.115234375)], 'case_00080_35': [(0.29296875, 0.671875, 0.125, 0.15234375), (0.6865234375, 0.7138671875, 0.130859375, 0.146484375)], 'case_00080_40': [(0.2978515625, 0.6552734375, 0.103515625, 0.123046875), (0.6826171875, 0.6982421875, 0.095703125, 0.115234375)], 'case_00080_45': [], 'case_00080_50': [], 'case_00080_55': [], 'case_00080_60': [], 'case_00080_65': [], 'case_00080_70': [], 'case_00080_75': [], 'case_00080_80': [], 'case_00080_85': [], 'case_00014_0': [], 'case_00014_15': [], 'case_00014_5': [], 'case_00014_10': [], 'case_00014_20': [], 'case_00014_30': [], 'case_00014_25': [], 'case_00014_35': [], 'case_00014_40': [], 'case_00014_45': [], 'case_00014_50': [], 'case_00014_55': [], 'case_00014_60': [], 'case_00014_65': [], 'case_00014_70': [(0.4189453125, 0.603515625, 0.041015625, 0.05859375)], 'case_00014_75': [(0.4150390625, 0.6025390625, 0.072265625, 0.107421875), (0.6513671875, 0.5947265625, 0.060546875, 0.041015625), (0.654296875, 0.61328125, 0.015625, 0.01171875), (0.685546875, 0.6171875, 0.00390625, 0.00390625)], 'case_00014_80': [(0.4130859375, 0.599609375, 0.087890625, 0.125), (0.6533203125, 0.5927734375, 0.087890625, 0.080078125)], 'case_00014_85': [(0.412109375, 0.5986328125, 0.09375, 0.134765625), (0.654296875, 0.5869140625, 0.10546875, 0.091796875)], 'case_00014_90': [(0.4091796875, 0.595703125, 0.107421875, 0.140625), (0.654296875, 0.583984375, 0.11328125, 0.1015625)], 'case_00014_95': [(0.40625, 0.59765625, 0.11328125, 0.1484375), (0.6572265625, 0.58203125, 0.123046875, 0.10546875)], 'case_00014_100': [(0.40234375, 0.5966796875, 0.12109375, 0.150390625), (0.658203125, 0.5791015625, 0.125, 0.107421875)], 'case_00014_105': [(0.4013671875, 0.59375, 0.126953125, 0.15234375), (0.662109375, 0.5771484375, 0.12890625, 0.107421875)], 'case_00014_110': [(0.400390625, 0.595703125, 0.12890625, 0.15625), (0.6650390625, 0.57421875, 0.126953125, 0.11328125), (0.349609375, 0.5830078125, 0.02734375, 0.044921875)], 'case_00014_115': [(0.6689453125, 0.5712890625, 0.123046875, 0.115234375), (0.3994140625, 0.5947265625, 0.126953125, 0.138671875), (0.353515625, 0.5791015625, 0.046875, 0.048828125)], 'case_00014_120': [(0.669921875, 0.5673828125, 0.12890625, 0.119140625), (0.396484375, 0.595703125, 0.12890625, 0.1328125), (0.3505859375, 0.580078125, 0.041015625, 0.046875)], 'case_00014_125': [(0.6708984375, 0.5654296875, 0.130859375, 0.115234375), (0.3935546875, 0.595703125, 0.130859375, 0.125), (0.333984375, 0.58203125, 0.0078125, 0.01171875)], 'case_00014_130': [(0.673828125, 0.5654296875, 0.12890625, 0.107421875), (0.3916015625, 0.5947265625, 0.130859375, 0.123046875)], 'case_00014_135': [(0.67578125, 0.5654296875, 0.12890625, 0.087890625), (0.38671875, 0.59765625, 0.12890625, 0.11328125)], 'case_00014_140': [(0.6787109375, 0.5625, 0.126953125, 0.08203125), (0.3857421875, 0.599609375, 0.126953125, 0.109375)], 'case_00014_145': [(0.68359375, 0.5546875, 0.125, 0.08984375), (0.3828125, 0.599609375, 0.12109375, 0.09765625)], 'case_00014_150': [(0.6865234375, 0.5537109375, 0.123046875, 0.103515625), (0.3798828125, 0.599609375, 0.119140625, 0.09375)], 'case_00014_155': [(0.689453125, 0.55078125, 0.1171875, 0.09765625), (0.376953125, 0.59375, 0.11328125, 0.09765625)], 'case_00014_160': [(0.69140625, 0.548828125, 0.109375, 0.08984375), (0.3740234375, 0.5908203125, 0.107421875, 0.095703125)], 'case_00014_165': [(0.6904296875, 0.5458984375, 0.095703125, 0.076171875), (0.3720703125, 0.5869140625, 0.103515625, 0.095703125)], 'case_00014_170': [(0.69140625, 0.544921875, 0.07421875, 0.0625), (0.3720703125, 0.5830078125, 0.091796875, 0.091796875)], 'case_00014_175': [(0.6962890625, 0.544921875, 0.044921875, 0.046875), (0.37109375, 0.580078125, 0.078125, 0.08203125)], 'case_00014_180': [(0.37109375, 0.5771484375, 0.0625, 0.064453125)], 'case_00014_190': [], 'case_00014_185': [(0.37109375, 0.5751953125, 0.03515625, 0.041015625)], 'case_00014_200': [], 'case_00014_195': [], 'case_00014_210': [], 'case_00014_205': [], 'case_00014_215': [], 'case_00014_220': [], 'case_00014_225': [], 'case_00014_230': [], 'case_00014_235': [], 'case_00014_240': [], 'case_00014_245': [], 'case_00014_250': [], 'case_00014_255': [], 'case_00014_260': [], 'case_00014_280': [], 'case_00014_275': [], 'case_00014_270': [], 'case_00014_265': [], 'case_00014_285': [], 'case_00014_310': [], 'case_00014_305': [], 'case_00014_290': [], 'case_00014_295': [], 'case_00014_300': [], 'case_00014_320': [], 'case_00014_325': [], 'case_00014_315': [], 'case_00014_330': [], 'case_00014_335': [], 'case_00014_345': [], 'case_00014_340': [], 'case_00014_350': [], 'case_00014_355': [], 'case_00014_360': [], 'case_00014_365': [], 'case_00014_370': [], 'case_00014_375': [], 'case_00014_380': [], 'case_00014_385': [], 'case_00014_390': [], 'case_00014_395': [], 'case_00014_400': [], 'case_00014_405': [], 'case_00014_410': [], 'case_00014_415': [], 'case_00014_420': [], 'case_00014_425': [], 'case_00014_430': [], 'case_00014_435': [], 'case_00131_5': [], 'case_00131_15': [], 'case_00131_10': [], 'case_00131_0': [], 'case_00131_30': [], 'case_00131_25': [], 'case_00131_20': [], 'case_00131_35': [(0.646484375, 0.6064453125, 0.04296875, 0.056640625), (0.65234375, 0.6376953125, 0.03125, 0.013671875)], 'case_00131_40': [(0.6650390625, 0.60546875, 0.134765625, 0.140625), (0.3564453125, 0.6640625, 0.021484375, 0.01171875), (0.6474609375, 0.6630859375, 0.130859375, 0.126953125)], 'case_00131_45': [(0.6826171875, 0.6005859375, 0.166015625, 0.162109375), (0.3330078125, 0.634765625, 0.126953125, 0.13671875), (0.7158203125, 0.6845703125, 0.001953125, 0.001953125), (0.6455078125, 0.6572265625, 0.142578125, 0.158203125)], 'case_00131_50': [(0.701171875, 0.5927734375, 0.171875, 0.166015625), (0.3232421875, 0.6142578125, 0.166015625, 0.177734375), (0.6484375, 0.666015625, 0.07421875, 0.08203125)], 'case_00131_55': [(0.70703125, 0.5849609375, 0.16796875, 0.154296875), (0.310546875, 0.603515625, 0.17578125, 0.1875)], 'case_00131_60': [(0.2841796875, 0.6005859375, 0.158203125, 0.177734375), (0.7041015625, 0.5869140625, 0.166015625, 0.146484375)], 'case_00131_65': [(0.6953125, 0.5849609375, 0.14453125, 0.126953125), (0.2822265625, 0.6015625, 0.177734375, 0.14453125)], 'case_00131_70': [(0.6865234375, 0.578125, 0.099609375, 0.0859375), (0.291015625, 0.59765625, 0.13671875, 0.1171875)], 'case_00131_75': [], 'case_00131_80': [], 'case_00131_85': [], 'case_00131_90': [], 'case_00131_95': [], 'case_00131_100': [], 'case_00131_105': [], 'case_00131_110': [], 'case_00131_115': [], 'case_00131_120': [], 'case_00131_125': [], 'case_00131_130': [], 'case_00131_135': [], 'case_00131_140': [], 'case_00131_145': [], 'case_00131_150': [], 'case_00131_155': [], 'case_00153_20': [(0.6923828125, 0.5703125, 0.208984375, 0.18359375), (0.3466796875, 0.603515625, 0.115234375, 0.1484375)], 'case_00153_0': [], 'case_00153_5': [(0.638671875, 0.6328125, 0.0546875, 0.078125)], 'case_00153_10': [(0.65625, 0.6142578125, 0.13671875, 0.150390625)], 'case_00153_15': [(0.6767578125, 0.595703125, 0.189453125, 0.1640625)], 'case_00153_30': [(0.3046875, 0.5478515625, 0.18359375, 0.228515625), (0.7119140625, 0.5234375, 0.177734375, 0.1796875), (0.25390625, 0.5673828125, 0.08984375, 0.080078125)], 'case_00153_25': [(0.708984375, 0.5458984375, 0.203125, 0.189453125), (0.3173828125, 0.5673828125, 0.177734375, 0.216796875), (0.251953125, 0.578125, 0.0390625, 0.03515625)], 'case_00153_35': [(0.296875, 0.5166015625, 0.17578125, 0.240234375), (0.7041015625, 0.5087890625, 0.146484375, 0.142578125)], 'case_00153_40': [(0.2958984375, 0.48828125, 0.189453125, 0.22265625), (0.6962890625, 0.478515625, 0.072265625, 0.0625)], 'case_00153_45': [(0.2998046875, 0.4580078125, 0.162109375, 0.158203125)], 'case_00153_50': [(0.29296875, 0.439453125, 0.0390625, 0.03125)], 'case_00153_55': [], 'case_00153_60': [], 'case_00153_65': [], 'case_00039_5': [], 'case_00039_10': [], 'case_00039_15': [], 'case_00039_20': [(0.634765625, 0.626953125, 0.109375, 0.140625)], 'case_00039_0': [], 'case_00039_25': [(0.658203125, 0.591796875, 0.16796875, 0.1875), (0.3212890625, 0.59765625, 0.052734375, 0.078125)], 'case_00039_30': [(0.291015625, 0.5634765625, 0.140625, 0.181640625), (0.666015625, 0.5556640625, 0.1484375, 0.166015625)], 'case_00039_35': [(0.26171875, 0.5341796875, 0.13671875, 0.181640625), (0.6630859375, 0.53515625, 0.095703125, 0.109375), (0.6142578125, 0.5283203125, 0.001953125, 0.001953125), (0.6376953125, 0.5029296875, 0.072265625, 0.064453125)], 'case_00039_40': [(0.2666015625, 0.4931640625, 0.123046875, 0.142578125)], 'case_00039_45': [], 'case_00039_50': [], 'case_00039_55': [], 'case_00039_60': [], 'case_00039_65': [], 'case_00039_70': [], 'case_00039_75': [], 'case_00039_80': [], 'case_00039_85': [], 'case_00110_5': [(0.3203125, 0.5673828125, 0.10546875, 0.095703125)], 'case_00110_0': [], 'case_00110_10': [(0.3095703125, 0.5654296875, 0.158203125, 0.130859375), (0.65625, 0.564453125, 0.1484375, 0.12109375)], 'case_00110_20': [(0.697265625, 0.5078125, 0.125, 0.171875), (0.30078125, 0.5224609375, 0.109375, 0.126953125), (0.7548828125, 0.4736328125, 0.087890625, 0.091796875)], 'case_00110_15': [(0.677734375, 0.529296875, 0.18359375, 0.1796875), (0.2880859375, 0.5419921875, 0.107421875, 0.134765625)], 'case_00110_30': [], 'case_00110_25': [(0.69140625, 0.4755859375, 0.07421875, 0.083984375)], 'case_00025_0': [], 'case_00025_5': [], 'case_00025_20': [], 'case_00025_10': [], 'case_00025_15': [], 'case_00025_30': [], 'case_00025_25': [], 'case_00025_35': [(0.7216796875, 0.5966796875, 0.056640625, 0.056640625)], 'case_00025_40': [(0.359375, 0.6708984375, 0.03125, 0.037109375), (0.70703125, 0.5947265625, 0.15625, 0.166015625)], 'case_00025_45': [(0.603515625, 0.5546875, 0.04296875, 0.0859375), (0.34765625, 0.658203125, 0.1015625, 0.12109375), (0.708984375, 0.59765625, 0.23046875, 0.25)], 'case_00025_50': [(0.603515625, 0.5478515625, 0.0703125, 0.123046875), (0.8330078125, 0.5537109375, 0.001953125, 0.001953125), (0.8349609375, 0.5625, 0.001953125, 0.0078125), (0.8369140625, 0.572265625, 0.001953125, 0.0078125), (0.337890625, 0.6533203125, 0.13671875, 0.150390625), (0.828125, 0.6201171875, 0.02734375, 0.083984375), (0.712890625, 0.599609375, 0.25, 0.2734375)], 'case_00025_55': [(0.5927734375, 0.546875, 0.064453125, 0.12890625), (0.3271484375, 0.630859375, 0.154296875, 0.17578125), (0.5869140625, 0.619140625, 0.001953125, 0.0078125), (0.7216796875, 0.5986328125, 0.267578125, 0.283203125)], 'case_00025_60': [(0.59765625, 0.5498046875, 0.0703125, 0.134765625), (0.31640625, 0.6162109375, 0.16015625, 0.189453125), (0.728515625, 0.59375, 0.265625, 0.28125)], 'case_00025_65': [(0.689453125, 0.5390625, 0.234375, 0.1796875), (0.306640625, 0.6025390625, 0.16015625, 0.177734375), (0.8076171875, 0.5224609375, 0.001953125, 0.001953125), (0.8095703125, 0.5244140625, 0.001953125, 0.001953125), (0.6162109375, 0.6298828125, 0.001953125, 0.001953125), (0.7333984375, 0.599609375, 0.240234375, 0.234375)], 'case_00025_70': [(0.6943359375, 0.5537109375, 0.216796875, 0.205078125), (0.302734375, 0.59375, 0.14453125, 0.16015625), (0.6591796875, 0.6572265625, 0.001953125, 0.001953125), (0.7255859375, 0.587890625, 0.181640625, 0.19921875)], 'case_00025_75': [(0.69921875, 0.55078125, 0.1796875, 0.1796875), (0.306640625, 0.5771484375, 0.125, 0.130859375), (0.6943359375, 0.587890625, 0.060546875, 0.0625)], 'case_00025_80': [(0.6953125, 0.5361328125, 0.16796875, 0.150390625), (0.3115234375, 0.5693359375, 0.083984375, 0.091796875)], 'case_00025_85': [(0.6923828125, 0.5302734375, 0.146484375, 0.126953125)], 'case_00025_90': [(0.6767578125, 0.5234375, 0.099609375, 0.09375)], 'case_00025_95': [(0.6767578125, 0.5185546875, 0.064453125, 0.056640625)], 'case_00025_100': [], 'case_00157_0': [], 'case_00157_10': [], 'case_00157_5': [], 'case_00157_20': [], 'case_00157_15': [], 'case_00157_25': [], 'case_00157_30': [], 'case_00157_35': [], 'case_00157_40': [], 'case_00157_45': [], 'case_00157_50': [], 'case_00157_55': [], 'case_00157_60': [], 'case_00157_65': [], 'case_00157_75': [], 'case_00157_70': [], 'case_00157_80': [], 'case_00157_85': [], 'case_00157_90': [], 'case_00157_95': [], 'case_00157_100': [], 'case_00157_105': [], 'case_00157_110': [], 'case_00157_115': [], 'case_00157_120': [], 'case_00157_125': [], 'case_00157_130': [], 'case_00157_135': [], 'case_00157_145': [], 'case_00157_140': [], 'case_00157_150': [], 'case_00157_155': [], 'case_00157_160': [], 'case_00157_165': [], 'case_00157_170': [(0.666015625, 0.65625, 0.0078125, 0.0078125)], 'case_00157_175': [(0.666015625, 0.658203125, 0.03515625, 0.03515625)], 'case_00157_180': [(0.6572265625, 0.654296875, 0.060546875, 0.05078125)], 'case_00157_185': [(0.6552734375, 0.6533203125, 0.076171875, 0.068359375)], 'case_00157_190': [(0.6572265625, 0.65234375, 0.080078125, 0.07421875)], 'case_00157_195': [(0.6572265625, 0.650390625, 0.087890625, 0.08203125)], 'case_00157_200': [(0.66015625, 0.650390625, 0.09765625, 0.08984375)], 'case_00157_205': [(0.6611328125, 0.6474609375, 0.107421875, 0.091796875)], 'case_00157_210': [(0.662109375, 0.6455078125, 0.11328125, 0.095703125)], 'case_00157_215': [(0.6630859375, 0.642578125, 0.119140625, 0.1015625)], 'case_00157_220': [(0.6630859375, 0.642578125, 0.123046875, 0.1015625)], 'case_00157_225': [(0.662109375, 0.6416015625, 0.125, 0.103515625)], 'case_00157_230': [(0.6630859375, 0.640625, 0.126953125, 0.10546875), (0.388671875, 0.6669921875, 0.0390625, 0.033203125), (0.4091796875, 0.6552734375, 0.005859375, 0.005859375)], 'case_00157_235': [(0.6650390625, 0.638671875, 0.130859375, 0.109375), (0.38671875, 0.6630859375, 0.0703125, 0.056640625)], 'case_00157_240': [(0.666015625, 0.6357421875, 0.1328125, 0.111328125), (0.3837890625, 0.6611328125, 0.083984375, 0.072265625), (0.7333984375, 0.5849609375, 0.001953125, 0.001953125)], 'case_00157_245': [(0.6669921875, 0.6318359375, 0.134765625, 0.119140625), (0.37890625, 0.6591796875, 0.09765625, 0.080078125), (0.734375, 0.5791015625, 0.03515625, 0.048828125)], 'case_00157_250': [(0.66796875, 0.6279296875, 0.1328125, 0.123046875), (0.375, 0.65625, 0.109375, 0.0859375), (0.736328125, 0.5791015625, 0.05078125, 0.064453125)], 'case_00157_255': [(0.669921875, 0.625, 0.1328125, 0.12890625), (0.3701171875, 0.654296875, 0.119140625, 0.09765625), (0.736328125, 0.580078125, 0.06640625, 0.07421875), (0.7021484375, 0.5712890625, 0.001953125, 0.001953125)], 'case_00157_260': [(0.671875, 0.623046875, 0.12890625, 0.12890625), (0.365234375, 0.650390625, 0.12890625, 0.09765625), (0.736328125, 0.5849609375, 0.07421875, 0.087890625)], 'case_00157_265': [(0.6728515625, 0.6201171875, 0.123046875, 0.126953125), (0.359375, 0.6474609375, 0.140625, 0.107421875), (0.736328125, 0.5859375, 0.078125, 0.09765625)], 'case_00157_270': [(0.6767578125, 0.6171875, 0.111328125, 0.12890625), (0.3544921875, 0.6474609375, 0.146484375, 0.107421875), (0.7353515625, 0.583984375, 0.087890625, 0.09765625)], 'case_00157_275': [(0.677734375, 0.6142578125, 0.10546875, 0.126953125), (0.3505859375, 0.6455078125, 0.154296875, 0.111328125), (0.736328125, 0.5869140625, 0.10546875, 0.107421875)], 'case_00157_280': [(0.6787109375, 0.6123046875, 0.103515625, 0.123046875), (0.3466796875, 0.640625, 0.158203125, 0.1171875), (0.740234375, 0.5869140625, 0.1171875, 0.111328125)], 'case_00157_285': [(0.6806640625, 0.6103515625, 0.103515625, 0.123046875), (0.3427734375, 0.63671875, 0.158203125, 0.125), (0.7412109375, 0.5859375, 0.123046875, 0.11328125)], 'case_00157_290': [(0.677734375, 0.609375, 0.09375, 0.125), (0.3388671875, 0.6328125, 0.158203125, 0.12890625), (0.732421875, 0.5849609375, 0.12109375, 0.115234375)], 'case_00157_295': [(0.677734375, 0.6083984375, 0.08984375, 0.123046875), (0.3359375, 0.6298828125, 0.15625, 0.130859375), (0.73046875, 0.583984375, 0.125, 0.11328125)], 'case_00157_300': [(0.681640625, 0.607421875, 0.09375, 0.1171875), (0.333984375, 0.6279296875, 0.15625, 0.134765625), (0.7275390625, 0.5810546875, 0.130859375, 0.115234375)], 'case_00157_305': [(0.6875, 0.607421875, 0.1015625, 0.1171875), (0.33203125, 0.6240234375, 0.15625, 0.138671875), (0.7421875, 0.6396484375, 0.00390625, 0.001953125), (0.7294921875, 0.5830078125, 0.126953125, 0.119140625)], 'case_00157_310': [(0.6884765625, 0.6064453125, 0.107421875, 0.115234375), (0.328125, 0.6220703125, 0.15234375, 0.138671875), (0.7373046875, 0.5849609375, 0.107421875, 0.119140625)], 'case_00157_315': [(0.6904296875, 0.60546875, 0.111328125, 0.1171875), (0.3251953125, 0.6181640625, 0.150390625, 0.138671875), (0.73828125, 0.583984375, 0.10546875, 0.1171875)], 'case_00157_320': [(0.3212890625, 0.615234375, 0.142578125, 0.140625), (0.6923828125, 0.6044921875, 0.115234375, 0.119140625), (0.7373046875, 0.583984375, 0.103515625, 0.1171875)], 'case_00157_330': [(0.3115234375, 0.611328125, 0.119140625, 0.140625), (0.669921875, 0.6015625, 0.10546875, 0.12109375), (0.7431640625, 0.5908203125, 0.091796875, 0.107421875)], 'case_00157_325': [(0.3173828125, 0.6123046875, 0.134765625, 0.138671875), (0.6728515625, 0.6025390625, 0.103515625, 0.119140625), (0.7412109375, 0.5869140625, 0.099609375, 0.119140625)], 'case_00157_335': [(0.310546875, 0.609375, 0.1171875, 0.140625), (0.6708984375, 0.6005859375, 0.103515625, 0.119140625), (0.74609375, 0.5966796875, 0.0859375, 0.091796875)], 'case_00157_340': [(0.310546875, 0.607421875, 0.12109375, 0.140625), (0.6708984375, 0.599609375, 0.103515625, 0.12109375), (0.7470703125, 0.5947265625, 0.076171875, 0.087890625)], 'case_00157_345': [(0.310546875, 0.60546875, 0.125, 0.13671875), (0.67578125, 0.5966796875, 0.109375, 0.119140625), (0.75390625, 0.5888671875, 0.0546875, 0.072265625), (0.724609375, 0.611328125, 0.01953125, 0.03515625)], 'case_00157_350': [(0.3095703125, 0.6025390625, 0.130859375, 0.134765625), (0.6728515625, 0.5966796875, 0.099609375, 0.115234375), (0.755859375, 0.591796875, 0.0390625, 0.05859375)], 'case_00157_355': [(0.310546875, 0.6005859375, 0.1328125, 0.130859375), (0.673828125, 0.595703125, 0.1015625, 0.11328125), (0.751953125, 0.587890625, 0.02734375, 0.03515625)], 'case_00157_360': [(0.310546875, 0.5986328125, 0.1328125, 0.126953125), (0.673828125, 0.59375, 0.09765625, 0.109375)], 'case_00157_365': [(0.3095703125, 0.5966796875, 0.130859375, 0.123046875), (0.673828125, 0.59375, 0.09765625, 0.10546875)], 'case_00157_370': [(0.3076171875, 0.591796875, 0.126953125, 0.11328125), (0.6728515625, 0.5927734375, 0.091796875, 0.103515625)], 'case_00157_375': [(0.30859375, 0.5888671875, 0.125, 0.103515625), (0.6728515625, 0.591796875, 0.087890625, 0.09375)], 'case_00157_380': [(0.3076171875, 0.5859375, 0.119140625, 0.09765625), (0.6728515625, 0.58984375, 0.083984375, 0.08984375)], 'case_00157_385': [(0.3076171875, 0.5859375, 0.111328125, 0.09375), (0.6728515625, 0.5908203125, 0.076171875, 0.080078125)], 'case_00157_390': [(0.3076171875, 0.5859375, 0.103515625, 0.0859375), (0.6728515625, 0.58984375, 0.068359375, 0.07421875)], 'case_00157_395': [(0.3076171875, 0.5859375, 0.087890625, 0.07421875), (0.6728515625, 0.5888671875, 0.056640625, 0.060546875)], 'case_00157_400': [(0.3095703125, 0.583984375, 0.064453125, 0.05859375), (0.6689453125, 0.5869140625, 0.037109375, 0.044921875)], 'case_00157_405': [(0.3115234375, 0.580078125, 0.025390625, 0.0234375), (0.6640625, 0.580078125, 0.0078125, 0.0078125)], 'case_00157_410': [], 'case_00157_420': [], 'case_00157_415': [], 'case_00157_425': [], 'case_00157_430': [], 'case_00157_435': [], 'case_00157_440': [], 'case_00157_450': [], 'case_00157_445': [], 'case_00157_455': [], 'case_00157_460': [], 'case_00157_465': [], 'case_00157_470': [], 'case_00157_475': [], 'case_00157_480': [], 'case_00157_485': [], 'case_00157_490': [], 'case_00157_495': [], 'case_00157_500': [], 'case_00157_505': [], 'case_00157_510': [], 'case_00157_515': [], 'case_00157_520': [], 'case_00157_525': [], 'case_00157_530': [], 'case_00157_535': [], 'case_00157_540': [], 'case_00157_545': [], 'case_00088_0': [], 'case_00088_5': [], 'case_00088_20': [], 'case_00088_10': [], 'case_00088_15': [], 'case_00088_30': [], 'case_00088_25': [], 'case_00088_35': [], 'case_00088_40': [(0.6796875, 0.62109375, 0.2578125, 0.2578125)], 'case_00088_45': [(0.705078125, 0.6240234375, 0.30859375, 0.361328125)], 'case_00088_50': [(0.3681640625, 0.69140625, 0.119140625, 0.125), (0.8544921875, 0.6474609375, 0.001953125, 0.001953125), (0.7958984375, 0.7109375, 0.115234375, 0.125), (0.6201171875, 0.759765625, 0.087890625, 0.05078125), (0.705078125, 0.6025390625, 0.33203125, 0.365234375)], 'case_00088_55': [(0.3427734375, 0.6904296875, 0.166015625, 0.142578125), (0.8525390625, 0.642578125, 0.001953125, 0.00390625), (0.7177734375, 0.7099609375, 0.267578125, 0.130859375), (0.7119140625, 0.57421875, 0.306640625, 0.30078125)], 'case_00088_60': [(0.708984375, 0.6318359375, 0.23828125, 0.232421875), (0.353515625, 0.654296875, 0.19140625, 0.171875), (0.703125, 0.552734375, 0.2265625, 0.203125)], 'case_00088_65': [(0.6787109375, 0.611328125, 0.220703125, 0.1796875), (0.3564453125, 0.6376953125, 0.107421875, 0.091796875)], 'case_00088_70': [(0.6611328125, 0.60546875, 0.080078125, 0.03515625)], 'case_00088_75': [], 'case_00088_80': [], 'case_00088_85': [], 'case_00088_95': [], 'case_00088_90': [], 'case_00105_0': [], 'case_00105_15': [], 'case_00105_5': [], 'case_00105_10': [], 'case_00105_20': [], 'case_00105_30': [], 'case_00105_25': [], 'case_00105_35': [(0.5751953125, 0.646484375, 0.021484375, 0.02734375), (0.373046875, 0.6533203125, 0.09765625, 0.080078125)], 'case_00105_40': [(0.3779296875, 0.5986328125, 0.060546875, 0.041015625), (0.5908203125, 0.6513671875, 0.064453125, 0.080078125), (0.359375, 0.654296875, 0.11328125, 0.09765625)], 'case_00105_45': [(0.3505859375, 0.61328125, 0.111328125, 0.125), (0.59765625, 0.642578125, 0.09765625, 0.10546875), (0.359375, 0.6630859375, 0.0703125, 0.068359375)], 'case_00105_50': [(0.3447265625, 0.6064453125, 0.119140625, 0.134765625), (0.6083984375, 0.6240234375, 0.111328125, 0.119140625)], 'case_00105_55': [(0.3349609375, 0.5927734375, 0.111328125, 0.134765625), (0.6171875, 0.6044921875, 0.1171875, 0.130859375)], 'case_00105_60': [(0.6220703125, 0.5849609375, 0.111328125, 0.130859375), (0.3369140625, 0.583984375, 0.111328125, 0.125)], 'case_00105_65': [(0.619140625, 0.5693359375, 0.08984375, 0.103515625), (0.3447265625, 0.5703125, 0.099609375, 0.1015625)], 'case_00105_70': [(0.3466796875, 0.5615234375, 0.052734375, 0.060546875), (0.615234375, 0.5546875, 0.03125, 0.046875)], 'case_00105_75': [], 'case_00105_80': [], 'case_00105_85': [], 'case_00105_90': [], 'case_00105_95': [], 'case_00105_100': [], 'case_00105_105': [], 'case_00105_110': [], 'case_00105_115': [], 'case_00105_120': [], 'case_00105_125': [], 'case_00105_130': [], 'case_00105_135': [], 'case_00105_140': [], 'case_00105_145': [], 'case_00105_150': [], 'case_00164_0': [], 'case_00164_15': [], 'case_00164_20': [(0.685546875, 0.6298828125, 0.109375, 0.099609375), (0.3369140625, 0.6591796875, 0.166015625, 0.138671875)], 'case_00164_5': [], 'case_00164_10': [], 'case_00164_25': [(0.6904296875, 0.5927734375, 0.158203125, 0.185546875), (0.32421875, 0.6318359375, 0.19140625, 0.185546875)], 'case_00164_30': [(0.7080078125, 0.5810546875, 0.126953125, 0.181640625), (0.30078125, 0.615234375, 0.15234375, 0.1640625), (0.26953125, 0.5537109375, 0.05078125, 0.037109375)], 'case_00164_35': [(0.6728515625, 0.564453125, 0.150390625, 0.1484375), (0.3154296875, 0.6015625, 0.134765625, 0.125)], 'case_00164_40': [], 'case_00164_45': [], 'case_00164_50': [], 'case_00164_55': [], 'case_00164_60': [], 'case_00164_65': [], 'case_00164_70': [], 'case_00164_75': [], 'case_00164_80': [], 'case_00164_85': [], 'case_00060_0': [], 'case_00060_15': [], 'case_00060_10': [], 'case_00060_20': [], 'case_00060_5': [], 'case_00060_25': [], 'case_00060_30': [(0.6552734375, 0.6142578125, 0.021484375, 0.029296875)], 'case_00060_35': [(0.67578125, 0.6123046875, 0.12109375, 0.107421875), (0.4052734375, 0.5966796875, 0.033203125, 0.052734375)], 'case_00060_40': [(0.3896484375, 0.55078125, 0.115234375, 0.171875), (0.6845703125, 0.5966796875, 0.146484375, 0.138671875)], 'case_00060_45': [(0.376953125, 0.53125, 0.140625, 0.1953125), (0.6845703125, 0.5791015625, 0.123046875, 0.134765625)], 'case_00060_50': [(0.36328125, 0.5146484375, 0.1484375, 0.177734375), (0.693359375, 0.5732421875, 0.125, 0.126953125)], 'case_00060_55': [(0.3623046875, 0.4951171875, 0.123046875, 0.146484375), (0.6875, 0.572265625, 0.109375, 0.12890625), (0.2998046875, 0.5205078125, 0.001953125, 0.001953125), (0.341796875, 0.5517578125, 0.09765625, 0.095703125)], 'case_00060_60': [(0.3564453125, 0.50390625, 0.041015625, 0.03125), (0.3349609375, 0.5048828125, 0.001953125, 0.001953125), (0.6943359375, 0.5478515625, 0.056640625, 0.068359375), (0.3779296875, 0.5205078125, 0.001953125, 0.001953125), (0.345703125, 0.5439453125, 0.0859375, 0.080078125)], 'case_00060_65': [], 'case_00060_70': [], 'case_00060_75': [], 'case_00060_80': [], 'case_00060_85': [], 'case_00060_90': [], 'case_00060_95': [], 'case_00060_100': [], 'case_00060_110': [], 'case_00060_105': [], 'case_00060_115': [], 'case_00060_120': [], 'case_00060_125': [], 'case_00060_130': [], 'case_00020_0': [], 'case_00020_5': [], 'case_00020_10': [], 'case_00060_135': [], 'case_00020_15': [], 'case_00020_20': [(0.6669921875, 0.666015625, 0.041015625, 0.0546875)], 'case_00060_140': [], 'case_00020_25': [(0.6767578125, 0.6494140625, 0.126953125, 0.115234375), (0.31640625, 0.6474609375, 0.10546875, 0.080078125)], 'case_00020_30': [(0.6904296875, 0.630859375, 0.146484375, 0.12890625), (0.3017578125, 0.6357421875, 0.138671875, 0.115234375), (0.626953125, 0.63671875, 0.01953125, 0.0234375)], 'case_00020_35': [(0.7041015625, 0.61328125, 0.138671875, 0.12890625), (0.2939453125, 0.625, 0.130859375, 0.12890625)], 'case_00020_40': [(0.6953125, 0.59765625, 0.109375, 0.09375), (0.3076171875, 0.6171875, 0.119140625, 0.11328125)], 'case_00020_45': [(0.3203125, 0.6171875, 0.08203125, 0.0703125)], 'case_00020_50': [], 'case_00020_55': [], 'case_00020_60': [], 'case_00020_65': [], 'case_00020_70': [], 'case_00020_75': [], 'case_00020_80': [], 'case_00020_85': [], 'case_00020_90': [], 'case_00020_95': [], 'case_00177_0': [], 'case_00177_5': [], 'case_00177_10': [], 'case_00177_15': [], 'case_00177_20': [(0.3623046875, 0.6484375, 0.169921875, 0.1171875), (0.67578125, 0.6640625, 0.0625, 0.0859375)], 'case_00177_25': [(0.330078125, 0.62890625, 0.17578125, 0.15234375), (0.705078125, 0.638671875, 0.16796875, 0.14453125), (0.2880859375, 0.7060546875, 0.001953125, 0.001953125), (0.2822265625, 0.7099609375, 0.001953125, 0.001953125), (0.2529296875, 0.6728515625, 0.099609375, 0.111328125)], 'case_00177_30': [(0.7294921875, 0.6123046875, 0.169921875, 0.154296875), (0.328125, 0.61328125, 0.140625, 0.12890625)], 'case_00177_35': [(0.7197265625, 0.5908203125, 0.111328125, 0.123046875), (0.3427734375, 0.5947265625, 0.037109375, 0.029296875)], 'case_00177_40': [], 'case_00177_45': [], 'case_00177_50': [], 'case_00177_55': [], 'case_00177_60': [], 'case_00177_65': [], 'case_00177_70': [], 'case_00177_75': [], 'case_00177_80': [], 'case_00177_85': [], 'case_00071_0': [], 'case_00071_5': [], 'case_00071_10': [], 'case_00071_15': [], 'case_00071_20': [], 'case_00071_25': [], 'case_00071_30': [], 'case_00071_35': [], 'case_00071_40': [], 'case_00071_45': [], 'case_00071_50': [], 'case_00071_55': [(0.630859375, 0.712890625, 0.0625, 0.05859375)], 'case_00071_60': [(0.6328125, 0.708984375, 0.08203125, 0.078125)], 'case_00071_65': [(0.63671875, 0.7041015625, 0.09765625, 0.091796875)], 'case_00071_70': [(0.6416015625, 0.6982421875, 0.111328125, 0.111328125), (0.4208984375, 0.7080078125, 0.048828125, 0.048828125)], 'case_00071_75': [(0.6474609375, 0.6962890625, 0.126953125, 0.115234375), (0.4130859375, 0.7158203125, 0.083984375, 0.080078125)], 'case_00071_80': [(0.65234375, 0.6923828125, 0.13671875, 0.119140625), (0.4072265625, 0.7138671875, 0.103515625, 0.099609375)], 'case_00071_85': [(0.658203125, 0.693359375, 0.15234375, 0.125), (0.404296875, 0.7099609375, 0.1171875, 0.107421875)], 'case_00071_90': [(0.662109375, 0.69140625, 0.1640625, 0.125), (0.40234375, 0.7099609375, 0.125, 0.111328125)], 'case_00071_95': [(0.6689453125, 0.6865234375, 0.177734375, 0.126953125), (0.396484375, 0.7080078125, 0.1328125, 0.123046875)], 'case_00071_100': [(0.6728515625, 0.6865234375, 0.185546875, 0.130859375), (0.392578125, 0.7060546875, 0.140625, 0.123046875)], 'case_00071_105': [(0.6767578125, 0.68359375, 0.193359375, 0.12890625), (0.3896484375, 0.703125, 0.146484375, 0.12109375)], 'case_00071_110': [(0.6796875, 0.681640625, 0.203125, 0.1328125), (0.3857421875, 0.703125, 0.150390625, 0.12890625)], 'case_00071_115': [(0.6845703125, 0.6796875, 0.208984375, 0.1328125), (0.384765625, 0.697265625, 0.15625, 0.1328125)], 'case_00071_120': [(0.6884765625, 0.677734375, 0.208984375, 0.1328125), (0.3828125, 0.693359375, 0.1640625, 0.13671875)], 'case_00071_125': [(0.689453125, 0.67578125, 0.2109375, 0.13671875), (0.37890625, 0.6923828125, 0.1640625, 0.142578125), (0.7001953125, 0.7197265625, 0.041015625, 0.041015625)], 'case_00071_130': [(0.69140625, 0.6767578125, 0.20703125, 0.138671875), (0.37890625, 0.6904296875, 0.16796875, 0.142578125), (0.6962890625, 0.7197265625, 0.052734375, 0.052734375)], 'case_00071_135': [(0.6923828125, 0.673828125, 0.205078125, 0.1328125), (0.3759765625, 0.6884765625, 0.166015625, 0.146484375), (0.69140625, 0.71875, 0.0546875, 0.0546875)], 'case_00071_140': [(0.6953125, 0.6728515625, 0.19921875, 0.138671875), (0.375, 0.6875, 0.171875, 0.1484375), (0.6943359375, 0.72265625, 0.064453125, 0.05078125)], 'case_00071_145': [(0.69921875, 0.6708984375, 0.19140625, 0.126953125), (0.3740234375, 0.6884765625, 0.173828125, 0.146484375), (0.6943359375, 0.7099609375, 0.072265625, 0.072265625)], 'case_00071_150': [(0.708984375, 0.669921875, 0.171875, 0.1328125), (0.3720703125, 0.6865234375, 0.169921875, 0.146484375), (0.6982421875, 0.7138671875, 0.076171875, 0.068359375)], 'case_00071_155': [(0.708984375, 0.669921875, 0.16796875, 0.1328125), (0.3681640625, 0.685546875, 0.166015625, 0.14453125), (0.693359375, 0.7119140625, 0.0703125, 0.064453125)], 'case_00071_160': [(0.7109375, 0.669921875, 0.16796875, 0.12890625), (0.3662109375, 0.6845703125, 0.166015625, 0.142578125), (0.6953125, 0.7119140625, 0.0625, 0.056640625)], 'case_00071_165': [(0.7109375, 0.66796875, 0.16796875, 0.12890625), (0.3564453125, 0.6826171875, 0.146484375, 0.146484375), (0.7177734375, 0.7333984375, 0.001953125, 0.001953125), (0.7158203125, 0.7353515625, 0.001953125, 0.001953125), (0.7138671875, 0.7373046875, 0.001953125, 0.001953125), (0.7119140625, 0.7412109375, 0.005859375, 0.001953125), (0.697265625, 0.7109375, 0.0546875, 0.06640625)], 'case_00071_170': [(0.7080078125, 0.6669921875, 0.169921875, 0.126953125), (0.3564453125, 0.681640625, 0.146484375, 0.14453125), (0.693359375, 0.7080078125, 0.05078125, 0.044921875)], 'case_00071_175': [(0.7060546875, 0.6640625, 0.173828125, 0.125), (0.3603515625, 0.6806640625, 0.150390625, 0.142578125), (0.6962890625, 0.705078125, 0.044921875, 0.0390625)], 'case_00071_180': [(0.70703125, 0.6640625, 0.16796875, 0.125), (0.361328125, 0.677734375, 0.15234375, 0.140625), (0.6953125, 0.703125, 0.02734375, 0.01953125)], 'case_00071_185': [(0.70703125, 0.6630859375, 0.1640625, 0.126953125), (0.3623046875, 0.6748046875, 0.154296875, 0.134765625)], 'case_00071_190': [(0.7060546875, 0.662109375, 0.158203125, 0.12109375), (0.36328125, 0.6728515625, 0.15234375, 0.138671875), (0.3193359375, 0.7431640625, 0.001953125, 0.001953125)], 'case_00071_195': [(0.3642578125, 0.6708984375, 0.150390625, 0.134765625), (0.7041015625, 0.662109375, 0.150390625, 0.1171875)], 'case_00071_200': [(0.365234375, 0.669921875, 0.14453125, 0.1328125), (0.703125, 0.66015625, 0.14453125, 0.109375)], 'case_00071_205': [(0.3662109375, 0.6689453125, 0.138671875, 0.130859375), (0.701171875, 0.66015625, 0.13671875, 0.1015625)], 'case_00071_210': [(0.365234375, 0.66796875, 0.1328125, 0.125), (0.701171875, 0.662109375, 0.12890625, 0.09765625)], 'case_00071_215': [(0.365234375, 0.666015625, 0.12890625, 0.1171875), (0.701171875, 0.662109375, 0.1171875, 0.08984375)], 'case_00071_220': [(0.3671875, 0.666015625, 0.12109375, 0.1171875), (0.701171875, 0.66015625, 0.1015625, 0.08203125)], 'case_00071_225': [(0.3662109375, 0.6640625, 0.115234375, 0.11328125), (0.701171875, 0.658203125, 0.09375, 0.0703125)], 'case_00071_230': [(0.3671875, 0.662109375, 0.109375, 0.1015625), (0.7001953125, 0.65625, 0.080078125, 0.0625)], 'case_00071_235': [(0.3671875, 0.662109375, 0.1015625, 0.09765625), (0.7001953125, 0.65625, 0.060546875, 0.046875)], 'case_00071_240': [(0.3662109375, 0.66015625, 0.091796875, 0.0859375), (0.7001953125, 0.6552734375, 0.033203125, 0.029296875)], 'case_00071_245': [(0.3662109375, 0.6611328125, 0.080078125, 0.076171875)], 'case_00071_250': [(0.3662109375, 0.662109375, 0.064453125, 0.0625)], 'case_00071_255': [(0.3623046875, 0.666015625, 0.037109375, 0.0390625)], 'case_00071_260': [], 'case_00071_265': [], 'case_00071_270': [], 'case_00071_275': [], 'case_00071_280': [], 'case_00071_285': [], 'case_00071_290': [], 'case_00071_295': [], 'case_00071_300': [], 'case_00071_305': [], 'case_00071_310': [], 'case_00071_315': [], 'case_00071_320': [], 'case_00071_325': [], 'case_00071_330': [], 'case_00071_335': [], 'case_00071_340': [], 'case_00071_345': [], 'case_00071_350': [], 'case_00071_355': [], 'case_00071_360': [], 'case_00071_365': [], 'case_00071_370': [], 'case_00071_375': [], 'case_00071_380': [], 'case_00071_385': [], 'case_00071_390': [], 'case_00071_395': [], 'case_00071_400': [], 'case_00071_405': [], 'case_00071_410': [], 'case_00071_415': [], 'case_00071_420': [], 'case_00071_425': [], 'case_00071_430': [], 'case_00071_435': [], 'case_00071_440': [], 'case_00071_445': [], 'case_00071_450': [], 'case_00071_455': [], 'case_00071_460': [], 'case_00071_465': [], 'case_00071_470': [], 'case_00071_475': [], 'case_00071_480': [], 'case_00071_485': [], 'case_00071_490': [], 'case_00071_495': [], 'case_00071_500': [], 'case_00071_505': [], 'case_00071_510': [], 'case_00071_515': [], 'case_00071_520': [], 'case_00071_525': [], 'case_00071_530': [], 'case_00071_535': [], 'case_00071_540': [], 'case_00071_545': [], 'case_00071_550': [], 'case_00071_555': [], 'case_00071_560': [], 'case_00071_565': [], 'case_00071_570': [], 'case_00071_575': [], 'case_00071_580': [], 'case_00071_585': [], 'case_00071_590': [], 'case_00071_595': [], 'case_00071_600': [], 'case_00071_605': [], 'case_00071_610': [], 'case_00087_0': [], 'case_00087_5': [], 'case_00087_10': [], 'case_00087_15': [], 'case_00087_20': [(0.66015625, 0.6962890625, 0.09375, 0.087890625)], 'case_00087_25': [(0.3125, 0.6455078125, 0.17578125, 0.189453125), (0.69921875, 0.6669921875, 0.19140625, 0.169921875), (0.3193359375, 0.5908203125, 0.119140625, 0.111328125)], 'case_00087_30': [(0.298828125, 0.6142578125, 0.18359375, 0.181640625), (0.7333984375, 0.64453125, 0.181640625, 0.171875), (0.3427734375, 0.6005859375, 0.068359375, 0.052734375)], 'case_00087_35': [(0.3017578125, 0.5888671875, 0.181640625, 0.158203125), (0.734375, 0.6201171875, 0.15625, 0.134765625)], 'case_00087_40': [(0.3212890625, 0.5849609375, 0.033203125, 0.041015625)], 'case_00087_45': [], 'case_00179_0': [], 'case_00179_5': [], 'case_00179_10': [], 'case_00179_15': [], 'case_00179_20': [(0.3046875, 0.6376953125, 0.17578125, 0.154296875), (0.63671875, 0.6796875, 0.10546875, 0.1015625)], 'case_00179_25': [(0.2841796875, 0.6005859375, 0.189453125, 0.185546875), (0.6630859375, 0.6455078125, 0.177734375, 0.150390625)], 'case_00179_30': [(0.2607421875, 0.5576171875, 0.162109375, 0.181640625), (0.6962890625, 0.6259765625, 0.146484375, 0.162109375), (0.3388671875, 0.6494140625, 0.001953125, 0.001953125), (0.279296875, 0.6416015625, 0.17578125, 0.248046875)], 'case_00179_35': [(0.2509765625, 0.5390625, 0.068359375, 0.0703125), (0.6875, 0.6123046875, 0.140625, 0.142578125), (0.669921875, 0.6875, 0.0078125, 0.00390625), (0.2451171875, 0.65234375, 0.154296875, 0.1796875)], 'case_00179_40': [(0.7255859375, 0.5458984375, 0.041015625, 0.048828125), (0.6806640625, 0.5927734375, 0.095703125, 0.095703125)], 'case_00179_45': [], 'case_00179_50': [], 'case_00179_55': [], 'case_00179_60': [], 'case_00179_65': [], 'case_00179_70': [], 'case_00179_75': [], 'case_00179_80': [], 'case_00179_85': [], 'case_00179_90': [], 'case_00179_95': [], 'case_00072_0': [], 'case_00072_5': [], 'case_00072_10': [], 'case_00072_15': [], 'case_00072_20': [], 'case_00072_25': [(0.62890625, 0.7451171875, 0.09375, 0.083984375)], 'case_00072_30': [(0.6416015625, 0.736328125, 0.146484375, 0.1328125)], 'case_00072_35': [(0.6533203125, 0.724609375, 0.169921875, 0.15234375), (0.3701171875, 0.6953125, 0.080078125, 0.0859375)], 'case_00072_40': [(0.3486328125, 0.6845703125, 0.150390625, 0.142578125), (0.6650390625, 0.7119140625, 0.189453125, 0.166015625)], 'case_00072_45': [(0.3330078125, 0.671875, 0.177734375, 0.15625), (0.6962890625, 0.703125, 0.162109375, 0.16796875)], 'case_00072_50': [(0.3193359375, 0.6484375, 0.189453125, 0.1875), (0.6923828125, 0.6953125, 0.162109375, 0.1640625)], 'case_00072_55': [(0.296875, 0.6396484375, 0.1640625, 0.185546875), (0.681640625, 0.6845703125, 0.15625, 0.150390625)], 'case_00072_60': [(0.3017578125, 0.6240234375, 0.181640625, 0.185546875), (0.6748046875, 0.677734375, 0.123046875, 0.125)], 'case_00072_65': [(0.3056640625, 0.61328125, 0.166015625, 0.171875), (0.669921875, 0.6708984375, 0.05859375, 0.064453125), (0.2373046875, 0.623046875, 0.025390625, 0.01953125)], 'case_00072_70': [(0.30859375, 0.599609375, 0.13671875, 0.12890625), (0.2421875, 0.6240234375, 0.02734375, 0.037109375)], 'case_00072_75': [(0.3095703125, 0.59765625, 0.048828125, 0.05078125)], 'case_00072_80': [], 'case_00072_85': [], 'case_00072_90': [], 'case_00072_95': [], 'case_00072_100': [], 'case_00072_105': [], 'case_00072_110': [], 'case_00072_115': [], 'case_00072_120': [], 'case_00072_125': [], 'case_00072_130': [], 'case_00072_135': [], 'case_00072_140': [], 'case_00072_145': [], 'case_00072_150': [], 'case_00072_155': [], 'case_00072_160': [], 'case_00032_0': [], 'case_00032_5': [], 'case_00032_10': [], 'case_00032_15': [], 'case_00032_20': [], 'case_00032_25': [], 'case_00032_30': [], 'case_00032_35': [], 'case_00032_40': [(0.6123046875, 0.583984375, 0.072265625, 0.09375)], 'case_00032_45': [(0.623046875, 0.578125, 0.10546875, 0.12109375)], 'case_00032_50': [(0.6337890625, 0.576171875, 0.123046875, 0.1328125), (0.38671875, 0.5869140625, 0.07421875, 0.072265625), (0.3818359375, 0.646484375, 0.037109375, 0.03125)], 'case_00032_55': [(0.6435546875, 0.5771484375, 0.134765625, 0.126953125), (0.376953125, 0.5810546875, 0.12109375, 0.123046875), (0.3818359375, 0.6337890625, 0.060546875, 0.064453125)], 'case_00032_60': [(0.369140625, 0.5732421875, 0.13671875, 0.134765625), (0.6572265625, 0.572265625, 0.119140625, 0.12109375), (0.3779296875, 0.6181640625, 0.013671875, 0.013671875)], 'case_00032_65': [(0.666015625, 0.564453125, 0.1015625, 0.125), (0.359375, 0.5703125, 0.13671875, 0.125)], 'case_00032_70': [(0.66015625, 0.55859375, 0.1015625, 0.11328125), (0.34765625, 0.564453125, 0.12109375, 0.12109375)], 'case_00032_75': [(0.34375, 0.55859375, 0.12109375, 0.11328125), (0.6591796875, 0.5556640625, 0.076171875, 0.083984375)], 'case_00032_80': [(0.3525390625, 0.552734375, 0.099609375, 0.09765625)], 'case_00032_85': [(0.35546875, 0.5498046875, 0.0546875, 0.056640625)], 'case_00032_90': [], 'case_00032_95': [], 'case_00032_100': [], 'case_00032_105': [], 'case_00032_110': [], 'case_00032_115': [], 'case_00032_120': [], 'case_00032_125': [], 'case_00032_130': [], 'case_00032_135': [], 'case_00032_140': [], 'case_00032_145': [], 'case_00032_150': [], 'case_00032_155': [], 'case_00032_160': [], 'case_00032_165': [], 'case_00032_170': [], 'case_00032_175': [], 'case_00032_180': [], 'case_00032_185': [], 'case_00183_0': [], 'case_00183_5': [], 'case_00183_10': [], 'case_00183_15': [], 'case_00183_20': [], 'case_00183_25': [], 'case_00183_30': [], 'case_00183_35': [], 'case_00183_40': [], 'case_00183_45': [], 'case_00183_50': [], 'case_00183_55': [], 'case_00183_60': [], 'case_00183_65': [], 'case_00183_70': [], 'case_00183_75': [], 'case_00183_80': [(0.33984375, 0.54296875, 0.05859375, 0.0546875)], 'case_00183_85': [(0.333984375, 0.5361328125, 0.109375, 0.099609375)], 'case_00183_90': [(0.33203125, 0.5302734375, 0.12890625, 0.130859375)], 'case_00183_95': [(0.3203125, 0.52734375, 0.1484375, 0.14453125), (0.6982421875, 0.5302734375, 0.060546875, 0.060546875)], 'case_00183_100': [(0.310546875, 0.5185546875, 0.15625, 0.166015625), (0.697265625, 0.5263671875, 0.09765625, 0.095703125)], 'case_00183_105': [(0.30078125, 0.5078125, 0.15234375, 0.171875), (0.6806640625, 0.494140625, 0.091796875, 0.08203125), (0.6513671875, 0.5361328125, 0.001953125, 0.001953125), (0.697265625, 0.5205078125, 0.09375, 0.107421875)], 'case_00183_110': [(0.28125, 0.5048828125, 0.1484375, 0.169921875), (0.68359375, 0.49609375, 0.12890625, 0.13671875), (0.6923828125, 0.5654296875, 0.009765625, 0.001953125), (0.7041015625, 0.5302734375, 0.083984375, 0.068359375)], 'case_00183_115': [(0.6796875, 0.4912109375, 0.140625, 0.146484375), (0.2783203125, 0.5048828125, 0.134765625, 0.154296875), (0.7236328125, 0.52734375, 0.044921875, 0.046875)], 'case_00183_120': [(0.6787109375, 0.478515625, 0.138671875, 0.1640625), (0.2802734375, 0.501953125, 0.119140625, 0.15234375)], 'case_00183_125': [(0.681640625, 0.4697265625, 0.14453125, 0.177734375), (0.28125, 0.5, 0.12109375, 0.140625)], 'case_00183_130': [(0.6865234375, 0.458984375, 0.150390625, 0.1796875), (0.2724609375, 0.49609375, 0.111328125, 0.109375)], 'case_00183_135': [(0.6767578125, 0.453125, 0.166015625, 0.18359375), (0.2587890625, 0.4931640625, 0.083984375, 0.083984375)], 'case_00183_140': [(0.6767578125, 0.4482421875, 0.166015625, 0.173828125), (0.2548828125, 0.4853515625, 0.048828125, 0.044921875)], 'case_00183_145': [(0.6796875, 0.439453125, 0.1640625, 0.15625)], 'case_00183_150': [(0.6728515625, 0.435546875, 0.154296875, 0.14453125)], 'case_00183_155': [(0.66796875, 0.4326171875, 0.13671875, 0.111328125)], 'case_00183_160': [(0.6728515625, 0.43359375, 0.134765625, 0.11328125)], 'case_00183_165': [(0.6728515625, 0.4326171875, 0.119140625, 0.099609375)], 'case_00183_170': [(0.65625, 0.4208984375, 0.0546875, 0.052734375)], 'case_00183_175': [], 'case_00183_180': [], 'case_00183_185': [], 'case_00183_190': [], 'case_00191_0': [], 'case_00191_5': [], 'case_00191_10': [], 'case_00191_15': [], 'case_00191_20': [], 'case_00191_25': [], 'case_00191_30': [], 'case_00191_35': [], 'case_00191_40': [], 'case_00191_45': [], 'case_00191_50': [], 'case_00191_55': [], 'case_00191_60': [], 'case_00191_65': [], 'case_00191_70': [], 'case_00191_75': [], 'case_00191_80': [], 'case_00191_85': [], 'case_00191_90': [(0.662109375, 0.6474609375, 0.0625, 0.087890625)], 'case_00191_95': [(0.673828125, 0.6484375, 0.09375, 0.1171875)], 'case_00191_100': [(0.6845703125, 0.646484375, 0.119140625, 0.1328125)], 'case_00191_105': [(0.6962890625, 0.6455078125, 0.142578125, 0.146484375)], 'case_00191_110': [(0.7021484375, 0.6435546875, 0.158203125, 0.154296875), (0.365234375, 0.638671875, 0.0625, 0.07421875)], 'case_00191_115': [(0.7099609375, 0.638671875, 0.169921875, 0.16796875), (0.3564453125, 0.640625, 0.091796875, 0.109375)], 'case_00191_120': [(0.7158203125, 0.634765625, 0.177734375, 0.171875), (0.3505859375, 0.6376953125, 0.115234375, 0.130859375)], 'case_00191_125': [(0.7216796875, 0.6328125, 0.181640625, 0.17578125), (0.3466796875, 0.63671875, 0.126953125, 0.15234375)], 'case_00191_130': [(0.732421875, 0.63671875, 0.171875, 0.16796875), (0.341796875, 0.63671875, 0.14453125, 0.16015625)], 'case_00191_135': [(0.33984375, 0.6298828125, 0.15234375, 0.169921875), (0.748046875, 0.6416015625, 0.15234375, 0.154296875)], 'case_00191_140': [(0.3359375, 0.6259765625, 0.16015625, 0.173828125), (0.7509765625, 0.6376953125, 0.154296875, 0.158203125)], 'case_00191_145': [(0.3330078125, 0.6201171875, 0.162109375, 0.173828125), (0.7490234375, 0.62890625, 0.162109375, 0.16796875)], 'case_00191_150': [(0.3251953125, 0.6181640625, 0.154296875, 0.169921875), (0.7431640625, 0.626953125, 0.158203125, 0.16796875)], 'case_00191_155': [(0.30859375, 0.6171875, 0.1328125, 0.1640625), (0.7392578125, 0.6259765625, 0.142578125, 0.162109375)], 'case_00191_160': [(0.3125, 0.607421875, 0.140625, 0.171875), (0.736328125, 0.626953125, 0.1328125, 0.14453125)], 'case_00191_165': [(0.31640625, 0.60546875, 0.15234375, 0.171875), (0.7333984375, 0.625, 0.119140625, 0.12109375)], 'case_00191_170': [(0.3173828125, 0.603515625, 0.146484375, 0.1640625), (0.73046875, 0.619140625, 0.09375, 0.09375), (0.7177734375, 0.6044921875, 0.013671875, 0.013671875)], 'case_00191_175': [(0.3173828125, 0.6005859375, 0.138671875, 0.158203125), (0.7451171875, 0.5986328125, 0.001953125, 0.001953125), (0.7255859375, 0.62109375, 0.052734375, 0.0390625), (0.6982421875, 0.6201171875, 0.001953125, 0.001953125), (0.7197265625, 0.6044921875, 0.052734375, 0.044921875)], 'case_00191_180': [(0.3203125, 0.5947265625, 0.125, 0.142578125), (0.7177734375, 0.6044921875, 0.029296875, 0.033203125)], 'case_00191_185': [(0.32421875, 0.591796875, 0.109375, 0.12890625)], 'case_00191_190': [(0.3291015625, 0.5869140625, 0.080078125, 0.099609375)], 'case_00191_195': [(0.3369140625, 0.5810546875, 0.017578125, 0.025390625)], 'case_00191_200': [], 'case_00191_205': [], 'case_00191_210': [], 'case_00191_215': [], 'case_00191_220': [], 'case_00191_225': [], 'case_00191_230': [], 'case_00191_235': [], 'case_00191_240': [], 'case_00191_245': [], 'case_00191_250': [], 'case_00191_255': [], 'case_00191_260': [], 'case_00191_265': [], 'case_00191_270': [], 'case_00191_275': [], 'case_00191_280': [], 'case_00191_285': [], 'case_00191_290': [], 'case_00191_295': [], 'case_00191_300': [], 'case_00191_305': [], 'case_00191_310': [], 'case_00191_315': [], 'case_00191_320': [], 'case_00191_325': [], 'case_00191_330': [], 'case_00191_335': [], 'case_00191_340': [], 'case_00191_345': [], 'case_00203_40': [], 'case_00203_45': [], 'case_00203_50': [], 'case_00203_60': [], 'case_00203_55': [], 'case_00203_65': [], 'case_00203_70': [], 'case_00203_75': [], 'case_00203_80': [], 'case_00203_85': [], 'case_00203_90': [], 'case_00203_95': [], 'case_00203_100': [], 'case_00203_105': [], 'case_00203_110': [], 'case_00203_115': [], 'case_00203_120': [], 'case_00203_125': [], 'case_00203_130': [], 'case_00203_135': [], 'case_00203_140': [], 'case_00203_145': [], 'case_00203_155': [], 'case_00203_150': [], 'case_00203_160': [], 'case_00203_170': [], 'case_00203_165': [], 'case_00203_175': [], 'case_00203_185': [], 'case_00203_180': [], 'case_00203_190': [], 'case_00203_195': [], 'case_00203_200': [], 'case_00203_205': [], 'case_00203_210': [], 'case_00203_215': [], 'case_00203_220': [], 'case_00203_225': [], 'case_00203_230': [], 'case_00203_235': [], 'case_00203_240': [], 'case_00203_245': [], 'case_00203_250': [], 'case_00203_255': [], 'case_00203_260': [], 'case_00203_265': [], 'case_00203_270': [], 'case_00203_275': [], 'case_00203_280': [], 'case_00203_285': [], 'case_00203_290': [], 'case_00203_295': [], 'case_00203_300': [], 'case_00203_305': [(0.703125, 0.6259765625, 0.1171875, 0.076171875)], 'case_00203_310': [(0.708984375, 0.6201171875, 0.140625, 0.091796875)], 'case_00203_315': [(0.7158203125, 0.61328125, 0.150390625, 0.1015625)], 'case_00203_320': [(0.7216796875, 0.6064453125, 0.158203125, 0.111328125)], 'case_00203_325': [(0.724609375, 0.6005859375, 0.15625, 0.119140625)], 'case_00203_330': [(0.7294921875, 0.595703125, 0.154296875, 0.12890625)], 'case_00203_335': [(0.734375, 0.58984375, 0.14453125, 0.1328125)], 'case_00203_340': [(0.7373046875, 0.587890625, 0.146484375, 0.13671875)], 'case_00203_345': [(0.7373046875, 0.5830078125, 0.146484375, 0.138671875), (0.8056640625, 0.59375, 0.041015625, 0.0390625)], 'case_00203_350': [(0.736328125, 0.58203125, 0.13671875, 0.13671875), (0.380859375, 0.583984375, 0.046875, 0.078125), (0.8046875, 0.59375, 0.0546875, 0.0546875)], 'case_00203_355': [(0.73828125, 0.5791015625, 0.1328125, 0.134765625), (0.37109375, 0.580078125, 0.078125, 0.109375), (0.8056640625, 0.5927734375, 0.052734375, 0.052734375)], 'case_00203_360': [(0.3642578125, 0.5576171875, 0.099609375, 0.169921875), (0.7353515625, 0.576171875, 0.119140625, 0.12890625), (0.79296875, 0.5849609375, 0.00390625, 0.005859375), (0.8056640625, 0.5947265625, 0.021484375, 0.021484375), (0.7900390625, 0.5888671875, 0.001953125, 0.001953125)], 'case_00203_365': [(0.3525390625, 0.546875, 0.119140625, 0.1953125), (0.736328125, 0.5751953125, 0.1171875, 0.123046875)], 'case_00203_370': [(0.3466796875, 0.53125, 0.126953125, 0.21875), (0.736328125, 0.57421875, 0.1015625, 0.11328125)], 'case_00203_375': [(0.33984375, 0.5234375, 0.140625, 0.2265625), (0.732421875, 0.5732421875, 0.08203125, 0.103515625)], 'case_00203_380': [(0.3408203125, 0.515625, 0.146484375, 0.22265625), (0.73046875, 0.5703125, 0.06640625, 0.078125)], 'case_00203_385': [(0.3369140625, 0.5068359375, 0.142578125, 0.216796875), (0.720703125, 0.560546875, 0.00390625, 0.00390625)], 'case_00203_390': [(0.333984375, 0.498046875, 0.1328125, 0.2109375)], 'case_00203_395': [(0.333984375, 0.4912109375, 0.1171875, 0.189453125)], 'case_00203_400': [(0.33203125, 0.4794921875, 0.1015625, 0.162109375)], 'case_00203_405': [(0.3349609375, 0.4599609375, 0.076171875, 0.111328125)], 'case_00203_410': [], 'case_00203_415': [], 'case_00203_420': [], 'case_00203_425': [], 'case_00203_430': [], 'case_00203_435': [], 'case_00203_440': [], 'case_00203_445': [], 'case_00203_450': [], 'case_00203_455': [], 'case_00203_460': [], 'case_00203_465': [], 'case_00203_475': [], 'case_00203_470': [], 'case_00203_480': [], 'case_00203_485': [], 'case_00203_490': [], 'case_00203_495': [], 'case_00203_500': [], 'case_00203_505': [], 'case_00203_510': [], 'case_00203_515': [], 'case_00203_520': [], 'case_00203_525': [], 'case_00203_530': [], 'case_00203_535': [], 'case_00203_540': [], 'case_00203_545': [], 'case_00203_550': [], 'case_00203_560': [], 'case_00203_555': [], 'case_00203_565': [], 'case_00203_570': [], 'case_00203_575': [], 'case_00203_580': [], 'case_00203_585': [], 'case_00203_595': [], 'case_00203_590': [], 'case_00203_605': [], 'case_00203_600': [], 'case_00203_610': [], 'case_00203_615': [], 'case_00184_15': [], 'case_00184_5': [], 'case_00184_20': [], 'case_00184_10': [], 'case_00184_0': [], 'case_00184_25': [], 'case_00184_30': [], 'case_00184_35': [], 'case_00184_40': [], 'case_00184_45': [], 'case_00184_50': [], 'case_00184_55': [(0.392578125, 0.6162109375, 0.05859375, 0.060546875), (0.630859375, 0.626953125, 0.03125, 0.04296875)], 'case_00184_60': [(0.6845703125, 0.5146484375, 0.001953125, 0.001953125), (0.6689453125, 0.591796875, 0.166015625, 0.1484375), (0.5888671875, 0.54296875, 0.029296875, 0.03125), (0.3583984375, 0.5419921875, 0.001953125, 0.001953125), (0.369140625, 0.58984375, 0.1015625, 0.09375), (0.6708984375, 0.517578125, 0.029296875, 0.03125), (0.3779296875, 0.546875, 0.041015625, 0.04296875), (0.63671875, 0.576171875, 0.04296875, 0.0390625), (0.3623046875, 0.6220703125, 0.048828125, 0.044921875)], 'case_00184_65': [(0.34375, 0.50390625, 0.17578125, 0.23046875), (0.6884765625, 0.5830078125, 0.162109375, 0.138671875), (0.595703125, 0.548828125, 0.046875, 0.0546875), (0.7080078125, 0.5, 0.095703125, 0.11328125), (0.2958984375, 0.484375, 0.060546875, 0.0546875), (0.376953125, 0.4775390625, 0.046875, 0.037109375)], 'case_00184_70': [(0.330078125, 0.513671875, 0.16796875, 0.17578125), (0.6943359375, 0.560546875, 0.162109375, 0.14453125), (0.7216796875, 0.4912109375, 0.158203125, 0.150390625), (0.3447265625, 0.4326171875, 0.033203125, 0.029296875), (0.2958984375, 0.48828125, 0.037109375, 0.03515625), (0.380859375, 0.572265625, 0.0390625, 0.03515625), (0.33203125, 0.59765625, 0.046875, 0.0390625)], 'case_00184_75': [(0.3310546875, 0.505859375, 0.154296875, 0.13671875), (0.693359375, 0.5419921875, 0.11328125, 0.099609375), (0.353515625, 0.4384765625, 0.05859375, 0.041015625), (0.7119140625, 0.4775390625, 0.111328125, 0.080078125), (0.337890625, 0.5185546875, 0.05078125, 0.033203125), (0.3408203125, 0.568359375, 0.052734375, 0.05078125)], 'case_00184_80': [(0.3427734375, 0.48046875, 0.068359375, 0.0546875)], 'case_00184_85': [], 'case_00184_90': [], 'case_00184_100': [], 'case_00184_95': [], 'case_00184_105': [], 'case_00184_110': [], 'case_00184_115': [], 'case_00184_120': [], 'case_00184_125': [], 'case_00184_135': [], 'case_00184_130': [], 'case_00184_145': [], 'case_00184_140': [], 'case_00199_0': [], 'case_00199_10': [], 'case_00199_5': [], 'case_00199_25': [], 'case_00199_15': [], 'case_00199_20': [], 'case_00199_30': [], 'case_00199_40': [], 'case_00199_35': [], 'case_00199_45': [], 'case_00199_50': [(0.67578125, 0.509765625, 0.1328125, 0.14453125)], 'case_00199_55': [(0.697265625, 0.50390625, 0.1796875, 0.16796875)], 'case_00199_60': [(0.71484375, 0.4951171875, 0.1953125, 0.173828125), (0.3193359375, 0.517578125, 0.091796875, 0.1171875)], 'case_00199_65': [(0.3154296875, 0.4580078125, 0.197265625, 0.251953125), (0.724609375, 0.4833984375, 0.1796875, 0.173828125)], 'case_00199_70': [(0.31640625, 0.435546875, 0.2421875, 0.28125), (0.734375, 0.470703125, 0.1484375, 0.17578125), (0.296875, 0.4775390625, 0.09765625, 0.076171875)], 'case_00199_75': [(0.32421875, 0.3798828125, 0.23828125, 0.193359375), (0.73046875, 0.4658203125, 0.15234375, 0.166015625), (0.2041015625, 0.4306640625, 0.001953125, 0.001953125), (0.2880859375, 0.494140625, 0.197265625, 0.171875)], 'case_00199_80': [(0.3349609375, 0.361328125, 0.185546875, 0.140625), (0.73046875, 0.45703125, 0.12890625, 0.12890625), (0.275390625, 0.482421875, 0.18359375, 0.18359375)], 'case_00199_85': [(0.732421875, 0.4599609375, 0.08203125, 0.064453125), (0.2724609375, 0.4794921875, 0.154296875, 0.158203125)], 'case_00199_90': [(0.283203125, 0.4814453125, 0.09375, 0.103515625)], 'case_00199_95': [], 'case_00199_100': [], 'case_00199_105': [], 'case_00199_110': [], 'case_00199_115': [], 'case_00199_120': [], 'case_00155_0': [], 'case_00155_10': [], 'case_00155_5': [], 'case_00155_15': [], 'case_00155_25': [], 'case_00155_20': [], 'case_00155_30': [], 'case_00155_35': [], 'case_00155_40': [], 'case_00155_45': [], 'case_00155_50': [], 'case_00155_55': [], 'case_00155_60': [], 'case_00155_65': [], 'case_00155_70': [], 'case_00155_75': [], 'case_00155_80': [], 'case_00155_85': [(0.6337890625, 0.673828125, 0.029296875, 0.04296875)], 'case_00155_90': [(0.6376953125, 0.6728515625, 0.056640625, 0.052734375)], 'case_00155_95': [(0.640625, 0.673828125, 0.06640625, 0.0703125)], 'case_00155_100': [(0.642578125, 0.671875, 0.07421875, 0.078125)], 'case_00155_105': [(0.64453125, 0.673828125, 0.08203125, 0.08203125)], 'case_00155_110': [(0.6455078125, 0.6728515625, 0.091796875, 0.091796875)], 'case_00155_115': [(0.6474609375, 0.6708984375, 0.099609375, 0.095703125)], 'case_00155_120': [(0.6484375, 0.66796875, 0.10546875, 0.1015625)], 'case_00155_125': [(0.6494140625, 0.6650390625, 0.111328125, 0.107421875)], 'case_00155_130': [(0.650390625, 0.6630859375, 0.1171875, 0.115234375)], 'case_00155_135': [(0.6533203125, 0.6591796875, 0.119140625, 0.119140625)], 'case_00155_140': [(0.6552734375, 0.6552734375, 0.123046875, 0.126953125)], 'case_00155_145': [(0.6572265625, 0.65234375, 0.126953125, 0.1328125), (0.404296875, 0.6611328125, 0.01953125, 0.025390625)], 'case_00155_150': [(0.658203125, 0.650390625, 0.12890625, 0.13671875), (0.396484375, 0.6650390625, 0.0390625, 0.052734375)], 'case_00155_155': [(0.66015625, 0.646484375, 0.1328125, 0.140625), (0.39453125, 0.6630859375, 0.05078125, 0.060546875)], 'case_00155_160': [(0.662109375, 0.64453125, 0.1328125, 0.14453125), (0.392578125, 0.6611328125, 0.0625, 0.072265625)], 'case_00155_165': [(0.666015625, 0.6435546875, 0.1328125, 0.146484375), (0.3896484375, 0.6591796875, 0.072265625, 0.076171875)], 'case_00155_170': [(0.666015625, 0.640625, 0.13671875, 0.14453125), (0.384765625, 0.6552734375, 0.0859375, 0.080078125)], 'case_00155_175': [(0.66796875, 0.638671875, 0.13671875, 0.14453125), (0.3818359375, 0.6552734375, 0.091796875, 0.091796875)], 'case_00155_180': [(0.669921875, 0.6376953125, 0.13671875, 0.146484375), (0.3779296875, 0.654296875, 0.099609375, 0.09765625)], 'case_00155_185': [(0.6728515625, 0.6357421875, 0.134765625, 0.146484375), (0.3759765625, 0.6513671875, 0.103515625, 0.107421875)], 'case_00155_190': [(0.673828125, 0.634765625, 0.13671875, 0.1484375), (0.373046875, 0.6494140625, 0.109375, 0.111328125)], 'case_00155_195': [(0.673828125, 0.6318359375, 0.140625, 0.150390625), (0.3701171875, 0.6474609375, 0.115234375, 0.115234375)], 'case_00155_200': [(0.673828125, 0.630859375, 0.14453125, 0.15234375), (0.3671875, 0.6474609375, 0.12109375, 0.115234375)], 'case_00155_205': [(0.673828125, 0.626953125, 0.1484375, 0.15625), (0.3642578125, 0.6455078125, 0.123046875, 0.115234375)], 'case_00155_210': [(0.6728515625, 0.625, 0.150390625, 0.15625), (0.36328125, 0.634765625, 0.12890625, 0.13671875)], 'case_00155_215': [(0.6728515625, 0.623046875, 0.150390625, 0.15625), (0.3603515625, 0.6328125, 0.130859375, 0.140625)], 'case_00155_220': [(0.671875, 0.62109375, 0.15234375, 0.15234375), (0.3583984375, 0.6318359375, 0.130859375, 0.142578125)], 'case_00155_225': [(0.671875, 0.6181640625, 0.15234375, 0.150390625), (0.35546875, 0.626953125, 0.1328125, 0.1484375)], 'case_00155_230': [(0.6728515625, 0.6181640625, 0.150390625, 0.150390625), (0.353515625, 0.62109375, 0.1328125, 0.15234375)], 'case_00155_235': [(0.6708984375, 0.615234375, 0.154296875, 0.1484375), (0.3505859375, 0.6201171875, 0.134765625, 0.154296875)], 'case_00155_240': [(0.349609375, 0.6162109375, 0.1328125, 0.158203125), (0.671875, 0.615234375, 0.14453125, 0.1484375)], 'case_00155_245': [(0.3447265625, 0.61328125, 0.126953125, 0.16015625), (0.6728515625, 0.61328125, 0.138671875, 0.14453125)], 'case_00155_250': [(0.3427734375, 0.6123046875, 0.126953125, 0.158203125), (0.67578125, 0.6123046875, 0.12890625, 0.138671875)], 'case_00155_255': [(0.341796875, 0.609375, 0.125, 0.15625), (0.6806640625, 0.6103515625, 0.111328125, 0.134765625)], 'case_00155_260': [(0.3408203125, 0.607421875, 0.123046875, 0.15625), (0.681640625, 0.6083984375, 0.10546875, 0.130859375)], 'case_00155_265': [(0.337890625, 0.6064453125, 0.1171875, 0.150390625), (0.681640625, 0.6083984375, 0.1015625, 0.123046875)], 'case_00155_270': [(0.337890625, 0.60546875, 0.12109375, 0.1484375), (0.68359375, 0.607421875, 0.09765625, 0.1171875)], 'case_00155_275': [(0.3349609375, 0.603515625, 0.115234375, 0.14453125), (0.68359375, 0.6064453125, 0.09375, 0.111328125)], 'case_00155_280': [(0.3349609375, 0.6015625, 0.115234375, 0.140625), (0.685546875, 0.6044921875, 0.09375, 0.103515625)], 'case_00155_285': [(0.3359375, 0.599609375, 0.1171875, 0.140625), (0.6875, 0.603515625, 0.09375, 0.09765625)], 'case_00155_290': [(0.3369140625, 0.5986328125, 0.119140625, 0.138671875), (0.6787109375, 0.6025390625, 0.072265625, 0.087890625), (0.716796875, 0.6142578125, 0.0390625, 0.041015625)], 'case_00155_295': [(0.3388671875, 0.5947265625, 0.123046875, 0.134765625), (0.677734375, 0.6015625, 0.0625, 0.078125), (0.72265625, 0.6123046875, 0.03515625, 0.048828125)], 'case_00155_300': [(0.33984375, 0.59375, 0.12109375, 0.1328125), (0.6806640625, 0.59765625, 0.052734375, 0.06640625), (0.724609375, 0.61328125, 0.04296875, 0.05078125)], 'case_00155_305': [(0.33984375, 0.5908203125, 0.1171875, 0.126953125), (0.6826171875, 0.5947265625, 0.048828125, 0.052734375), (0.7255859375, 0.615234375, 0.048828125, 0.0546875)], 'case_00155_310': [(0.33984375, 0.5888671875, 0.11328125, 0.123046875), (0.6865234375, 0.59375, 0.033203125, 0.0390625), (0.7216796875, 0.619140625, 0.056640625, 0.0546875)], 'case_00155_315': [(0.337890625, 0.5859375, 0.10546875, 0.11328125), (0.724609375, 0.6181640625, 0.05078125, 0.052734375)], 'case_00155_320': [(0.3388671875, 0.5830078125, 0.091796875, 0.107421875), (0.72265625, 0.6181640625, 0.046875, 0.048828125)], 'case_00155_325': [(0.3369140625, 0.5830078125, 0.083984375, 0.099609375), (0.7080078125, 0.5888671875, 0.001953125, 0.001953125), (0.7060546875, 0.5908203125, 0.001953125, 0.001953125), (0.7041015625, 0.5927734375, 0.001953125, 0.001953125), (0.72265625, 0.6181640625, 0.04296875, 0.041015625)], 'case_00155_330': [(0.3349609375, 0.580078125, 0.072265625, 0.08984375), (0.716796875, 0.6181640625, 0.03515625, 0.033203125)], 'case_00155_335': [(0.3330078125, 0.578125, 0.060546875, 0.078125), (0.7177734375, 0.6181640625, 0.021484375, 0.017578125)], 'case_00155_340': [(0.33203125, 0.5771484375, 0.046875, 0.060546875)], 'case_00155_345': [(0.3291015625, 0.5771484375, 0.025390625, 0.033203125)], 'case_00155_350': [], 'case_00155_355': [], 'case_00155_360': [], 'case_00155_365': [], 'case_00155_370': [], 'case_00155_375': [], 'case_00155_380': [], 'case_00155_385': [], 'case_00155_390': [], 'case_00155_395': [], 'case_00155_400': [], 'case_00155_405': [], 'case_00155_410': [], 'case_00155_415': [], 'case_00155_420': [], 'case_00155_425': [], 'case_00155_430': [], 'case_00155_435': [], 'case_00155_440': [], 'case_00155_445': [], 'case_00155_450': [], 'case_00155_455': [], 'case_00155_460': [], 'case_00155_465': [], 'case_00155_470': [], 'case_00155_475': [], 'case_00155_480': [], 'case_00155_485': [], 'case_00155_490': [], 'case_00155_495': [], 'case_00155_500': [], 'case_00155_505': [], 'case_00155_510': [], 'case_00155_515': [], 'case_00155_520': [], 'case_00155_530': [], 'case_00155_525': [], 'case_00155_535': [], 'case_00121_5': [], 'case_00121_0': [], 'case_00121_10': [(0.6328125, 0.68359375, 0.12109375, 0.1015625), (0.6064453125, 0.703125, 0.041015625, 0.04296875)], 'case_00121_15': [(0.6572265625, 0.65625, 0.185546875, 0.15625), (0.3232421875, 0.6884765625, 0.087890625, 0.103515625)], 'case_00121_20': [(0.6982421875, 0.640625, 0.115234375, 0.1328125), (0.2978515625, 0.669921875, 0.138671875, 0.13671875)], 'case_00121_25': [(0.2705078125, 0.640625, 0.130859375, 0.15625), (0.6845703125, 0.6416015625, 0.099609375, 0.087890625)], 'case_00121_30': [(0.2587890625, 0.6162109375, 0.099609375, 0.123046875)], 'case_00121_35': [], 'case_00121_40': [], 'case_00121_45': [], 'case_00121_50': [], 'case_00121_55': [], 'case_00121_60': [], 'case_00121_65': [], 'case_00121_70': [], 'case_00121_75': [], 'case_00068_0': [], 'case_00068_5': [], 'case_00068_15': [], 'case_00068_10': [], 'case_00068_20': [], 'case_00068_25': [], 'case_00068_30': [], 'case_00068_35': [], 'case_00068_40': [], 'case_00068_45': [], 'case_00068_50': [], 'case_00068_55': [], 'case_00068_60': [], 'case_00068_65': [], 'case_00068_70': [], 'case_00068_75': [], 'case_00068_80': [], 'case_00068_85': [], 'case_00068_90': [], 'case_00068_95': [], 'case_00068_100': [], 'case_00068_105': [], 'case_00068_110': [], 'case_00068_115': [], 'case_00068_120': [], 'case_00068_125': [], 'case_00068_130': [(0.6708984375, 0.64453125, 0.017578125, 0.015625)], 'case_00068_135': [(0.6845703125, 0.63671875, 0.048828125, 0.05078125)], 'case_00068_140': [(0.310546875, 0.603515625, 0.02734375, 0.02734375), (0.6875, 0.6376953125, 0.0703125, 0.080078125)], 'case_00068_145': [(0.3134765625, 0.607421875, 0.060546875, 0.05859375), (0.6904296875, 0.6376953125, 0.087890625, 0.099609375)], 'case_00068_150': [(0.3125, 0.6064453125, 0.07421875, 0.076171875), (0.6904296875, 0.6357421875, 0.103515625, 0.115234375)], 'case_00068_155': [(0.310546875, 0.60546875, 0.08984375, 0.09375), (0.69140625, 0.634765625, 0.1171875, 0.12890625)], 'case_00068_160': [(0.306640625, 0.607421875, 0.1015625, 0.10546875), (0.69140625, 0.6318359375, 0.12890625, 0.142578125)], 'case_00068_165': [(0.3046875, 0.6044921875, 0.11328125, 0.119140625), (0.693359375, 0.6298828125, 0.140625, 0.150390625)], 'case_00068_170': [(0.3046875, 0.599609375, 0.125, 0.12890625), (0.6962890625, 0.62890625, 0.150390625, 0.15625)], 'case_00068_175': [(0.302734375, 0.595703125, 0.13671875, 0.140625), (0.6982421875, 0.6279296875, 0.158203125, 0.162109375)], 'case_00068_180': [(0.30078125, 0.59375, 0.14453125, 0.1484375), (0.701171875, 0.62109375, 0.1640625, 0.16796875)], 'case_00068_185': [(0.2978515625, 0.587890625, 0.150390625, 0.16015625), (0.703125, 0.62109375, 0.16796875, 0.17578125)], 'case_00068_190': [(0.294921875, 0.5869140625, 0.15625, 0.169921875), (0.705078125, 0.615234375, 0.171875, 0.17578125)], 'case_00068_195': [(0.2919921875, 0.5830078125, 0.162109375, 0.177734375), (0.7080078125, 0.611328125, 0.177734375, 0.18359375)], 'case_00068_200': [(0.291015625, 0.5791015625, 0.1640625, 0.177734375), (0.708984375, 0.609375, 0.17578125, 0.18359375)], 'case_00068_205': [(0.2890625, 0.5771484375, 0.16796875, 0.181640625), (0.7099609375, 0.607421875, 0.177734375, 0.18359375)], 'case_00068_210': [(0.287109375, 0.5732421875, 0.16796875, 0.181640625), (0.7119140625, 0.6064453125, 0.181640625, 0.185546875)], 'case_00068_215': [(0.2880859375, 0.5703125, 0.169921875, 0.18359375), (0.712890625, 0.6044921875, 0.1796875, 0.189453125)], 'case_00068_220': [(0.2861328125, 0.56640625, 0.169921875, 0.18359375), (0.7177734375, 0.6044921875, 0.185546875, 0.193359375)], 'case_00068_225': [(0.2861328125, 0.5595703125, 0.169921875, 0.193359375), (0.7197265625, 0.6025390625, 0.181640625, 0.189453125)], 'case_00068_230': [(0.28515625, 0.5556640625, 0.16796875, 0.201171875), (0.720703125, 0.6025390625, 0.171875, 0.189453125)], 'case_00068_235': [(0.2841796875, 0.5546875, 0.166015625, 0.20703125), (0.7255859375, 0.6005859375, 0.166015625, 0.185546875)], 'case_00068_240': [(0.283203125, 0.556640625, 0.16015625, 0.21875), (0.728515625, 0.6005859375, 0.16015625, 0.189453125)], 'case_00068_245': [(0.2822265625, 0.5576171875, 0.158203125, 0.224609375), (0.73046875, 0.6015625, 0.15625, 0.19140625)], 'case_00068_250': [(0.28125, 0.55859375, 0.15625, 0.23046875), (0.7333984375, 0.6015625, 0.154296875, 0.19140625)], 'case_00068_255': [(0.2802734375, 0.55859375, 0.154296875, 0.234375), (0.734375, 0.6005859375, 0.15234375, 0.197265625)], 'case_00068_260': [(0.279296875, 0.556640625, 0.15234375, 0.234375), (0.7353515625, 0.6025390625, 0.154296875, 0.208984375)], 'case_00068_265': [(0.2802734375, 0.556640625, 0.154296875, 0.234375), (0.732421875, 0.6025390625, 0.15234375, 0.212890625)], 'case_00068_270': [(0.2802734375, 0.5546875, 0.150390625, 0.23046875), (0.7294921875, 0.6025390625, 0.154296875, 0.216796875)], 'case_00068_275': [(0.28125, 0.552734375, 0.15234375, 0.2265625), (0.7265625, 0.599609375, 0.15625, 0.21875), (0.7529296875, 0.533203125, 0.052734375, 0.06640625)], 'case_00068_280': [(0.279296875, 0.5517578125, 0.14453125, 0.220703125), (0.6904296875, 0.517578125, 0.076171875, 0.0546875), (0.7236328125, 0.62109375, 0.154296875, 0.16796875), (0.755859375, 0.5322265625, 0.08203125, 0.087890625)], 'case_00068_285': [(0.2783203125, 0.546875, 0.142578125, 0.2109375), (0.689453125, 0.51953125, 0.09765625, 0.06640625), (0.7978515625, 0.5400390625, 0.001953125, 0.001953125), (0.72265625, 0.61328125, 0.15234375, 0.14453125), (0.75390625, 0.53515625, 0.09765625, 0.09765625)], 'case_00068_290': [(0.279296875, 0.5400390625, 0.140625, 0.193359375), (0.73828125, 0.4853515625, 0.00390625, 0.001953125), (0.6884765625, 0.5224609375, 0.095703125, 0.072265625), (0.72265625, 0.6025390625, 0.1484375, 0.138671875), (0.2392578125, 0.642578125, 0.001953125, 0.00390625), (0.759765625, 0.521484375, 0.08984375, 0.07421875)], 'case_00068_295': [(0.279296875, 0.53515625, 0.12890625, 0.17578125), (0.7158203125, 0.576171875, 0.158203125, 0.18359375), (0.7568359375, 0.5302734375, 0.095703125, 0.095703125)], 'case_00068_300': [(0.27734375, 0.5322265625, 0.12109375, 0.162109375), (0.712890625, 0.5703125, 0.1484375, 0.171875), (0.7587890625, 0.5283203125, 0.095703125, 0.087890625)], 'case_00068_305': [(0.27734375, 0.53125, 0.109375, 0.15234375), (0.7099609375, 0.568359375, 0.146484375, 0.1640625), (0.759765625, 0.529296875, 0.09375, 0.0859375)], 'case_00068_310': [(0.2783203125, 0.52734375, 0.099609375, 0.13671875), (0.7080078125, 0.5654296875, 0.142578125, 0.158203125), (0.7587890625, 0.5263671875, 0.091796875, 0.080078125)], 'case_00068_315': [(0.27734375, 0.5263671875, 0.08984375, 0.115234375), (0.7109375, 0.5634765625, 0.140625, 0.146484375), (0.75, 0.525390625, 0.10546875, 0.0703125)], 'case_00068_320': [(0.2763671875, 0.5244140625, 0.072265625, 0.091796875), (0.7099609375, 0.5595703125, 0.130859375, 0.134765625), (0.74609375, 0.5263671875, 0.1015625, 0.068359375)], 'case_00068_325': [(0.27734375, 0.517578125, 0.05859375, 0.078125), (0.7119140625, 0.5576171875, 0.126953125, 0.126953125), (0.7763671875, 0.5341796875, 0.001953125, 0.001953125), (0.740234375, 0.5322265625, 0.08984375, 0.056640625)], 'case_00068_330': [(0.287109375, 0.5087890625, 0.05078125, 0.060546875), (0.7099609375, 0.5556640625, 0.111328125, 0.115234375), (0.7216796875, 0.5283203125, 0.037109375, 0.044921875)], 'case_00068_335': [(0.2890625, 0.4951171875, 0.01953125, 0.017578125), (0.7099609375, 0.5556640625, 0.091796875, 0.103515625)], 'case_00068_340': [(0.7109375, 0.5546875, 0.078125, 0.0859375)], 'case_00068_345': [(0.7138671875, 0.556640625, 0.052734375, 0.0703125)], 'case_00068_350': [(0.7119140625, 0.5546875, 0.033203125, 0.03125), (0.69140625, 0.564453125, 0.01171875, 0.01171875)], 'case_00068_355': [], 'case_00068_360': [], 'case_00068_365': [], 'case_00068_370': [], 'case_00068_380': [], 'case_00068_385': [], 'case_00068_375': [], 'case_00068_390': [], 'case_00068_395': [], 'case_00068_400': [], 'case_00068_405': [], 'case_00068_410': [], 'case_00068_415': [], 'case_00068_420': [], 'case_00068_425': [], 'case_00068_430': [], 'case_00068_435': [], 'case_00068_440': [], 'case_00068_445': [], 'case_00068_450': [], 'case_00068_455': [], 'case_00068_460': [], 'case_00068_465': [], 'case_00068_470': [], 'case_00068_475': [], 'case_00068_480': [], 'case_00068_485': [], 'case_00068_490': [], 'case_00068_495': [], 'case_00068_500': [], 'case_00068_505': [], 'case_00068_510': [], 'case_00068_515': [], 'case_00068_520': [], 'case_00068_525': [], 'case_00068_530': [], 'case_00068_535': [], 'case_00068_540': [], 'case_00068_545': [], 'case_00068_550': [], 'case_00068_555': [], 'case_00068_560': [], 'case_00068_565': [], 'case_00068_570': [], 'case_00068_575': [], 'case_00068_580': [], 'case_00068_585': [], 'case_00068_590': [], 'case_00068_595': [], 'case_00068_600': [], 'case_00068_605': [], 'case_00068_610': [], 'case_00068_615': [], 'case_00068_620': [], 'case_00068_625': [], 'case_00128_15': [], 'case_00128_20': [], 'case_00128_10': [], 'case_00128_5': [], 'case_00128_0': [], 'case_00128_25': [], 'case_00128_30': [], 'case_00128_35': [], 'case_00128_40': [], 'case_00128_45': [], 'case_00128_55': [], 'case_00128_50': [], 'case_00128_60': [(0.6689453125, 0.544921875, 0.083984375, 0.11328125), (0.3515625, 0.607421875, 0.11328125, 0.09765625)], 'case_00128_65': [(0.6796875, 0.53125, 0.12109375, 0.14453125), (0.3447265625, 0.5859375, 0.138671875, 0.140625), (0.33203125, 0.51171875, 0.0703125, 0.0703125)], 'case_00128_70': [(0.6875, 0.513671875, 0.140625, 0.16796875), (0.3193359375, 0.4814453125, 0.005859375, 0.001953125), (0.3349609375, 0.56640625, 0.150390625, 0.1640625), (0.33203125, 0.5078125, 0.05078125, 0.0546875)], 'case_00128_75': [(0.69921875, 0.501953125, 0.140625, 0.17578125), (0.3232421875, 0.548828125, 0.150390625, 0.17578125)], 'case_00128_80': [(0.7099609375, 0.490234375, 0.146484375, 0.16796875), (0.3154296875, 0.5263671875, 0.130859375, 0.173828125)], 'case_00128_85': [(0.7021484375, 0.4755859375, 0.146484375, 0.162109375), (0.318359375, 0.515625, 0.125, 0.171875)], 'case_00128_90': [(0.6962890625, 0.46484375, 0.130859375, 0.13671875), (0.3212890625, 0.4990234375, 0.095703125, 0.130859375)], 'case_00128_95': [(0.697265625, 0.4541015625, 0.1015625, 0.091796875), (0.3203125, 0.486328125, 0.0703125, 0.0859375)], 'case_00128_100': [(0.7021484375, 0.455078125, 0.025390625, 0.01953125)], 'case_00128_110': [], 'case_00128_105': [], 'case_00128_115': [], 'case_00128_120': [], 'case_00128_125': [], 'case_00128_130': [], 'case_00128_135': [], 'case_00128_140': [], 'case_00128_145': [], 'case_00128_150': [], 'case_00128_155': [], 'case_00128_160': [], 'case_00128_165': [], 'case_00128_170': [], 'case_00128_175': [], 'case_00128_180': [], 'case_00128_185': [], 'case_00128_190': [], 'case_00128_195': [], 'case_00128_200': [], 'case_00128_205': [], 'case_00167_0': [], 'case_00167_15': [], 'case_00167_5': [], 'case_00167_20': [], 'case_00167_10': [], 'case_00167_25': [(0.6513671875, 0.6328125, 0.138671875, 0.109375), (0.40234375, 0.6513671875, 0.0859375, 0.103515625)], 'case_00167_35': [(0.3544921875, 0.607421875, 0.150390625, 0.1484375), (0.6943359375, 0.6083984375, 0.130859375, 0.130859375)], 'case_00167_30': [(0.66796875, 0.62109375, 0.16015625, 0.125), (0.3779296875, 0.634765625, 0.154296875, 0.12890625), (0.37109375, 0.5927734375, 0.05078125, 0.052734375)], 'case_00167_40': [(0.349609375, 0.5830078125, 0.1171875, 0.130859375), (0.6865234375, 0.5947265625, 0.115234375, 0.111328125)], 'case_00167_45': [(0.357421875, 0.576171875, 0.03125, 0.03515625), (0.6865234375, 0.5869140625, 0.056640625, 0.052734375)], 'case_00167_50': [], 'case_00167_55': [], 'case_00167_60': [], 'case_00167_65': [], 'case_00167_70': [], 'case_00167_75': [], 'case_00167_80': [], 'case_00167_85': [], 'case_00167_90': [], 'case_00167_95': [], 'case_00167_100': [], 'case_00084_0': [], 'case_00084_5': [], 'case_00084_10': [], 'case_00084_15': [], 'case_00084_20': [], 'case_00084_25': [], 'case_00084_30': [], 'case_00084_35': [], 'case_00084_40': [], 'case_00084_45': [(0.365234375, 0.6181640625, 0.0078125, 0.009765625)], 'case_00084_50': [(0.3544921875, 0.6142578125, 0.091796875, 0.064453125), (0.3603515625, 0.673828125, 0.068359375, 0.05859375), (0.322265625, 0.6474609375, 0.00390625, 0.001953125)], 'case_00084_55': [(0.353515625, 0.611328125, 0.125, 0.09375), (0.6669921875, 0.662109375, 0.021484375, 0.0234375), (0.369140625, 0.6796875, 0.109375, 0.0859375)], 'case_00084_60': [(0.3505859375, 0.6103515625, 0.138671875, 0.107421875), (0.6591796875, 0.6376953125, 0.083984375, 0.087890625), (0.3720703125, 0.68359375, 0.126953125, 0.10546875)], 'case_00084_65': [(0.3466796875, 0.6083984375, 0.154296875, 0.115234375), (0.666015625, 0.6240234375, 0.12109375, 0.107421875), (0.37109375, 0.6806640625, 0.12109375, 0.103515625)], 'case_00084_70': [(0.34375, 0.6083984375, 0.1640625, 0.119140625), (0.673828125, 0.6171875, 0.140625, 0.12109375), (0.3232421875, 0.6689453125, 0.001953125, 0.001953125), (0.3251953125, 0.671875, 0.001953125, 0.00390625), (0.3720703125, 0.6796875, 0.107421875, 0.08984375)], 'case_00084_75': [(0.3427734375, 0.6044921875, 0.162109375, 0.138671875), (0.6796875, 0.6123046875, 0.1484375, 0.119140625), (0.3818359375, 0.68359375, 0.056640625, 0.0625)], 'case_00084_80': [(0.337890625, 0.6005859375, 0.16015625, 0.134765625), (0.6806640625, 0.6015625, 0.154296875, 0.13671875)], 'case_00084_85': [(0.6904296875, 0.595703125, 0.146484375, 0.14453125), (0.328125, 0.599609375, 0.1484375, 0.125)], 'case_00084_90': [(0.3271484375, 0.5947265625, 0.142578125, 0.126953125), (0.6962890625, 0.5966796875, 0.150390625, 0.126953125)], 'case_00084_95': [(0.701171875, 0.587890625, 0.140625, 0.13671875), (0.3251953125, 0.591796875, 0.138671875, 0.12109375)], 'case_00084_100': [(0.7060546875, 0.5810546875, 0.130859375, 0.119140625), (0.32421875, 0.587890625, 0.125, 0.109375)], 'case_00084_105': [(0.705078125, 0.5673828125, 0.12890625, 0.138671875), (0.326171875, 0.5791015625, 0.10546875, 0.103515625), (0.7763671875, 0.56640625, 0.001953125, 0.00390625)], 'case_00084_110': [(0.69921875, 0.5478515625, 0.15234375, 0.154296875), (0.3291015625, 0.5732421875, 0.076171875, 0.083984375)], 'case_00084_115': [(0.693359375, 0.544921875, 0.15234375, 0.13671875), (0.3271484375, 0.5693359375, 0.029296875, 0.033203125)], 'case_00084_120': [(0.6923828125, 0.53515625, 0.130859375, 0.12109375)], 'case_00084_125': [(0.693359375, 0.5263671875, 0.09375, 0.091796875)], 'case_00084_130': [], 'case_00084_135': [], 'case_00084_140': [], 'case_00084_145': [], 'case_00084_150': [], 'case_00084_155': [], 'case_00084_160': [], 'case_00084_170': [], 'case_00084_165': [], 'case_00084_175': [], 'case_00084_180': [], 'case_00084_185': [], 'case_00084_190': [], 'case_00084_200': [], 'case_00084_195': [], 'case_00084_205': [], 'case_00084_210': [], 'case_00084_215': [], 'case_00084_220': [], 'case_00084_225': [], 'case_00084_230': [], 'case_00084_235': [], 'case_00084_240': [], 'case_00084_245': [], 'case_00084_250': [], 'case_00084_255': [], 'case_00084_260': [], 'case_00084_265': [], 'case_00084_270': [], 'case_00001_0': [], 'case_00001_5': [], 'case_00001_10': [], 'case_00001_15': [], 'case_00001_20': [], 'case_00001_25': [], 'case_00001_30': [], 'case_00001_35': [], 'case_00001_40': [], 'case_00001_45': [], 'case_00001_50': [], 'case_00001_55': [], 'case_00001_60': [], 'case_00001_65': [], 'case_00001_70': [], 'case_00001_75': [], 'case_00001_80': [], 'case_00001_85': [], 'case_00001_90': [], 'case_00001_95': [], 'case_00001_100': [], 'case_00001_105': [], 'case_00001_110': [], 'case_00001_115': [], 'case_00001_120': [], 'case_00001_125': [], 'case_00001_130': [], 'case_00001_135': [], 'case_00001_140': [], 'case_00001_150': [], 'case_00001_145': [], 'case_00001_155': [], 'case_00001_160': [], 'case_00001_165': [], 'case_00001_170': [], 'case_00001_175': [], 'case_00001_180': [], 'case_00001_185': [(0.681640625, 0.5869140625, 0.046875, 0.048828125), (0.3046875, 0.603515625, 0.02734375, 0.02734375)], 'case_00001_190': [(0.6796875, 0.5791015625, 0.07421875, 0.072265625), (0.3056640625, 0.6044921875, 0.064453125, 0.064453125)], 'case_00001_195': [(0.685546875, 0.5751953125, 0.1015625, 0.087890625), (0.298828125, 0.60546875, 0.08203125, 0.08203125)], 'case_00001_200': [(0.689453125, 0.5693359375, 0.125, 0.099609375), (0.294921875, 0.6005859375, 0.09765625, 0.091796875)], 'case_00001_205': [(0.69140625, 0.5654296875, 0.13671875, 0.111328125), (0.2939453125, 0.599609375, 0.111328125, 0.1015625)], 'case_00001_210': [(0.6943359375, 0.560546875, 0.142578125, 0.1171875), (0.29296875, 0.59765625, 0.125, 0.109375)], 'case_00001_215': [(0.6943359375, 0.5595703125, 0.150390625, 0.119140625), (0.2919921875, 0.591796875, 0.130859375, 0.125)], 'case_00001_220': [(0.697265625, 0.5546875, 0.15625, 0.12890625), (0.2900390625, 0.583984375, 0.138671875, 0.140625)], 'case_00001_225': [(0.6982421875, 0.55078125, 0.158203125, 0.13671875), (0.2880859375, 0.5771484375, 0.142578125, 0.154296875)], 'case_00001_230': [(0.6982421875, 0.5439453125, 0.158203125, 0.150390625), (0.287109375, 0.572265625, 0.1484375, 0.1640625)], 'case_00001_240': [(0.7021484375, 0.537109375, 0.166015625, 0.16015625), (0.2861328125, 0.5712890625, 0.150390625, 0.169921875)], 'case_00001_235': [(0.701171875, 0.5400390625, 0.1640625, 0.158203125), (0.287109375, 0.5712890625, 0.1484375, 0.166015625)], 'case_00001_245': [(0.705078125, 0.53515625, 0.171875, 0.1640625), (0.2861328125, 0.5693359375, 0.154296875, 0.169921875)], 'case_00001_250': [(0.70703125, 0.533203125, 0.171875, 0.1640625), (0.28515625, 0.5654296875, 0.15625, 0.173828125), (0.25390625, 0.5185546875, 0.03125, 0.037109375)], 'case_00001_255': [(0.7099609375, 0.5322265625, 0.169921875, 0.169921875), (0.2841796875, 0.5625, 0.158203125, 0.17578125), (0.2568359375, 0.5166015625, 0.041015625, 0.048828125)], 'case_00001_260': [(0.712890625, 0.529296875, 0.171875, 0.16796875), (0.2822265625, 0.5556640625, 0.162109375, 0.185546875), (0.2607421875, 0.51953125, 0.056640625, 0.05859375)], 'case_00001_265': [(0.71484375, 0.529296875, 0.16796875, 0.16796875), (0.2822265625, 0.55078125, 0.162109375, 0.1875), (0.26171875, 0.5234375, 0.0546875, 0.05859375)], 'case_00001_270': [(0.7158203125, 0.5263671875, 0.166015625, 0.166015625), (0.2802734375, 0.5458984375, 0.162109375, 0.189453125), (0.26171875, 0.521484375, 0.05078125, 0.05078125)], 'case_00001_275': [(0.71875, 0.52734375, 0.1640625, 0.16796875), (0.27734375, 0.54296875, 0.1640625, 0.1953125), (0.2685546875, 0.52734375, 0.033203125, 0.03125)], 'case_00001_280': [(0.720703125, 0.5234375, 0.1640625, 0.1640625), (0.2724609375, 0.5400390625, 0.162109375, 0.193359375), (0.2666015625, 0.525390625, 0.013671875, 0.01953125)], 'case_00001_285': [(0.2666015625, 0.537109375, 0.158203125, 0.1953125), (0.7236328125, 0.521484375, 0.162109375, 0.1640625)], 'case_00001_290': [(0.263671875, 0.5341796875, 0.15234375, 0.193359375), (0.724609375, 0.5185546875, 0.16015625, 0.162109375)], 'case_00001_295': [(0.7236328125, 0.5166015625, 0.162109375, 0.166015625), (0.26171875, 0.5341796875, 0.1484375, 0.193359375)], 'case_00001_300': [(0.724609375, 0.51171875, 0.15625, 0.171875), (0.2607421875, 0.5322265625, 0.146484375, 0.189453125)], 'case_00001_305': [(0.724609375, 0.509765625, 0.15234375, 0.171875), (0.2578125, 0.529296875, 0.1484375, 0.1953125)], 'case_00001_310': [(0.7255859375, 0.5068359375, 0.150390625, 0.169921875), (0.255859375, 0.5302734375, 0.1484375, 0.189453125)], 'case_00001_315': [(0.7275390625, 0.5048828125, 0.146484375, 0.169921875), (0.2548828125, 0.52734375, 0.142578125, 0.1875)], 'case_00001_320': [(0.7265625, 0.5029296875, 0.14453125, 0.166015625), (0.251953125, 0.5244140625, 0.13671875, 0.185546875)], 'case_00001_325': [(0.7275390625, 0.5, 0.142578125, 0.1640625), (0.25, 0.5224609375, 0.1328125, 0.185546875)], 'case_00001_330': [(0.7265625, 0.4990234375, 0.13671875, 0.162109375), (0.248046875, 0.51953125, 0.125, 0.1796875), (0.21484375, 0.5869140625, 0.02734375, 0.025390625)], 'case_00001_335': [(0.724609375, 0.4951171875, 0.1328125, 0.158203125), (0.2490234375, 0.517578125, 0.123046875, 0.1796875), (0.21484375, 0.587890625, 0.03515625, 0.03515625)], 'case_00001_340': [(0.7255859375, 0.4931640625, 0.126953125, 0.150390625), (0.25, 0.515625, 0.12109375, 0.171875), (0.21484375, 0.5869140625, 0.0390625, 0.033203125)], 'case_00001_345': [(0.724609375, 0.4892578125, 0.125, 0.150390625), (0.2509765625, 0.513671875, 0.119140625, 0.16796875), (0.216796875, 0.5869140625, 0.0390625, 0.033203125)], 'case_00001_350': [(0.72265625, 0.48828125, 0.1171875, 0.14453125), (0.2509765625, 0.51171875, 0.119140625, 0.16015625), (0.2177734375, 0.5859375, 0.033203125, 0.02734375)], 'case_00001_355': [(0.7216796875, 0.48828125, 0.111328125, 0.13671875), (0.2509765625, 0.509765625, 0.115234375, 0.15234375), (0.220703125, 0.5859375, 0.0234375, 0.015625)], 'case_00001_360': [(0.720703125, 0.4892578125, 0.10546875, 0.130859375), (0.251953125, 0.5078125, 0.11328125, 0.1484375), (0.2197265625, 0.5185546875, 0.025390625, 0.025390625)], 'case_00001_365': [(0.720703125, 0.4873046875, 0.1015625, 0.123046875), (0.2509765625, 0.5087890625, 0.107421875, 0.138671875), (0.2197265625, 0.5126953125, 0.033203125, 0.029296875)], 'case_00001_370': [(0.71875, 0.486328125, 0.09765625, 0.1171875), (0.251953125, 0.505859375, 0.09765625, 0.12890625), (0.21875, 0.5107421875, 0.03125, 0.033203125)], 'case_00001_375': [(0.7197265625, 0.484375, 0.087890625, 0.10546875), (0.2529296875, 0.5029296875, 0.083984375, 0.119140625), (0.2177734375, 0.51171875, 0.025390625, 0.03515625)], 'case_00001_380': [(0.7197265625, 0.482421875, 0.080078125, 0.09765625), (0.251953125, 0.5048828125, 0.07421875, 0.091796875), (0.21484375, 0.515625, 0.00390625, 0.015625)], 'case_00001_385': [(0.720703125, 0.48046875, 0.0703125, 0.0859375), (0.251953125, 0.5048828125, 0.0625, 0.072265625)], 'case_00001_390': [(0.720703125, 0.4794921875, 0.05859375, 0.072265625), (0.2509765625, 0.5029296875, 0.048828125, 0.060546875)], 'case_00001_395': [(0.71875, 0.4794921875, 0.03515625, 0.048828125), (0.2529296875, 0.5029296875, 0.033203125, 0.029296875)], 'case_00001_400': [], 'case_00001_405': [], 'case_00001_410': [], 'case_00001_415': [], 'case_00001_420': [], 'case_00001_425': [], 'case_00001_430': [], 'case_00001_435': [], 'case_00001_440': [], 'case_00001_445': [], 'case_00001_450': [], 'case_00001_455': [], 'case_00001_460': [], 'case_00001_465': [], 'case_00001_470': [], 'case_00001_475': [], 'case_00001_480': [], 'case_00001_485': [], 'case_00001_495': [], 'case_00001_490': [], 'case_00001_500': [], 'case_00001_510': [], 'case_00001_505': [], 'case_00001_515': [], 'case_00001_520': [], 'case_00001_525': [], 'case_00001_530': [], 'case_00001_535': [], 'case_00001_540': [], 'case_00001_545': [], 'case_00001_550': [], 'case_00001_555': [], 'case_00001_560': [], 'case_00001_565': [], 'case_00001_570': [], 'case_00001_575': [], 'case_00001_580': [], 'case_00001_585': [], 'case_00001_590': [], 'case_00001_595': [], 'case_00001_600': [], 'case_00048_0': [], 'case_00048_5': [], 'case_00048_10': [], 'case_00048_15': [(0.4013671875, 0.5830078125, 0.060546875, 0.056640625)], 'case_00048_20': [(0.6416015625, 0.52734375, 0.111328125, 0.09375), (0.392578125, 0.5751953125, 0.1171875, 0.087890625)], 'case_00048_25': [(0.646484375, 0.4921875, 0.12109375, 0.12890625), (0.384765625, 0.560546875, 0.1171875, 0.09375), (0.693359375, 0.5322265625, 0.05078125, 0.064453125)], 'case_00048_30': [(0.6396484375, 0.474609375, 0.111328125, 0.125), (0.384765625, 0.5419921875, 0.11328125, 0.107421875), (0.6787109375, 0.5244140625, 0.064453125, 0.068359375)], 'case_00048_35': [(0.6220703125, 0.4580078125, 0.099609375, 0.095703125), (0.3955078125, 0.5205078125, 0.107421875, 0.095703125)], 'case_00048_40': [(0.619140625, 0.4453125, 0.0234375, 0.01953125), (0.3994140625, 0.5244140625, 0.041015625, 0.037109375)], 'case_00048_45': [], 'case_00048_50': [], 'case_00048_55': [], 'case_00048_60': [], 'case_00048_65': [], 'case_00048_70': [], 'case_00048_75': [], 'case_00048_80': [], 'case_00122_5': [], 'case_00122_10': [], 'case_00122_0': [], 'case_00122_15': [], 'case_00122_20': [(0.6767578125, 0.6513671875, 0.162109375, 0.146484375), (0.7216796875, 0.57421875, 0.091796875, 0.09765625), (0.7373046875, 0.6240234375, 0.001953125, 0.001953125), (0.7197265625, 0.6318359375, 0.001953125, 0.001953125)], 'case_00122_25': [(0.7060546875, 0.623046875, 0.189453125, 0.19140625), (0.33203125, 0.650390625, 0.07421875, 0.08984375), (0.736328125, 0.57421875, 0.0625, 0.05859375)], 'case_00122_30': [(0.2998046875, 0.5849609375, 0.158203125, 0.248046875), (0.7216796875, 0.6123046875, 0.181640625, 0.177734375)], 'case_00122_35': [(0.2958984375, 0.548828125, 0.173828125, 0.26171875), (0.7080078125, 0.5869140625, 0.138671875, 0.166015625)], 'case_00122_40': [(0.296875, 0.5185546875, 0.1484375, 0.201171875), (0.7119140625, 0.57421875, 0.041015625, 0.0546875)], 'case_00122_45': [], 'case_00100_0': [], 'case_00100_5': [], 'case_00100_10': [], 'case_00100_25': [], 'case_00100_15': [], 'case_00100_20': [], 'case_00100_40': [], 'case_00100_35': [], 'case_00100_30': [], 'case_00100_45': [], 'case_00100_50': [], 'case_00100_55': [], 'case_00100_60': [], 'case_00100_65': [], 'case_00100_75': [], 'case_00100_70': [], 'case_00100_80': [], 'case_00100_90': [], 'case_00100_85': [], 'case_00100_95': [], 'case_00100_105': [], 'case_00100_100': [], 'case_00100_110': [], 'case_00100_115': [], 'case_00100_120': [], 'case_00100_125': [(0.6552734375, 0.59765625, 0.052734375, 0.0546875)], 'case_00100_130': [(0.6572265625, 0.595703125, 0.080078125, 0.078125)], 'case_00100_135': [(0.662109375, 0.5927734375, 0.1015625, 0.095703125)], 'case_00100_140': [(0.6650390625, 0.5888671875, 0.115234375, 0.103515625)], 'case_00100_145': [(0.6669921875, 0.5830078125, 0.123046875, 0.115234375)], 'case_00100_150': [(0.669921875, 0.5810546875, 0.12890625, 0.115234375)], 'case_00100_155': [(0.671875, 0.5771484375, 0.12890625, 0.126953125)], 'case_00100_160': [(0.671875, 0.572265625, 0.12890625, 0.12890625), (0.404296875, 0.59375, 0.03515625, 0.05078125)], 'case_00100_165': [(0.6748046875, 0.5693359375, 0.130859375, 0.130859375), (0.3994140625, 0.58984375, 0.064453125, 0.0859375)], 'case_00100_170': [(0.6806640625, 0.5673828125, 0.119140625, 0.130859375), (0.3916015625, 0.58984375, 0.087890625, 0.11328125)], 'case_00100_175': [(0.3857421875, 0.5693359375, 0.103515625, 0.158203125), (0.6845703125, 0.564453125, 0.119140625, 0.12890625)], 'case_00100_180': [(0.3759765625, 0.5615234375, 0.115234375, 0.169921875), (0.68359375, 0.5625, 0.125, 0.125)], 'case_00100_185': [(0.3671875, 0.5517578125, 0.1328125, 0.177734375), (0.67578125, 0.5595703125, 0.13671875, 0.119140625), (0.310546875, 0.52734375, 0.02734375, 0.0234375)], 'case_00100_190': [(0.3642578125, 0.54296875, 0.126953125, 0.1796875), (0.6708984375, 0.5556640625, 0.138671875, 0.115234375), (0.3076171875, 0.52734375, 0.033203125, 0.03515625)], 'case_00100_195': [(0.3603515625, 0.5361328125, 0.123046875, 0.177734375), (0.66796875, 0.5537109375, 0.1328125, 0.111328125), (0.2978515625, 0.5419921875, 0.001953125, 0.001953125), (0.3154296875, 0.5283203125, 0.044921875, 0.041015625)], 'case_00100_200': [(0.3583984375, 0.5283203125, 0.126953125, 0.173828125), (0.666015625, 0.55078125, 0.12890625, 0.1015625), (0.31640625, 0.52734375, 0.01171875, 0.01171875)], 'case_00100_205': [(0.3583984375, 0.5205078125, 0.130859375, 0.169921875), (0.6630859375, 0.5478515625, 0.115234375, 0.091796875)], 'case_00100_210': [(0.3564453125, 0.5146484375, 0.130859375, 0.162109375), (0.662109375, 0.5439453125, 0.09765625, 0.076171875)], 'case_00100_215': [(0.3583984375, 0.505859375, 0.123046875, 0.1484375), (0.6572265625, 0.5380859375, 0.072265625, 0.052734375)], 'case_00100_220': [(0.3623046875, 0.4990234375, 0.111328125, 0.130859375), (0.662109375, 0.53515625, 0.03515625, 0.0234375)], 'case_00100_225': [(0.3642578125, 0.4951171875, 0.095703125, 0.111328125)], 'case_00100_230': [(0.36328125, 0.4892578125, 0.07421875, 0.080078125)], 'case_00100_235': [], 'case_00100_245': [], 'case_00100_240': [], 'case_00100_250': [], 'case_00100_255': [], 'case_00100_260': [], 'case_00100_265': [], 'case_00100_270': [], 'case_00100_275': [], 'case_00100_280': [], 'case_00100_285': [], 'case_00100_290': [], 'case_00100_300': [], 'case_00100_295': [], 'case_00100_305': [], 'case_00100_310': [], 'case_00100_315': [], 'case_00100_320': [], 'case_00100_325': [], 'case_00100_330': [], 'case_00100_335': [], 'case_00100_340': [], 'case_00100_345': [], 'case_00100_350': [], 'case_00100_355': [], 'case_00100_365': [], 'case_00100_360': [], 'case_00100_370': [], 'case_00100_375': [], 'case_00100_380': [], 'case_00100_385': [], 'case_00100_390': [], 'case_00100_395': [], 'case_00100_400': [], 'case_00100_405': [], 'case_00100_410': [], 'case_00100_415': [], 'case_00100_420': [], 'case_00100_425': [], 'case_00100_430': [], 'case_00100_435': [], 'case_00100_440': [], 'case_00100_445': [], 'case_00100_450': [], 'case_00100_455': [], 'case_00100_460': [], 'case_00100_465': [], 'case_00196_0': [], 'case_00196_5': [], 'case_00196_20': [], 'case_00196_10': [], 'case_00196_15': [], 'case_00196_25': [], 'case_00196_30': [], 'case_00196_35': [], 'case_00196_40': [], 'case_00196_45': [], 'case_00196_50': [(0.3544921875, 0.5791015625, 0.037109375, 0.041015625)], 'case_00196_55': [(0.3349609375, 0.5703125, 0.126953125, 0.1171875), (0.6337890625, 0.57421875, 0.060546875, 0.08984375)], 'case_00196_60': [(0.6513671875, 0.5634765625, 0.126953125, 0.142578125), (0.3193359375, 0.564453125, 0.166015625, 0.1328125)], 'case_00196_65': [(0.669921875, 0.5419921875, 0.15625, 0.162109375), (0.3125, 0.5595703125, 0.17578125, 0.138671875)], 'case_00196_70': [(0.6943359375, 0.5302734375, 0.162109375, 0.158203125), (0.2939453125, 0.5537109375, 0.150390625, 0.142578125), (0.7763671875, 0.5419921875, 0.001953125, 0.001953125), (0.7412109375, 0.5595703125, 0.068359375, 0.064453125)], 'case_00196_80': [(0.6865234375, 0.5029296875, 0.154296875, 0.123046875), (0.3017578125, 0.5498046875, 0.126953125, 0.115234375), (0.7392578125, 0.552734375, 0.099609375, 0.078125)], 'case_00196_75': [(0.6904296875, 0.5146484375, 0.154296875, 0.146484375), (0.2919921875, 0.552734375, 0.138671875, 0.1328125), (0.7685546875, 0.5048828125, 0.001953125, 0.001953125), (0.7490234375, 0.546875, 0.091796875, 0.0859375)], 'case_00196_85': [(0.6748046875, 0.4931640625, 0.095703125, 0.087890625), (0.3046875, 0.544921875, 0.078125, 0.07421875), (0.7275390625, 0.5654296875, 0.072265625, 0.052734375)], 'case_00196_95': [], 'case_00196_90': [], 'case_00196_100': [], 'case_00196_110': [], 'case_00196_105': [], 'case_00196_115': [], 'case_00196_120': [], 'case_00196_125': [], 'case_00196_130': [], 'case_00196_135': [], 'case_00196_140': [], 'case_00196_145': [], 'case_00196_150': [], 'case_00196_155': [], 'case_00196_160': [], 'case_00196_165': [], 'case_00196_170': [], 'case_00196_175': [], 'case_00047_5': [], 'case_00047_0': [], 'case_00047_10': [], 'case_00047_15': [], 'case_00047_20': [], 'case_00047_25': [], 'case_00047_30': [], 'case_00047_35': [], 'case_00047_40': [], 'case_00047_45': [], 'case_00047_50': [], 'case_00047_55': [], 'case_00047_60': [], 'case_00047_65': [(0.6513671875, 0.6474609375, 0.091796875, 0.095703125)], 'case_00047_70': [(0.669921875, 0.6337890625, 0.15625, 0.123046875), (0.375, 0.6279296875, 0.0703125, 0.072265625)], 'case_00047_75': [(0.34375, 0.6025390625, 0.14453125, 0.134765625), (0.69140625, 0.623046875, 0.15625, 0.12890625), (0.326171875, 0.6455078125, 0.06640625, 0.041015625)], 'case_00047_80': [(0.333984375, 0.5419921875, 0.171875, 0.166015625), (0.69921875, 0.6064453125, 0.13671875, 0.123046875), (0.3603515625, 0.6259765625, 0.001953125, 0.001953125), (0.3212890625, 0.5859375, 0.146484375, 0.140625)], 'case_00047_85': [(0.3369140625, 0.4931640625, 0.111328125, 0.095703125), (0.6923828125, 0.599609375, 0.076171875, 0.08203125), (0.314453125, 0.5869140625, 0.15625, 0.169921875)], 'case_00047_90': [], 'case_00047_95': [], 'case_00047_105': [], 'case_00047_100': [], 'case_00047_110': [], 'case_00047_115': [], 'case_00047_120': [], 'case_00047_125': [], 'case_00047_130': [], 'case_00047_135': [], 'case_00047_140': [], 'case_00067_0': [], 'case_00067_15': [], 'case_00067_10': [], 'case_00067_5': [], 'case_00067_20': [], 'case_00067_25': [], 'case_00067_30': [], 'case_00067_40': [], 'case_00067_35': [], 'case_00067_45': [], 'case_00067_50': [], 'case_00067_55': [], 'case_00067_60': [], 'case_00067_65': [], 'case_00067_70': [], 'case_00067_75': [], 'case_00067_80': [], 'case_00067_85': [], 'case_00067_90': [], 'case_00067_95': [], 'case_00067_100': [(0.6669921875, 0.5537109375, 0.033203125, 0.044921875)], 'case_00067_105': [(0.6708984375, 0.548828125, 0.072265625, 0.109375)], 'case_00067_110': [(0.6728515625, 0.541015625, 0.099609375, 0.12890625)], 'case_00067_115': [(0.673828125, 0.533203125, 0.1171875, 0.14453125), (0.37890625, 0.6650390625, 0.0546875, 0.076171875)], 'case_00067_120': [(0.6767578125, 0.5244140625, 0.130859375, 0.158203125), (0.3671875, 0.66015625, 0.1015625, 0.1015625)], 'case_00067_125': [(0.6787109375, 0.5166015625, 0.138671875, 0.166015625), (0.3583984375, 0.6552734375, 0.123046875, 0.123046875)], 'case_00067_130': [(0.6796875, 0.5107421875, 0.1484375, 0.177734375), (0.3486328125, 0.6474609375, 0.138671875, 0.138671875)], 'case_00067_135': [(0.673828125, 0.5029296875, 0.1640625, 0.189453125), (0.33984375, 0.6416015625, 0.1484375, 0.146484375)], 'case_00067_140': [(0.669921875, 0.5, 0.18359375, 0.19921875), (0.333984375, 0.6357421875, 0.15625, 0.150390625), (0.724609375, 0.5478515625, 0.0625, 0.056640625)], 'case_00067_145': [(0.6640625, 0.453125, 0.19921875, 0.12890625), (0.328125, 0.6328125, 0.16015625, 0.1484375), (0.6494140625, 0.5791015625, 0.001953125, 0.001953125), (0.685546875, 0.53125, 0.171875, 0.16015625)], 'case_00067_150': [(0.642578125, 0.439453125, 0.21484375, 0.125), (0.322265625, 0.6279296875, 0.16015625, 0.146484375), (0.6767578125, 0.5302734375, 0.220703125, 0.193359375)], 'case_00067_155': [(0.31640625, 0.6240234375, 0.15625, 0.146484375), (0.6630859375, 0.490234375, 0.275390625, 0.26953125)], 'case_00067_160': [(0.3115234375, 0.6201171875, 0.150390625, 0.142578125), (0.6611328125, 0.486328125, 0.291015625, 0.296875)], 'case_00067_165': [(0.3056640625, 0.6181640625, 0.134765625, 0.138671875), (0.662109375, 0.482421875, 0.30078125, 0.3125)], 'case_00067_170': [(0.30078125, 0.6142578125, 0.125, 0.134765625), (0.662109375, 0.478515625, 0.3046875, 0.32421875)], 'case_00067_175': [(0.30078125, 0.6103515625, 0.1171875, 0.130859375), (0.6640625, 0.4775390625, 0.30859375, 0.337890625)], 'case_00067_180': [(0.298828125, 0.6064453125, 0.10546875, 0.123046875), (0.6650390625, 0.4755859375, 0.310546875, 0.345703125)], 'case_00067_185': [(0.296875, 0.6025390625, 0.08984375, 0.107421875), (0.66796875, 0.4736328125, 0.3125, 0.353515625)], 'case_00067_190': [(0.2958984375, 0.595703125, 0.068359375, 0.08984375), (0.6708984375, 0.4736328125, 0.306640625, 0.349609375)], 'case_00067_195': [(0.2919921875, 0.58984375, 0.041015625, 0.05078125), (0.671875, 0.4736328125, 0.3125, 0.345703125)], 'case_00067_200': [(0.671875, 0.4755859375, 0.31640625, 0.341796875)], 'case_00067_205': [(0.671875, 0.4765625, 0.3203125, 0.33203125)], 'case_00067_210': [(0.6748046875, 0.478515625, 0.326171875, 0.32421875)], 'case_00067_215': [(0.6748046875, 0.4794921875, 0.322265625, 0.310546875)], 'case_00067_220': [(0.6787109375, 0.4775390625, 0.314453125, 0.298828125)], 'case_00067_225': [(0.681640625, 0.478515625, 0.30078125, 0.29296875)], 'case_00067_230': [(0.6884765625, 0.4765625, 0.283203125, 0.28125), (0.7578125, 0.619140625, 0.00390625, 0.00390625)], 'case_00067_235': [(0.6953125, 0.4765625, 0.26171875, 0.26171875)], 'case_00067_240': [(0.693359375, 0.4755859375, 0.25390625, 0.244140625)], 'case_00067_245': [(0.697265625, 0.4736328125, 0.234375, 0.224609375)], 'case_00067_250': [(0.7021484375, 0.47265625, 0.212890625, 0.20703125)], 'case_00067_255': [(0.7041015625, 0.4736328125, 0.189453125, 0.177734375)], 'case_00067_260': [(0.7060546875, 0.4755859375, 0.154296875, 0.146484375)], 'case_00067_265': [(0.708984375, 0.47265625, 0.09375, 0.09765625)], 'case_00067_270': [], 'case_00067_275': [], 'case_00067_280': [], 'case_00099_20': [], 'case_00099_15': [], 'case_00099_0': [], 'case_00099_5': [], 'case_00099_10': [], 'case_00099_25': [(0.6123046875, 0.6650390625, 0.052734375, 0.080078125), (0.302734375, 0.62109375, 0.1484375, 0.1328125)], 'case_00099_30': [(0.3193359375, 0.5634765625, 0.181640625, 0.103515625), (0.6689453125, 0.650390625, 0.169921875, 0.1640625), (0.30078125, 0.62109375, 0.16796875, 0.15234375)], 'case_00099_35': [(0.30078125, 0.576171875, 0.2109375, 0.140625), (0.7109375, 0.642578125, 0.18359375, 0.1640625)], 'case_00099_40': [(0.2705078125, 0.58203125, 0.150390625, 0.13671875), (0.7216796875, 0.6376953125, 0.158203125, 0.142578125)], 'case_00099_45': [(0.2822265625, 0.59375, 0.119140625, 0.09375), (0.732421875, 0.6396484375, 0.08203125, 0.080078125)], 'case_00099_50': [], 'case_00099_55': [], 'case_00099_60': [], 'case_00099_65': [], 'case_00099_70': [], 'case_00099_75': [], 'case_00099_85': [], 'case_00099_80': [], 'case_00099_90': [], 'case_00099_95': [], 'case_00099_100': [], 'case_00033_0': [], 'case_00033_5': [], 'case_00033_15': [], 'case_00033_10': [], 'case_00033_25': [], 'case_00033_30': [], 'case_00033_20': [], 'case_00033_35': [], 'case_00033_40': [], 'case_00033_45': [], 'case_00033_50': [], 'case_00033_55': [], 'case_00033_60': [], 'case_00033_65': [], 'case_00033_70': [], 'case_00033_75': [], 'case_00033_80': [], 'case_00033_85': [], 'case_00033_90': [], 'case_00033_95': [(0.3525390625, 0.5947265625, 0.064453125, 0.068359375)], 'case_00033_100': [(0.3486328125, 0.5859375, 0.095703125, 0.09765625), (0.361328125, 0.544921875, 0.015625, 0.01171875)], 'case_00033_105': [(0.3447265625, 0.5810546875, 0.115234375, 0.107421875), (0.6767578125, 0.599609375, 0.044921875, 0.07421875), (0.3564453125, 0.5478515625, 0.052734375, 0.044921875)], 'case_00033_110': [(0.3408203125, 0.5771484375, 0.126953125, 0.111328125), (0.6767578125, 0.59375, 0.076171875, 0.09765625), (0.359375, 0.544921875, 0.0546875, 0.05859375)], 'case_00033_115': [(0.3369140625, 0.5732421875, 0.134765625, 0.119140625), (0.681640625, 0.5869140625, 0.1015625, 0.115234375), (0.3623046875, 0.541015625, 0.052734375, 0.0546875)], 'case_00033_120': [(0.33203125, 0.5693359375, 0.1484375, 0.123046875), (0.6845703125, 0.5810546875, 0.119140625, 0.134765625), (0.3720703125, 0.537109375, 0.041015625, 0.0390625)], 'case_00033_125': [(0.3291015625, 0.564453125, 0.150390625, 0.12890625), (0.6875, 0.5732421875, 0.1328125, 0.146484375), (0.3720703125, 0.5322265625, 0.025390625, 0.025390625)], 'case_00033_130': [(0.69140625, 0.568359375, 0.1484375, 0.15234375), (0.3251953125, 0.560546875, 0.154296875, 0.1328125), (0.3740234375, 0.5302734375, 0.009765625, 0.009765625)], 'case_00033_135': [(0.6943359375, 0.5595703125, 0.154296875, 0.158203125), (0.3232421875, 0.556640625, 0.158203125, 0.140625)], 'case_00033_140': [(0.6982421875, 0.55078125, 0.158203125, 0.16015625), (0.31640625, 0.552734375, 0.1484375, 0.14453125)], 'case_00033_145': [(0.703125, 0.5439453125, 0.1640625, 0.162109375), (0.3115234375, 0.5498046875, 0.142578125, 0.142578125)], 'case_00033_150': [(0.7119140625, 0.5390625, 0.162109375, 0.16015625), (0.30859375, 0.548828125, 0.13671875, 0.14453125)], 'case_00033_155': [(0.72265625, 0.5322265625, 0.140625, 0.162109375), (0.3076171875, 0.546875, 0.134765625, 0.14453125)], 'case_00033_160': [(0.720703125, 0.5244140625, 0.1484375, 0.162109375), (0.3046875, 0.54296875, 0.1328125, 0.14453125)], 'case_00033_165': [(0.716796875, 0.5185546875, 0.15234375, 0.158203125), (0.30859375, 0.5400390625, 0.140625, 0.142578125)], 'case_00033_170': [(0.71484375, 0.5146484375, 0.15234375, 0.154296875), (0.3076171875, 0.537109375, 0.142578125, 0.140625)], 'case_00033_175': [(0.7119140625, 0.51171875, 0.146484375, 0.1484375), (0.30859375, 0.5361328125, 0.140625, 0.134765625)], 'case_00033_180': [(0.7099609375, 0.5078125, 0.142578125, 0.140625), (0.3095703125, 0.53515625, 0.134765625, 0.125)], 'case_00033_185': [(0.705078125, 0.50390625, 0.1328125, 0.13671875), (0.3115234375, 0.5341796875, 0.126953125, 0.119140625)], 'case_00033_190': [(0.7021484375, 0.4951171875, 0.119140625, 0.123046875), (0.3125, 0.53125, 0.12109375, 0.109375)], 'case_00033_195': [(0.703125, 0.48828125, 0.109375, 0.109375), (0.3134765625, 0.529296875, 0.111328125, 0.09765625)], 'case_00033_200': [(0.703125, 0.4814453125, 0.09375, 0.095703125), (0.31640625, 0.525390625, 0.09375, 0.0859375)], 'case_00033_205': [(0.6982421875, 0.4755859375, 0.068359375, 0.072265625), (0.3193359375, 0.5185546875, 0.068359375, 0.068359375)], 'case_00033_210': [(0.697265625, 0.4697265625, 0.02734375, 0.033203125), (0.3203125, 0.515625, 0.0390625, 0.04296875)], 'case_00033_215': [], 'case_00033_220': [], 'case_00033_225': [], 'case_00033_230': [], 'case_00033_235': [], 'case_00033_240': [], 'case_00033_245': [], 'case_00033_250': [], 'case_00033_255': [], 'case_00033_260': [], 'case_00033_265': [], 'case_00033_270': [], 'case_00033_275': [], 'case_00033_280': [], 'case_00033_285': [], 'case_00033_290': [], 'case_00033_295': [], 'case_00033_300': [], 'case_00033_305': [], 'case_00033_310': [], 'case_00033_315': [], 'case_00033_320': [], 'case_00033_325': [], 'case_00033_335': [], 'case_00033_330': [], 'case_00033_340': [], 'case_00033_345': [], 'case_00033_350': [], 'case_00033_355': [], 'case_00033_360': [], 'case_00033_365': [], 'case_00033_370': [], 'case_00033_375': [], 'case_00144_0': [], 'case_00144_10': [], 'case_00144_15': [], 'case_00144_5': [], 'case_00144_20': [], 'case_00144_30': [], 'case_00144_25': [], 'case_00144_35': [], 'case_00144_40': [], 'case_00144_45': [], 'case_00144_50': [], 'case_00144_55': [(0.6669921875, 0.67578125, 0.041015625, 0.01953125)], 'case_00144_60': [(0.66796875, 0.681640625, 0.08984375, 0.0859375)], 'case_00144_65': [(0.6650390625, 0.64453125, 0.107421875, 0.07421875), (0.671875, 0.6826171875, 0.09765625, 0.091796875)], 'case_00144_70': [(0.673828125, 0.6484375, 0.13671875, 0.12890625), (0.6689453125, 0.6767578125, 0.033203125, 0.044921875)], 'case_00144_75': [(0.6826171875, 0.6357421875, 0.154296875, 0.126953125)], 'case_00144_80': [(0.6962890625, 0.626953125, 0.169921875, 0.140625), (0.37109375, 0.63671875, 0.08203125, 0.09375)], 'case_00144_85': [(0.361328125, 0.6005859375, 0.1171875, 0.193359375), (0.7001953125, 0.6142578125, 0.158203125, 0.146484375)], 'case_00144_90': [(0.3525390625, 0.5830078125, 0.130859375, 0.216796875), (0.7041015625, 0.6025390625, 0.150390625, 0.146484375)], 'case_00144_95': [(0.353515625, 0.5654296875, 0.14453125, 0.212890625), (0.7021484375, 0.5927734375, 0.134765625, 0.142578125)], 'case_00144_100': [(0.357421875, 0.544921875, 0.14453125, 0.1875), (0.69921875, 0.5791015625, 0.11328125, 0.119140625)], 'case_00144_105': [(0.3583984375, 0.5234375, 0.119140625, 0.140625), (0.69921875, 0.572265625, 0.078125, 0.08203125)], 'case_00144_115': [], 'case_00144_110': [(0.3603515625, 0.5126953125, 0.029296875, 0.037109375)], 'case_00144_120': [], 'case_00144_125': [], 'case_00144_130': [], 'case_00144_135': [], 'case_00144_140': [], 'case_00144_150': [], 'case_00144_145': [], 'case_00144_155': [], 'case_00144_160': [], 'case_00144_165': [], 'case_00144_170': [], 'case_00144_175': [], 'case_00144_180': [], 'case_00144_185': [], 'case_00144_190': [], 'case_00144_195': [], 'case_00171_10': [], 'case_00171_5': [], 'case_00171_15': [], 'case_00171_20': [], 'case_00171_0': [], 'case_00171_30': [], 'case_00171_25': [], 'case_00171_35': [], 'case_00171_45': [], 'case_00171_40': [], 'case_00171_55': [], 'case_00171_50': [], 'case_00171_60': [(0.6328125, 0.673828125, 0.0390625, 0.05078125)], 'case_00171_65': [(0.662109375, 0.65625, 0.12890625, 0.13671875), (0.3515625, 0.6591796875, 0.140625, 0.119140625)], 'case_00171_70': [(0.677734375, 0.642578125, 0.140625, 0.1328125), (0.3408203125, 0.6513671875, 0.158203125, 0.126953125), (0.7822265625, 0.595703125, 0.076171875, 0.07421875)], 'case_00171_75': [(0.6826171875, 0.615234375, 0.138671875, 0.1484375), (0.3251953125, 0.634765625, 0.150390625, 0.14453125), (0.7578125, 0.5908203125, 0.16015625, 0.162109375)], 'case_00171_80': [(0.66796875, 0.5888671875, 0.1328125, 0.130859375), (0.3330078125, 0.6171875, 0.130859375, 0.12890625), (0.7724609375, 0.5947265625, 0.126953125, 0.126953125)], 'case_00171_85': [(0.6552734375, 0.5634765625, 0.017578125, 0.013671875)], 'case_00171_95': [], 'case_00171_90': [], 'case_00171_100': [], 'case_00171_105': [], 'case_00171_110': [], 'case_00171_120': [], 'case_00171_115': [], 'case_00171_125': [], 'case_00171_130': [], 'case_00009_0': [], 'case_00009_10': [], 'case_00009_15': [], 'case_00009_5': [], 'case_00009_20': [(0.5869140625, 0.634765625, 0.041015625, 0.046875)], 'case_00009_25': [(0.595703125, 0.62890625, 0.10546875, 0.09375), (0.5966796875, 0.6767578125, 0.060546875, 0.052734375)], 'case_00009_30': [(0.6103515625, 0.6298828125, 0.130859375, 0.126953125), (0.595703125, 0.6787109375, 0.0546875, 0.044921875)], 'case_00009_35': [(0.6259765625, 0.62890625, 0.146484375, 0.1171875), (0.3603515625, 0.6318359375, 0.072265625, 0.099609375)], 'case_00009_40': [(0.337890625, 0.6240234375, 0.10546875, 0.123046875), (0.64453125, 0.6376953125, 0.140625, 0.111328125)], 'case_00009_45': [(0.328125, 0.6005859375, 0.12890625, 0.142578125), (0.65234375, 0.634765625, 0.125, 0.1171875)], 'case_00009_50': [(0.3115234375, 0.59375, 0.119140625, 0.125), (0.654296875, 0.6357421875, 0.10546875, 0.095703125)], 'case_00009_55': [(0.314453125, 0.5751953125, 0.12890625, 0.123046875), (0.6552734375, 0.6396484375, 0.044921875, 0.041015625)], 'case_00009_60': [(0.3125, 0.5703125, 0.1015625, 0.1015625)], 'case_00009_70': [], 'case_00009_65': [], 'case_00009_75': [], 'case_00159_0': [], 'case_00159_5': [], 'case_00159_10': [], 'case_00159_15': [], 'case_00159_20': [], 'case_00159_25': [], 'case_00159_30': [], 'case_00159_40': [], 'case_00159_35': [], 'case_00159_45': [], 'case_00159_50': [], 'case_00159_55': [], 'case_00159_60': [], 'case_00159_65': [], 'case_00159_70': [], 'case_00159_75': [(0.404296875, 0.6474609375, 0.03515625, 0.033203125)], 'case_00159_80': [(0.400390625, 0.638671875, 0.0625, 0.0703125)], 'case_00159_85': [(0.3994140625, 0.638671875, 0.080078125, 0.08984375)], 'case_00159_90': [(0.3994140625, 0.6396484375, 0.091796875, 0.099609375)], 'case_00159_95': [(0.3994140625, 0.6376953125, 0.107421875, 0.111328125)], 'case_00159_100': [(0.3974609375, 0.638671875, 0.115234375, 0.12109375)], 'case_00159_105': [(0.39453125, 0.6376953125, 0.12109375, 0.126953125)], 'case_00159_110': [(0.3955078125, 0.638671875, 0.119140625, 0.12890625)], 'case_00159_115': [(0.3955078125, 0.638671875, 0.123046875, 0.1328125)], 'case_00159_120': [(0.39453125, 0.63671875, 0.1328125, 0.1328125)], 'case_00159_125': [(0.6123046875, 0.634765625, 0.033203125, 0.03515625), (0.3271484375, 0.62109375, 0.001953125, 0.00390625), (0.3251953125, 0.6259765625, 0.001953125, 0.005859375), (0.3232421875, 0.642578125, 0.001953125, 0.0234375), (0.3251953125, 0.6630859375, 0.001953125, 0.005859375), (0.33203125, 0.67578125, 0.01171875, 0.01953125), (0.3388671875, 0.6865234375, 0.001953125, 0.001953125), (0.392578125, 0.63671875, 0.13671875, 0.13671875)], 'case_00159_130': [(0.6201171875, 0.6357421875, 0.068359375, 0.064453125), (0.3310546875, 0.654296875, 0.025390625, 0.078125), (0.3916015625, 0.63671875, 0.134765625, 0.13671875)], 'case_00159_135': [(0.3544921875, 0.5869140625, 0.001953125, 0.001953125), (0.3330078125, 0.6416015625, 0.041015625, 0.107421875), (0.630859375, 0.6337890625, 0.1015625, 0.080078125), (0.39453125, 0.638671875, 0.12890625, 0.1328125)], 'case_00159_140': [(0.3447265625, 0.63671875, 0.072265625, 0.1171875), (0.3818359375, 0.5791015625, 0.001953125, 0.001953125), (0.6337890625, 0.6328125, 0.115234375, 0.09375), (0.3974609375, 0.638671875, 0.115234375, 0.12890625)], 'case_00159_145': [(0.3662109375, 0.5810546875, 0.001953125, 0.001953125), (0.6376953125, 0.6328125, 0.126953125, 0.10546875), (0.3310546875, 0.6396484375, 0.068359375, 0.115234375), (0.3916015625, 0.6376953125, 0.130859375, 0.126953125)], 'case_00159_150': [(0.6416015625, 0.6298828125, 0.138671875, 0.111328125), (0.3330078125, 0.6376953125, 0.091796875, 0.123046875), (0.3896484375, 0.63671875, 0.130859375, 0.12890625)], 'case_00159_155': [(0.6435546875, 0.630859375, 0.146484375, 0.12109375), (0.3720703125, 0.5771484375, 0.001953125, 0.001953125), (0.328125, 0.640625, 0.0859375, 0.125), (0.3857421875, 0.6337890625, 0.126953125, 0.130859375)], 'case_00159_160': [(0.34765625, 0.6357421875, 0.140625, 0.134765625), (0.646484375, 0.630859375, 0.15234375, 0.125), (0.3974609375, 0.638671875, 0.107421875, 0.109375)], 'case_00159_170': [(0.6494140625, 0.62890625, 0.162109375, 0.1328125), (0.34765625, 0.6337890625, 0.16015625, 0.138671875), (0.400390625, 0.6396484375, 0.08203125, 0.076171875)], 'case_00159_165': [(0.6474609375, 0.6279296875, 0.158203125, 0.130859375), (0.3486328125, 0.63671875, 0.150390625, 0.13671875), (0.3984375, 0.6396484375, 0.09375, 0.087890625)], 'case_00159_175': [(0.6513671875, 0.62890625, 0.169921875, 0.1328125), (0.345703125, 0.6337890625, 0.16015625, 0.138671875), (0.3994140625, 0.638671875, 0.072265625, 0.0625)], 'case_00159_180': [(0.65234375, 0.626953125, 0.171875, 0.13671875), (0.345703125, 0.6328125, 0.16015625, 0.140625), (0.41796875, 0.6416015625, 0.01171875, 0.013671875)], 'case_00159_185': [(0.654296875, 0.625, 0.17578125, 0.140625), (0.345703125, 0.6318359375, 0.1640625, 0.138671875)], 'case_00159_190': [(0.658203125, 0.62109375, 0.1796875, 0.14453125), (0.3447265625, 0.62890625, 0.166015625, 0.13671875)], 'case_00159_195': [(0.662109375, 0.6181640625, 0.1796875, 0.150390625), (0.3447265625, 0.6259765625, 0.169921875, 0.142578125)], 'case_00159_200': [(0.6669921875, 0.6171875, 0.185546875, 0.15234375), (0.34375, 0.623046875, 0.171875, 0.14453125)], 'case_00159_205': [(0.669921875, 0.615234375, 0.1875, 0.15234375), (0.3408203125, 0.619140625, 0.173828125, 0.1484375)], 'case_00159_210': [(0.6728515625, 0.615234375, 0.189453125, 0.15234375), (0.33984375, 0.6181640625, 0.17578125, 0.150390625)], 'case_00159_215': [(0.3388671875, 0.6142578125, 0.177734375, 0.154296875), (0.6767578125, 0.61328125, 0.189453125, 0.15234375)], 'case_00159_220': [(0.3349609375, 0.611328125, 0.177734375, 0.16015625), (0.6796875, 0.6123046875, 0.18359375, 0.154296875)], 'case_00159_225': [(0.33203125, 0.6083984375, 0.171875, 0.162109375), (0.697265625, 0.61328125, 0.1484375, 0.15234375)], 'case_00159_230': [(0.3291015625, 0.607421875, 0.169921875, 0.1640625), (0.703125, 0.611328125, 0.13671875, 0.1484375)], 'case_00159_235': [(0.3291015625, 0.60546875, 0.173828125, 0.1640625), (0.703125, 0.611328125, 0.1328125, 0.1484375)], 'case_00159_240': [(0.330078125, 0.603515625, 0.1796875, 0.16015625), (0.703125, 0.6142578125, 0.12890625, 0.146484375)], 'case_00159_245': [(0.330078125, 0.603515625, 0.1796875, 0.16015625), (0.701171875, 0.61328125, 0.1328125, 0.140625)], 'case_00159_250': [(0.33203125, 0.599609375, 0.1796875, 0.16015625), (0.697265625, 0.6123046875, 0.13671875, 0.142578125)], 'case_00159_255': [(0.3310546875, 0.5986328125, 0.177734375, 0.158203125), (0.6923828125, 0.6123046875, 0.142578125, 0.142578125)], 'case_00159_260': [(0.3330078125, 0.59765625, 0.177734375, 0.15625), (0.69140625, 0.611328125, 0.140625, 0.140625)], 'case_00159_265': [(0.3359375, 0.5947265625, 0.17578125, 0.154296875), (0.6865234375, 0.611328125, 0.142578125, 0.140625)], 'case_00159_270': [(0.337890625, 0.59375, 0.171875, 0.15234375), (0.6826171875, 0.6083984375, 0.146484375, 0.138671875)], 'case_00159_275': [(0.3388671875, 0.5927734375, 0.169921875, 0.150390625), (0.6826171875, 0.607421875, 0.142578125, 0.13671875)], 'case_00159_285': [(0.337890625, 0.591796875, 0.16015625, 0.1484375), (0.68359375, 0.607421875, 0.13671875, 0.12890625)], 'case_00159_280': [(0.337890625, 0.591796875, 0.1640625, 0.1484375), (0.68359375, 0.6083984375, 0.140625, 0.134765625)], 'case_00159_295': [(0.3388671875, 0.58984375, 0.150390625, 0.140625), (0.6826171875, 0.607421875, 0.126953125, 0.12109375)], 'case_00159_290': [(0.337890625, 0.5908203125, 0.15625, 0.142578125), (0.6826171875, 0.6064453125, 0.130859375, 0.126953125)], 'case_00159_300': [(0.33984375, 0.587890625, 0.1484375, 0.13671875), (0.681640625, 0.609375, 0.12109375, 0.1171875)], 'case_00159_305': [(0.341796875, 0.5869140625, 0.14453125, 0.134765625), (0.681640625, 0.607421875, 0.1171875, 0.11328125)], 'case_00159_310': [(0.3427734375, 0.5859375, 0.138671875, 0.12890625), (0.6806640625, 0.6064453125, 0.111328125, 0.111328125)], 'case_00159_320': [(0.3466796875, 0.5830078125, 0.126953125, 0.123046875), (0.681640625, 0.6064453125, 0.09765625, 0.095703125)], 'case_00159_315': [(0.345703125, 0.5849609375, 0.1328125, 0.126953125), (0.6806640625, 0.607421875, 0.103515625, 0.10546875)], 'case_00159_325': [(0.349609375, 0.58203125, 0.1171875, 0.11328125), (0.6826171875, 0.6064453125, 0.087890625, 0.091796875)], 'case_00159_330': [(0.353515625, 0.5810546875, 0.10546875, 0.103515625), (0.6826171875, 0.607421875, 0.080078125, 0.08203125)], 'case_00159_335': [(0.3564453125, 0.580078125, 0.091796875, 0.09765625), (0.6826171875, 0.6083984375, 0.068359375, 0.072265625)], 'case_00159_340': [(0.359375, 0.5830078125, 0.078125, 0.087890625), (0.6826171875, 0.609375, 0.056640625, 0.0546875)], 'case_00159_345': [(0.3603515625, 0.580078125, 0.068359375, 0.078125), (0.68359375, 0.6103515625, 0.0390625, 0.037109375)], 'case_00159_350': [(0.36328125, 0.5810546875, 0.05078125, 0.060546875)], 'case_00159_355': [(0.36328125, 0.5810546875, 0.01171875, 0.013671875)], 'case_00159_360': [], 'case_00159_365': [], 'case_00159_370': [], 'case_00159_375': [], 'case_00159_380': [], 'case_00159_385': [], 'case_00159_390': [], 'case_00159_395': [], 'case_00159_400': [], 'case_00159_405': [], 'case_00159_410': [], 'case_00159_415': [], 'case_00159_420': [], 'case_00159_425': [], 'case_00159_430': [], 'case_00159_435': [], 'case_00159_440': [], 'case_00159_445': [], 'case_00159_450': [], 'case_00159_455': [], 'case_00159_460': [], 'case_00159_465': [], 'case_00159_470': [], 'case_00159_475': [], 'case_00159_480': [], 'case_00159_485': [], 'case_00159_490': [], 'case_00159_495': [], 'case_00159_500': [], 'case_00159_505': [], 'case_00159_510': [], 'case_00159_515': [], 'case_00159_520': [], 'case_00159_525': [], 'case_00159_530': [], 'case_00159_540': [], 'case_00159_535': [], 'case_00159_555': [], 'case_00159_545': [], 'case_00159_550': [], 'case_00159_565': [], 'case_00159_560': [], 'case_00159_570': [], 'case_00159_580': [], 'case_00159_575': [], 'case_00159_585': [], 'case_00159_590': [], 'case_00159_595': [], 'case_00159_600': [], 'case_00159_605': [], 'case_00159_610': [], 'case_00159_615': [], 'case_00159_620': [], 'case_00159_625': [], 'case_00159_630': [], 'case_00159_635': [], 'case_00159_640': [], 'case_00159_645': [], 'case_00159_650': [], 'case_00159_655': [], 'case_00159_660': [], 'case_00159_665': [], 'case_00159_670': [], 'case_00159_675': [], 'case_00159_680': [], 'case_00159_685': [], 'case_00159_690': [], 'case_00159_695': [], 'case_00159_700': [], 'case_00159_705': [], 'case_00159_710': [], 'case_00159_715': [], 'case_00061_0': [], 'case_00061_5': [(0.6484375, 0.5908203125, 0.1015625, 0.095703125)], 'case_00061_10': [(0.3486328125, 0.5322265625, 0.142578125, 0.130859375), (0.6708984375, 0.5576171875, 0.158203125, 0.138671875)], 'case_00061_15': [(0.3271484375, 0.5087890625, 0.173828125, 0.154296875), (0.681640625, 0.5400390625, 0.14453125, 0.130859375), (0.283203125, 0.556640625, 0.09375, 0.05859375)], 'case_00061_20': [(0.3408203125, 0.4794921875, 0.173828125, 0.134765625), (0.6611328125, 0.52734375, 0.115234375, 0.1015625), (0.2890625, 0.5439453125, 0.1328125, 0.111328125)], 'case_00061_25': [(0.3662109375, 0.4599609375, 0.103515625, 0.095703125), (0.3095703125, 0.4814453125, 0.060546875, 0.052734375)], 'case_00203_0': [], 'case_00203_5': [], 'case_00203_10': [], 'case_00203_15': [], 'case_00203_20': [], 'case_00203_25': [], 'case_00203_30': [], 'case_00203_35': []}\n",
            "YOLO Predictions: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold: 0.5\n",
            "Precision: 0.0\n",
            "Recall: 0\n",
            "Threshold: 0.6\n",
            "Precision: 0.0\n",
            "Recall: 0\n",
            "Threshold: 0.7\n",
            "Precision: 0.0\n",
            "Recall: 0\n",
            "Threshold: 0.8\n",
            "Precision: 0.0\n",
            "Recall: 0\n",
            "Threshold: 0.9\n",
            "Precision: 0.0\n",
            "Recall: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}